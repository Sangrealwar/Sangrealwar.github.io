<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Stream框架</title>
    <url>/2022/02/16/stream%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<p>TODO </p>
<h1 id="常见流框架"><a href="#常见流框架" class="headerlink" title="常见流框架"></a>常见流框架</h1><p>Kafka stream</p>
<p>Flink</p>
<p>Spark stream</p>
]]></content>
      <tags>
        <tag>小结</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql排序</title>
    <url>/2022/05/19/Mysql%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h1 id="场景再现"><a href="#场景再现" class="headerlink" title="场景再现"></a>场景再现</h1><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`crowd_info`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT <span class="keyword">COMMENT</span> <span class="string">'id'</span>,</span><br><span class="line">  <span class="string">`crowd_type`</span> <span class="built_in">tinyint</span>(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">'0'</span> <span class="keyword">COMMENT</span> <span class="string">'人群类型'</span>,</span><br><span class="line">  <span class="string">`crowd_name`</span> <span class="built_in">varchar</span>(<span class="number">32</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'人群名'</span>,</span><br><span class="line">  <span class="string">`description`</span> <span class="built_in">varchar</span>(<span class="number">256</span>) <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="string">''</span> <span class="keyword">COMMENT</span> <span class="string">'人群描述'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> AUTO_INCREMENT=<span class="number">20534127</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4 <span class="keyword">COLLATE</span>=utf8mb4_bin <span class="keyword">COMMENT</span>=<span class="string">'人群'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5051</span>, <span class="number">2</span>, <span class="string">'AD'</span>, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5052</span>, <span class="number">2</span>, <span class="string">'是多少大'</span>, <span class="string">'阿萨德'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5053</span>, <span class="number">2</span>, <span class="string">'tantest'</span>, <span class="string">'1111'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5054</span>, <span class="number">2</span>, <span class="string">'zzy'</span>, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5055</span>, <span class="number">2</span>, <span class="string">'zy去111'</span>, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5056</span>, <span class="number">2</span>, <span class="string">'test人群包测试'</span>, <span class="string">'12121'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5215</span>, <span class="number">2</span>, <span class="string">'ad'</span>, <span class="string">'asdasd'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`1111`</span>.<span class="string">`crowd_info`</span>(<span class="string">`id`</span>, <span class="string">`crowd_type`</span>, <span class="string">`crowd_name`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="number">5216</span>, <span class="number">2</span>, <span class="string">'whg-验证一下人群名称'</span>, <span class="string">''</span>);</span><br></pre></td></tr></table></figure>

<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>想根据字符排序，但排序的时候忽略了大小写</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> crowd_info</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> crowd_name</span><br></pre></td></tr></table></figure>

<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>5051    2    AD<br>5215    2    ad    asdasd<br>5174    2    BY-01<br>5162    2    dd    dd</p>
<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>为什么ad会夹在AD和BY-01之间呢</p>
<h1 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h1><p>简而言之，是因为表创建时，crowd_name定义了字段的字符集，但没有定义排序规则，所以采用了字段字符集的排序规则。（详见：<a href="https://dev.mysql.com/doc/refman/5.7/en/charset-column.html），而utf8的默认排序规则为utf8_general_ci查询，详见（https://dev.mysql.com/doc/refman/5.7/en/show-collation.html），可以通过show指令看字段的排序集。utf8mb4_bin二进制编码排序可以有效的识别大小写，因为排序比较的是二进制的数值，而utf8_general_ci很可惜，是忽略大小写的。" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/charset-column.html），而utf8的默认排序规则为utf8_general_ci查询，详见（https://dev.mysql.com/doc/refman/5.7/en/show-collation.html），可以通过show指令看字段的排序集。utf8mb4_bin二进制编码排序可以有效的识别大小写，因为排序比较的是二进制的数值，而utf8_general_ci很可惜，是忽略大小写的。</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> @s = _utf8 <span class="string">'AD'</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="keyword">SET</span> @s1 = _utf8 <span class="string">'BY-01'</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="keyword">SET</span> @s2 = _utf8 <span class="string">'ad'</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="keyword">SELECT</span>   <span class="keyword">HEX</span>(WEIGHT_STRING(@s)),<span class="keyword">HEX</span>(WEIGHT_STRING(@s1)),<span class="keyword">HEX</span>(WEIGHT_STRING(@s2));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">00410044	00420059002D00300031	00410044</span><br></pre></td></tr></table></figure>

<p>可以看出</p>
<p>AD和ad的权重都是一样的，所以BY就排在下面了（如果相同了咋办，相同了，谁排在前面谁就在前面呀，一般是按id）</p>
<h1 id="附参考"><a href="#附参考" class="headerlink" title="附参考"></a>附参考</h1><p>来自mysql5.7官网</p>
<p>字符集命名规范</p>
<p><a href="https://dev.mysql.com/doc/refman/5.7/en/charset-collation-names.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/charset-collation-names.html</a></p>
<p>字符集排序的介绍</p>
<p><a href="https://dev.mysql.com/doc/refman/5.7/en/charset-general.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/charset-general.html</a></p>
<p>查看字符的排序值，确定排序顺序</p>
<p><a href="https://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_weight-string" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_weight-string</a></p>
<p>查看表的排序集</p>
<p><a href="https://dev.mysql.com/doc/refman/5.7/en/show-columns.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/show-columns.html</a></p>
]]></content>
      <tags>
        <tag>阅读笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Vert.x</title>
    <url>/2022/05/15/Vert-x/</url>
    <content><![CDATA[<h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p>Vertx是一款基于JVM的，反应式的应用包。本质上是一个工具包，可以利用这个工具包快速构建web的项目。有以下几个优点</p>
<ol>
<li>高效的资源利用</li>
</ol>
<p>相比传统的基于阻塞IO的框架，可以利用更少的资源响应更多的请求。</p>
<ol start="2">
<li>并行与异步</li>
</ol>
<p>致力提供可理解的软件包，可以与callback，promises，futures等相结合</p>
<ol start="3">
<li>灵活性</li>
</ol>
<p>是一个工具包，并不是个框架，有很好的兼容性和适配性，没有对应用框架有强制要求</p>
<ol start="4">
<li>自由</li>
</ol>
<p>没有所谓的最佳实践，享受编程</p>
<ol start="5">
<li>生态系统</li>
</ol>
<p>数据库，消息，事件流，注册中心等名词，Vert.x都有覆盖，如果没覆盖，说明有垂直领域实现了。</p>
<h1 id="核心模块"><a href="#核心模块" class="headerlink" title="核心模块"></a>核心模块</h1><p>编写Tcp的客户端服务端</p>
<p>编写Http的客户端服务端，并支持webSockets</p>
<p>事件总线</p>
<p>共享数据-本地字典及集群分布式字典</p>
<p>周期性和延迟动作</p>
<p>垂直部署和下线</p>
<p>数据包套接字</p>
<p>DNS客户端</p>
<p>文件系统访问</p>
<p>高可靠性</p>
<p>原生支持</p>
<p>集群</p>
<h1 id="其余板块"><a href="#其余板块" class="headerlink" title="其余板块"></a>其余板块</h1><h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><p>官网：<a href="https://vertx.io/" target="_blank" rel="noopener">https://vertx.io/</a></p>
<p>github：<a href="https://github.com/eclipse-vertx/vert.x" target="_blank" rel="noopener">https://github.com/eclipse-vertx/vert.x</a></p>
]]></content>
      <tags>
        <tag>组件</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>Lucene</title>
    <url>/2022/06/26/Lucene/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">



<p><em>Lucene</em>是apache软件基金会 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包</p>
<p>作为elasticsearch的基础构建，提供了强大的分词搜索功能，在倒排索引的基础之上，也进行了压缩、分块索引，达到优化的目的。</p>
<p>官网：<a href="https://lucene.apache.org/" target="_blank" rel="noopener">https://lucene.apache.org/</a></p>
<p>版本：9.2.0</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>在Lucene中基本概念是Index，Document，Field，Term。Index包含多个Document，Document包含一系列Field，Field是一系列Term的命名，Term是具体存储的二进制文件。</p>
<p>倒排索引（Inverted Indexing）。Lucene为了使基于Term的查询更高效，在Index中存储了term和term的统计信息，这种存储结构被称为倒排索引。倒排索引是一个列表，存储了每一个term被那个document包含。</p>
<p>Field的类型。Field可以被存储，表示只是存储，不被索引。另一种是索引。每一个Field可以被存储和索引。text类型的Field被分词（tokenized）以便索引，也可以直接作为字面量被索引。大部分通过分词索引，少数通过字面量直接索引（比如编号，url）。</p>
<p>分段（Segments）。Lucene的索引可以被多个子索引或者段组合而成。每一个段是一个独立的索引，可以被独立的搜索。Lucene主要操作有两个：在索引中创建一个新的段，或者合并已有的段。</p>
<p>文档编号。在段下面，文档是从0开始递增的。如需要转换为外部的编码，需要结合每个段的基准。</p>
<p>lucene4.0之后采用FST（Finite State Transducer）作为词典，存储term-&gt;docId的关系。在内存中查找，提高查询效率。</p>
<h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><h2 id="Posting-List"><a href="#Posting-List" class="headerlink" title="Posting List"></a>Posting List</h2><p>主要存储DocId，位置，词频等信息。三个文件实现类似。</p>
<blockquote>
<p>.doc后缀文件：记录 Postings 的 docId 信息和 Term 的词频<br>.pay后缀文件：记录 Payload 信息和偏移量信息<br>.pos后缀文件：记录位置信息</p>
</blockquote>
<p>.doc存储每个Term对应的DocId和词频。每个Term对应多个DocId。有两部分组成，TermFreqs和SkipData。TermFreqs存放DocId和词频信息，SkipData组织TermFreqs，快速查找DocId。</p>
<p>TermFreqs存储的是docId和词频的int值，这里为了压缩空间，采用PackedBlock 和 VIntBlocks两种方式存储。</p>
<p>SkipData存储了每个TermFreqs的Block节点，Block中存放了DocId，DocBlockFP、PosBlockFP、PayBlockFP。</p>
<blockquote>
<p>最终的数据<br>SkipOffset：用来描述当前 term 信息在 .doc 文件中跳表信息的起始位置。<br>DocStartFP：是当前 term 信息在 .doc 文件中的文档 ID 与词频信息的起始位置。<br>PosStartFP：是当前 term 信息在 .pos 文件中的起始位置。<br>PayStartFP：是当前 term 信息在 .pay 文件中的起始位置。</p>
</blockquote>
<h2 id="Terms-Dictionary（索引表）"><a href="#Terms-Dictionary（索引表）" class="headerlink" title="Terms Dictionary（索引表）"></a>Terms Dictionary（索引表）</h2><p>存储所有的 Term 数据，用于关联Posting List。内部通过共享前缀进行压缩存储</p>
<blockquote>
<p>.tim后缀文件：记录term的字典</p>
<p>.tip后缀文件：部分term内存存储，指向索引表</p>
</blockquote>
<p>考虑到Terms Dicttionary很大，无法直接存入内存，这里将部分前缀通过FST存储。所以FST只存储了部分前缀信息，后缀信息需要继续到tim文件中查找。</p>
<p>FST类似以下存储结构</p>
<p><img src="/2022/06/26/Lucene/weiqian/Documents/3_study/hexo/source/_posts/Lucene/image-20220626170304537.png" alt="image-20220626170304537" loading="lazy"></p>
<h2 id="查询逻辑"><a href="#查询逻辑" class="headerlink" title="查询逻辑"></a>查询逻辑</h2><p>通过 Term Index 数据（.tip文件）中的 StartFP 获取指定字段的 FST<br>通过 FST 找到指定 Term 在 Term Dictionary（.tim 文件）可能存在的 Block<br>将对应 Block 加载内存，遍历 Block 中的 Entry，通过后缀（Suffix）判断是否存在指定 Term<br>存在则通过 Entry 的 TermStat 数据中各个文件的 FP 获取 Posting 数据<br>如果需要获取 Term 对应的所有 DocId 则直接遍历 TermFreqs，如果获取指定 DocId 数据则通过 SkipData 快速跳转</p>
]]></content>
      <tags>
        <tag>组件</tag>
      </tags>
  </entry>
  <entry>
    <title>MQ选型比较</title>
    <url>/2023/09/23/MQ%E9%80%89%E5%9E%8B%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><h1 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h1><h2 id="多租户"><a href="#多租户" class="headerlink" title="多租户"></a>多租户</h2><p>Kafka</p>
<p>​    腾讯云Partition/Topic受限，目前购买的最大Partition为4000。按照每个Topic平均2个，也只能有2000个Topic。</p>
<p>​    多Topic，Topic正则消费，发送时指定不同的topic后缀，由同一个消费者消费，不太行，其实还是顺序消费，无法做到隔离</p>
<p>​    提前订阅多Topic，封装Kafka，Sdk，封装管理界面（这个可以做到artemis里面，和灰度类似）定义每个队列的优先级，每个优先级的partition数量，提供指定bosid加入xxx优先级的能力。</p>
<p>Rocketmq</p>
<p>​    需要定义多个消费者组，且同时生效不同的标签规则（Tag过滤，但同一个消费者组需要保证同样的tag过滤规则，否则会丢失消息），因为Tag只能定义一个，扩展性不强，只能用Sql过滤的方式，Sql过滤是要求消息里携带用户自定义属性，通过Sql表达式过滤</p>
<p>​    </p>
<p>Mysql</p>
<p>​    轮训租户标识，定时读取</p>
<p>公司内同类产品</p>
<p>Artemis</p>
<p>Rocketmq</p>
<h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><p>流量整形</p>
<p>Sentinal结合rocketmq（<a href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%BA-RocketMQ-%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AA）" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%BA-RocketMQ-%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AA）</a></p>
<p>公司同类产品</p>
<p>Sentinal</p>
<p>​    集成自Sentinal，有排队等待的规则</p>
<p>​    能否支持消费者端拦截？</p>
<p>Kafka+令牌桶</p>
<p>​    通过令牌桶限流，如果超过流量，暂停消费（<a href="https://blog.51cto.com/u_14020077/5836708）" target="_blank" rel="noopener">https://blog.51cto.com/u_14020077/5836708）</a></p>
<p>.</p>
<h1 id="百度爱番番实时CDP建设实践"><a href="#百度爱番番实时CDP建设实践" class="headerlink" title="百度爱番番实时CDP建设实践"></a>百度爱番番实时CDP建设实践</h1><p><a href="https://blog.csdn.net/lihui49/article/details/122819751" target="_blank" rel="noopener">https://blog.csdn.net/lihui49/article/details/122819751</a></p>
<h1 id="标签系统后端技术架构-标签平台技术架构"><a href="#标签系统后端技术架构-标签平台技术架构" class="headerlink" title="标签系统后端技术架构 标签平台技术架构"></a>标签系统后端技术架构 标签平台技术架构</h1><p> 转</p>
<p><a href="https://blog.51cto.com/u_16213659/7115736" target="_blank" rel="noopener">https://blog.51cto.com/u_16213659/7115736</a></p>
<p><strong>DMP标签系统建设实践</strong></p>
<p><a href="https://blog.51cto.com/u_14637492/6273020" target="_blank" rel="noopener">https://blog.51cto.com/u_14637492/6273020</a></p>
]]></content>
  </entry>
  <entry>
    <title>存储选型测试</title>
    <url>/2023/12/31/%E5%AD%98%E5%82%A8%E9%80%89%E5%9E%8B%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">



<h1 id="测试背景"><a href="#测试背景" class="headerlink" title="测试背景"></a>测试背景</h1><p>待测试中间件，impala+kudu，presto+kudu，starrocks</p>
<p>数据量100W，20个字段</p>
<p>写入：javaClient</p>
<p>查询：分页，多条件</p>
<p>环境：docker</p>
<p>测试表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kudu.default.ncdp_dwd_user_action_bos (</span><br><span class="line">   u_key <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   u_key_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   channel_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   channel_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   <span class="keyword">uuid</span> <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   update_time <span class="built_in">bigint</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   bos_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( primary_key = <span class="literal">true</span> ),</span><br><span class="line">   s_channel_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   s_channel_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   vid <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   vid_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   event_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   page_name <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   page_title <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   element_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   activity_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   activity_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   keyword <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   guider_wid <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   goods_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   en <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   scene <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   scene_h5 <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   goods_price <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   sku_price <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   sku_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   cart_sku_num <span class="built_in">bigint</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   external_userid <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   external_channel_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   bind_guider_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   share_guider_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   external_channel_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   campaign_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   adgroup_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   position_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   action_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   invited_num <span class="built_in">bigint</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   share_openid <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   share_wid <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   <span class="keyword">result</span> <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   weimob_channel_type <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   order_source <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   app_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   coupon_template_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   <span class="keyword">source</span> <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   add_value <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   staff_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   chat_group_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   menu_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   is_new_user <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   reward_level <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   process_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   goods_list <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   coupon_name <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   order_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   mall_down_stream <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   write_time <span class="built_in">bigint</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   pay_amt <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   point_discount <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   balance_discount <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   node_id <span class="built_in">varchar</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   enter_ma_time <span class="built_in">bigint</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> ),</span><br><span class="line">   join_process_time <span class="built_in">bigint</span> <span class="keyword">WITH</span> ( nullable = <span class="literal">true</span> )</span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">   number_of_replicas = <span class="number">1</span>,</span><br><span class="line">   partition_by_hash_buckets = <span class="number">4</span>,</span><br><span class="line">   partition_by_hash_columns = <span class="built_in">ARRAY</span>[<span class="string">'bos_id'</span>],</span><br><span class="line">   partition_by_range_columns = <span class="built_in">ARRAY</span>[<span class="string">'update_time'</span>],</span><br><span class="line">   partition_by_second_hash_buckets = <span class="number">8</span>,</span><br><span class="line">   partition_by_second_hash_columns = <span class="built_in">ARRAY</span>[<span class="string">'u_key'</span>],</span><br><span class="line">   range_partitions = <span class="string">'[&#123;"lower":0,"upper":1719763200000&#125;]'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>





<h1 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h1><h2 id="Starrocks"><a href="#Starrocks" class="headerlink" title="Starrocks"></a>Starrocks</h2><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><h2 id="Impala"><a href="#Impala" class="headerlink" title="Impala"></a>Impala</h2><blockquote>
<p>版本：4.0.0</p>
</blockquote>
<blockquote>
<p>腾讯云使用的是3.4.1，官网的quickstart提供的是较早的版本，这里直接利用官网步骤搭建简易环境</p>
</blockquote>
<p><a href="https://github.com/apache/impala/blob/master/docker/quickstart.yml" target="_blank" rel="noopener">https://github.com/apache/impala/blob/master/docker/quickstart.yml</a></p>
<h3 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">hms:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">$&#123;IMPALA_QUICKSTART_IMAGE_PREFIX:-&#125;impala_quickstart_hms</span></span><br><span class="line">    <span class="comment"># Give the HMS an explicit hostname to avoid issues with docker-compose-generated</span></span><br><span class="line">    <span class="comment"># hostnames including underscore, which is rejected by Java's URL parser.</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">quickstart-hive-metastore</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["hms"]</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="comment"># Volume used to store Apache Derby database.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">impala-quickstart-warehouse:/var/lib/hive</span></span><br><span class="line">      <span class="comment"># Warehouse directory. HMS does file operations so needs access to the</span></span><br><span class="line">      <span class="comment"># shared volume.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">impala-quickstart-warehouse:/user/hive/warehouse</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./quickstart_conf:/opt/hive/conf:ro</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">quickstart-network</span></span><br><span class="line">  <span class="attr">statestored:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">$&#123;IMPALA_QUICKSTART_IMAGE_PREFIX:-&#125;statestored</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="comment"># Web debug UI</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"$&#123;QUICKSTART_LISTEN_ADDR:?Please set QUICKSTART_LISTEN_ADDR environment variable&#125;:25010:25010"</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["-redirect_stdout_stderr=false",</span> <span class="string">"-logtostderr"</span><span class="string">,</span> <span class="string">"-v=1"</span><span class="string">]</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./quickstart_conf:/opt/impala/conf:ro</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">quickstart-network</span></span><br><span class="line">  <span class="attr">catalogd:</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">statestored</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">hms</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">$&#123;IMPALA_QUICKSTART_IMAGE_PREFIX:-&#125;catalogd</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="comment"># Web debug UI</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"$&#123;QUICKSTART_LISTEN_ADDR:?Please set QUICKSTART_LISTEN_ADDR environment variable&#125;:25020:25020"</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["-redirect_stdout_stderr=false",</span> <span class="string">"-logtostderr"</span><span class="string">,</span> <span class="string">"-v=1"</span><span class="string">,</span></span><br><span class="line">              <span class="string">"-hms_event_polling_interval_s=1"</span><span class="string">,</span> <span class="string">"-invalidate_tables_timeout_s=999999"</span><span class="string">]</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="comment"># Warehouse directory. Catalog does file operations so needs access to the</span></span><br><span class="line">      <span class="comment"># shared volume.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">impala-quickstart-warehouse:/user/hive/warehouse</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./quickstart_conf:/opt/impala/conf:ro</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">quickstart-network</span></span><br><span class="line">  <span class="attr">impalad-1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">$&#123;IMPALA_QUICKSTART_IMAGE_PREFIX:-&#125;impalad_coord_exec</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">impalad-1</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">statestored</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">catalogd</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="comment"># Beeswax endpoint (deprecated)</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"$&#123;QUICKSTART_LISTEN_ADDR:?Please set QUICKSTART_LISTEN_ADDR environment variable&#125;:21000:21000"</span></span><br><span class="line">      <span class="comment"># HS2 endpoint</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"$&#123;QUICKSTART_LISTEN_ADDR:?Please set QUICKSTART_LISTEN_ADDR environment variable&#125;:21050:21050"</span></span><br><span class="line">      <span class="comment"># Web debug UI</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"$&#123;QUICKSTART_LISTEN_ADDR:?Please set QUICKSTART_LISTEN_ADDR environment variable&#125;:25000:25000"</span></span><br><span class="line">      <span class="comment"># HS2 over HTTP endpoint.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"$&#123;QUICKSTART_LISTEN_ADDR:?Please set QUICKSTART_LISTEN_ADDR environment variable&#125;:28000:28000"</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">[</span> <span class="string">"-v=1"</span><span class="string">,</span></span><br><span class="line">              <span class="string">"-redirect_stdout_stderr=false"</span><span class="string">,</span> <span class="string">"-logtostderr"</span><span class="string">,</span></span><br><span class="line">              <span class="string">"-kudu_master_hosts=kudu_kudu-master-1_1:7051"</span><span class="string">,</span></span><br><span class="line">              <span class="string">"-mt_dop_auto_fallback=true"</span><span class="string">,</span></span><br><span class="line">              <span class="string">"-default_query_options=mt_dop=4,default_file_format=parquet,default_transactional_type=insert_only"</span><span class="string">,</span></span><br><span class="line">              <span class="string">"-mem_limit=4gb"</span><span class="string">]</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="comment"># Keep the Java heap small to preserve memory for query execution.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">JAVA_TOOL_OPTIONS="-Xmx1g"</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">impala-quickstart-warehouse:/user/hive/warehouse</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./quickstart_conf:/opt/impala/conf:ro</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">quickstart-network</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">impala-quickstart-hms:</span></span><br><span class="line">  <span class="attr">impala-quickstart-warehouse:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">quickstart-network:</span></span><br><span class="line">    <span class="attr">external:</span> <span class="literal">true</span><span class="string">%</span></span><br></pre></td></tr></table></figure>



<p>下载代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;impala.git</span><br><span class="line">cd impala&#x2F;docker</span><br></pre></td></tr></table></figure>

<ul>
<li>配置ip</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> QUICKSTART_LISTEN_ADDR=0.0.0.0</span><br></pre></td></tr></table></figure>

<ul>
<li>指定impala版本</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> IMPALA_QUICKSTART_IMAGE_PREFIX=<span class="string">"apache/impala:81d5377c2-"</span></span><br></pre></td></tr></table></figure>

<ul>
<li>docker-compose启动</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker-compose -f quickstart.yml up -d</span><br></pre></td></tr></table></figure>

<blockquote>
<p>坑1：由于docker-componse启动时，会把当前目录作为容器前缀，导致容器互联时会找不到容器，目前没找到解法，只能手动指定容器名</p>
<p>坑2：找到往上一个docker搭建3.4版本的镜像，但是，由于mac无法暴露host宿主机，导致搭建失败：<a href="https://github.com/yarivgraf/apache-impala-cluster-docker?tab=readme-ov-file" target="_blank" rel="noopener">https://github.com/yarivgraf/apache-impala-cluster-docker?tab=readme-ov-file</a></p>
</blockquote>
<h2 id="Presto"><a href="#Presto" class="headerlink" title="Presto"></a>Presto</h2><blockquote>
<p>版本：351</p>
</blockquote>
<h3 id="启动-2"><a href="#启动-2" class="headerlink" title="启动"></a>启动</h3><blockquote>
<p>由于Mac权限问题，以下docker方式，如果采用挂载的方式，会提示/User无权限，故采用本地安装的方式。不挂载可以启动</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name trino -d -p 8080:8080 --volume $PWD&#x2F;etc:&#x2F;etc&#x2F;presto  ghcr.io&#x2F;trinodb&#x2F;presto:322</span><br></pre></td></tr></table></figure>

<blockquote>
<p>由于332版本太古老，未找到安装包，官方提供最早的安装包是351，故测试采用351版本</p>
</blockquote>
<ul>
<li>服务端</li>
</ul>
<p>下载链接 <a href="https://repo1.maven.org/maven2/io/trino/trino-server/351/trino-server-351.tar.gz" target="_blank" rel="noopener">https://repo1.maven.org/maven2/io/trino/trino-server/351/trino-server-351.tar.gz</a>      解压目录如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drwxr-xr-x@   9 weiqian  staff     288  1  7 16:38 .&#x2F;</span><br><span class="line">drwxr-xr-x    8 weiqian  staff     256  1  7 16:39 ..&#x2F;</span><br><span class="line">-rw-r--r--@   1 weiqian  staff  190881  1  4  2021 NOTICE</span><br><span class="line">-rw-r--r--@   1 weiqian  staff     115  1  4  2021 README.txt</span><br><span class="line">drwxr-xr-x@   6 weiqian  staff     192  1  4  2021 bin&#x2F;</span><br><span class="line">drwxrwxrwx    8 weiqian  staff     256  1  7 16:36 etc&#x2F;</span><br><span class="line">drwxr-xr-x@ 152 weiqian  staff    4864  1  4  2021 lib&#x2F;</span><br><span class="line">drwxr-xr-x@  40 weiqian  staff    1280  1  4  2021 plugin&#x2F;</span><br></pre></td></tr></table></figure>

<p>配置etc目录，注意config.properties，351版本比较老，单节点启动时，可以把这个节点作为协调者，也作为worker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">coordinator&#x3D;true</span><br><span class="line">node-scheduler.include-coordinator&#x3D;true</span><br><span class="line">discovery-server.enabled&#x3D;true</span><br><span class="line">http-server.http.port&#x3D;8080</span><br><span class="line">discovery.uri&#x3D;http:&#x2F;&#x2F;localhost:8080</span><br></pre></td></tr></table></figure>

<ul>
<li>客户端</li>
</ul>
<p>下载链接 <a href="https://repo1.maven.org/maven2/io/trino/trino-cli/351/trino-cli-351-executable.jar" target="_blank" rel="noopener">https://repo1.maven.org/maven2/io/trino/trino-cli/351/trino-cli-351-executable.jar</a>   </p>
<p>使用java连接示例如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -jar trino-cli-351-executable.jar</span><br><span class="line">trino&gt;</span><br></pre></td></tr></table></figure>





<h2 id="Kudu"><a href="#Kudu" class="headerlink" title="Kudu"></a>Kudu</h2><blockquote>
<p>版本：1.12.0</p>
</blockquote>
<p>为了搭配impala使用，需要和impala连接在同一个docker环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Licensed to the Apache Software Foundation (ASF) under one</span><br><span class="line"># or more contributor license agreements.  See the NOTICE file</span><br><span class="line"># distributed with this work for additional information</span><br><span class="line"># regarding copyright ownership.  The ASF licenses this file</span><br><span class="line"># to you under the Apache License, Version 2.0 (the</span><br><span class="line"># &quot;License&quot;); you may not use this file except in compliance</span><br><span class="line"># with the License.  You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#   http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing,</span><br><span class="line"># software distributed under the License is distributed on an</span><br><span class="line"># &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span><br><span class="line"># KIND, either express or implied.  See the License for the</span><br><span class="line"># specific language governing permissions and limitations</span><br><span class="line"># under the License.</span><br><span class="line">version: &quot;3&quot;</span><br><span class="line">services:</span><br><span class="line">  kudu-master-1:</span><br><span class="line">    image: apache&#x2F;kudu:$&#123;KUDU_QUICKSTART_VERSION:-latest&#125;</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;7051:7051&quot;</span><br><span class="line">      - &quot;8051:8051&quot;</span><br><span class="line">    command: [&quot;master&quot;]</span><br><span class="line">    volumes:</span><br><span class="line">      - kudu-master-1:&#x2F;var&#x2F;lib&#x2F;kudu</span><br><span class="line">    environment:</span><br><span class="line">      - KUDU_MASTERS&#x3D;kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251</span><br><span class="line">      # TODO: Use &#96;host.docker.internal&#96; instead of KUDU_QUICKSTART_IP when it</span><br><span class="line">      # works on Linux (https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;for-linux&#x2F;issues&#x2F;264)</span><br><span class="line">      - &gt;</span><br><span class="line">        MASTER_ARGS&#x3D;--fs_wal_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kudu&#x2F;master</span><br><span class="line">        --rpc_bind_addresses&#x3D;0.0.0.0:7051</span><br><span class="line">        --rpc_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP:?Please set KUDU_QUICKSTART_IP environment variable&#125;:7051</span><br><span class="line">        --webserver_port&#x3D;8051</span><br><span class="line">        --webserver_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:8051</span><br><span class="line">        --webserver_doc_root&#x3D;&#x2F;opt&#x2F;kudu&#x2F;www</span><br><span class="line">        --stderrthreshold&#x3D;0</span><br><span class="line">        --use_hybrid_clock&#x3D;false</span><br><span class="line">        --unlock_unsafe_flags&#x3D;true</span><br><span class="line">    networks:</span><br><span class="line">      - quickstart-network</span><br><span class="line">  kudu-master-2:</span><br><span class="line">    image: apache&#x2F;kudu:$&#123;KUDU_QUICKSTART_VERSION:-latest&#125;</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;7151:7151&quot;</span><br><span class="line">      - &quot;8151:8151&quot;</span><br><span class="line">    command: [&quot;master&quot;]</span><br><span class="line">    volumes:</span><br><span class="line">      - kudu-master-2:&#x2F;var&#x2F;lib&#x2F;kudu</span><br><span class="line">    environment:</span><br><span class="line">      - KUDU_MASTERS&#x3D;kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251</span><br><span class="line">      - &gt;</span><br><span class="line">        MASTER_ARGS&#x3D;--fs_wal_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kudu&#x2F;master</span><br><span class="line">        --rpc_bind_addresses&#x3D;0.0.0.0:7151</span><br><span class="line">        --rpc_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:7151</span><br><span class="line">        --webserver_port&#x3D;8151</span><br><span class="line">        --webserver_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:8151</span><br><span class="line">        --webserver_doc_root&#x3D;&#x2F;opt&#x2F;kudu&#x2F;www</span><br><span class="line">        --stderrthreshold&#x3D;0</span><br><span class="line">        --use_hybrid_clock&#x3D;false</span><br><span class="line">        --unlock_unsafe_flags&#x3D;true</span><br><span class="line">    networks:</span><br><span class="line">      - quickstart-network</span><br><span class="line">  kudu-master-3:</span><br><span class="line">    image: apache&#x2F;kudu:$&#123;KUDU_QUICKSTART_VERSION:-latest&#125;</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;7251:7251&quot;</span><br><span class="line">      - &quot;8251:8251&quot;</span><br><span class="line">    command: [&quot;master&quot;]</span><br><span class="line">    volumes:</span><br><span class="line">      - kudu-master-3:&#x2F;var&#x2F;lib&#x2F;kudu</span><br><span class="line">    environment:</span><br><span class="line">      - KUDU_MASTERS&#x3D;kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251</span><br><span class="line">      - &gt;</span><br><span class="line">        MASTER_ARGS&#x3D;--fs_wal_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kudu&#x2F;master</span><br><span class="line">        --rpc_bind_addresses&#x3D;0.0.0.0:7251</span><br><span class="line">        --rpc_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:7251</span><br><span class="line">        --webserver_port&#x3D;8251</span><br><span class="line">        --webserver_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:8251</span><br><span class="line">        --webserver_doc_root&#x3D;&#x2F;opt&#x2F;kudu&#x2F;www</span><br><span class="line">        --stderrthreshold&#x3D;0</span><br><span class="line">        --use_hybrid_clock&#x3D;false</span><br><span class="line">        --unlock_unsafe_flags&#x3D;true</span><br><span class="line">    networks:</span><br><span class="line">      - quickstart-network</span><br><span class="line">  kudu-tserver-1:</span><br><span class="line">    image: apache&#x2F;kudu:$&#123;KUDU_QUICKSTART_VERSION:-latest&#125;</span><br><span class="line">    depends_on:</span><br><span class="line">      - kudu-master-1</span><br><span class="line">      - kudu-master-2</span><br><span class="line">      - kudu-master-3</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;7050:7050&quot;</span><br><span class="line">      - &quot;8050:8050&quot;</span><br><span class="line">    command: [&quot;tserver&quot;]</span><br><span class="line">    volumes:</span><br><span class="line">      - kudu-tserver-1:&#x2F;var&#x2F;lib&#x2F;kudu</span><br><span class="line">    environment:</span><br><span class="line">      - KUDU_MASTERS&#x3D;kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251</span><br><span class="line">      - &gt;</span><br><span class="line">        TSERVER_ARGS&#x3D;--fs_wal_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kudu&#x2F;tserver</span><br><span class="line">        --rpc_bind_addresses&#x3D;0.0.0.0:7050</span><br><span class="line">        --rpc_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:7050</span><br><span class="line">        --webserver_port&#x3D;8050</span><br><span class="line">        --webserver_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:8050</span><br><span class="line">        --webserver_doc_root&#x3D;&#x2F;opt&#x2F;kudu&#x2F;www</span><br><span class="line">        --stderrthreshold&#x3D;0</span><br><span class="line">        --use_hybrid_clock&#x3D;false</span><br><span class="line">        --unlock_unsafe_flags&#x3D;true</span><br><span class="line">    networks:</span><br><span class="line">      - quickstart-network</span><br><span class="line">  kudu-tserver-2:</span><br><span class="line">    image: apache&#x2F;kudu:$&#123;KUDU_QUICKSTART_VERSION:-latest&#125;</span><br><span class="line">    depends_on:</span><br><span class="line">      - kudu-master-1</span><br><span class="line">      - kudu-master-2</span><br><span class="line">      - kudu-master-3</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;7150:7150&quot;</span><br><span class="line">      - &quot;8150:8150&quot;</span><br><span class="line">    command: [&quot;tserver&quot;]</span><br><span class="line">    volumes:</span><br><span class="line">      - kudu-tserver-2:&#x2F;var&#x2F;lib&#x2F;kudu</span><br><span class="line">    environment:</span><br><span class="line">      - KUDU_MASTERS&#x3D;kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251</span><br><span class="line">      - &gt;</span><br><span class="line">        TSERVER_ARGS&#x3D;--fs_wal_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kudu&#x2F;tserver</span><br><span class="line">        --rpc_bind_addresses&#x3D;0.0.0.0:7150</span><br><span class="line">        --rpc_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:7150</span><br><span class="line">        --webserver_port&#x3D;8150</span><br><span class="line">        --webserver_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:8150</span><br><span class="line">        --webserver_doc_root&#x3D;&#x2F;opt&#x2F;kudu&#x2F;www</span><br><span class="line">        --stderrthreshold&#x3D;0</span><br><span class="line">        --use_hybrid_clock&#x3D;false</span><br><span class="line">        --unlock_unsafe_flags&#x3D;true</span><br><span class="line">    networks:</span><br><span class="line">      - quickstart-network</span><br><span class="line">  kudu-tserver-3:</span><br><span class="line">    image: apache&#x2F;kudu:$&#123;KUDU_QUICKSTART_VERSION:-latest&#125;</span><br><span class="line">    depends_on:</span><br><span class="line">      - kudu-master-1</span><br><span class="line">      - kudu-master-2</span><br><span class="line">      - kudu-master-3</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;7250:7250&quot;</span><br><span class="line">      - &quot;8250:8250&quot;</span><br><span class="line">    command: [&quot;tserver&quot;]</span><br><span class="line">    volumes:</span><br><span class="line">      - kudu-tserver-3:&#x2F;var&#x2F;lib&#x2F;kudu</span><br><span class="line">    environment:</span><br><span class="line">      - KUDU_MASTERS&#x3D;kudu-master-1:7051,kudu-master-2:7151,kudu-master-3:7251</span><br><span class="line">      - &gt;</span><br><span class="line">        TSERVER_ARGS&#x3D;--fs_wal_dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kudu&#x2F;tserver</span><br><span class="line">        --rpc_bind_addresses&#x3D;0.0.0.0:7250</span><br><span class="line">        --rpc_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:7250</span><br><span class="line">        --webserver_port&#x3D;8250</span><br><span class="line">        --webserver_advertised_addresses&#x3D;$&#123;KUDU_QUICKSTART_IP&#125;:8250</span><br><span class="line">        --webserver_doc_root&#x3D;&#x2F;opt&#x2F;kudu&#x2F;www</span><br><span class="line">        --stderrthreshold&#x3D;0</span><br><span class="line">        --use_hybrid_clock&#x3D;false</span><br><span class="line">        --unlock_unsafe_flags&#x3D;true</span><br><span class="line">    networks:</span><br><span class="line">      - quickstart-network</span><br><span class="line">volumes:</span><br><span class="line">  kudu-master-1:</span><br><span class="line">  kudu-master-2:</span><br><span class="line">  kudu-master-3:</span><br><span class="line">  kudu-tserver-1:</span><br><span class="line">  kudu-tserver-2:</span><br><span class="line">  kudu-tserver-3:</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  quickstart-network:</span><br><span class="line">    external: true</span><br></pre></td></tr></table></figure>



<h3 id="启动-3"><a href="#启动-3" class="headerlink" title="启动"></a>启动</h3><ul>
<li>下载git源码</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;kudu</span><br><span class="line">cd kudu</span><br></pre></td></tr></table></figure>

<ul>
<li>暴露kudu ip</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUDU_QUICKSTART_IP=$(ifconfig | grep <span class="string">"inet "</span> | grep -Fv 127.0.0.1 |  awk <span class="string">'&#123;print $2&#125;'</span> | tail -1)</span><br></pre></td></tr></table></figure>

<ul>
<li>调整kudu版本</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUDU_QUICKSTART_VERSION=<span class="string">"1.12.0"</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动集群，-d表示后台运行，官网会启动5个tablet server（测试用3个tablet server），3个master节点，启动后<a href="http://localhost:8050/tablets" target="_blank" rel="noopener">http://localhost:8050/tablets</a> Ui界面可以查看集群情况</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose -f quickstart.yml up -d</span><br></pre></td></tr></table></figure>

<ul>
<li>测试运行</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUDU_USER_NAME=kudu</span><br><span class="line"><span class="built_in">cd</span> examples/java/java-example</span><br><span class="line">mvn package</span><br><span class="line">java -DkuduMasters=localhost:7051,localhost:7151,localhost:7251 -jar target/kudu-java-example-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<ul>
<li>查看日志</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker logs $(docker ps -aqf <span class="string">"name=kudu-tserver-1"</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>关闭</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose -f quickstart.yml down</span><br><span class="line">docker stop $(docker ps -aqf <span class="string">"name=kudu"</span>)</span><br><span class="line">docker rm $(docker ps -aqf <span class="string">"name=kudu"</span>)</span><br><span class="line">docker volume rm $(docker volume ls --filter name=kudu -q)</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>课程学习</title>
    <url>/2024/03/11/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<blockquote>
<p>来自图灵课程学习</p>
</blockquote>
<h1 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h1><blockquote>
<p>无特殊说明，下文使用的引擎均指InnoDB</p>
</blockquote>
<h2 id="InnoDB引擎"><a href="#InnoDB引擎" class="headerlink" title="InnoDB引擎"></a>InnoDB引擎</h2><p>官网InnoDB架构：<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html</a> </p>
<p><img src="/2024/03/11/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/7.png" alt loading="lazy"></p>
<h3 id="In-Memory"><a href="#In-Memory" class="headerlink" title="In-Memory"></a>In-Memory</h3><ul>
<li>Buffer Pool</li>
</ul>
<p>提高读取的效率，缓存池分成页进行管理，同时为了管理缓存，有一个链表，使用LRU算法淘汰最近最少用的缓存</p>
<p>官网的缓冲链表结构图</p>
<p><img src="/2024/03/11/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/8.png" alt loading="lazy"></p>
<p>头部（Head）表示最近访问，尾部（Tail）表示最少使用。默认3/8是较少使用的，5/8是较频繁使用的。old sublist针对缓冲池污染（无索引扫描大量数据但只查询到部分数据）的操作，表示进入old sublist时必须停留的时间（毫秒），才能进入old sublist</p>
<p>如果修改数据时，当二级索引不在Buffer Pool里时，会将更新保存在change buffer，在数据加在到buffer pool时，合并之前change buffer的数据</p>
<h3 id="On-Disk"><a href="#On-Disk" class="headerlink" title="On-Disk"></a>On-Disk</h3><ul>
<li>Redo Log</li>
</ul>
<p>用于崩溃恢复，顺序追加，在commit后，会由buffer pool更新到page os cache，然后异步/同步更新到redo log</p>
<ul>
<li>Undo Tablespaces</li>
</ul>
<p>实际存储在Undo表空间，数据更新后，未commit前，会写入undo log，用于回滚和mvvc</p>
<h2 id="锁（Locking）"><a href="#锁（Locking）" class="headerlink" title="锁（Locking）"></a>锁（Locking）</h2><ul>
<li>共享锁，排他锁</li>
</ul>
<p>行锁，读读共享，读写互斥</p>
<ul>
<li>意向锁</li>
</ul>
<p>表锁，表示将要对表中的行加锁，实现多粒度锁定。为了快速识别是否有S X锁，避免加锁时，针对表内扫描每一行判断是否有冲突。分为IS，读意向锁，IX，写意向锁。<strong>不会</strong>阻塞事务</p>
<ul>
<li>记录锁</li>
</ul>
<p>行锁，锁索引，即使没有定义索引，也会生成隐藏的clustered索引</p>
<ul>
<li>间隙锁</li>
</ul>
<p>针对两个记录锁之间的间隙加锁，某些隔离级别生效（RR，RC）</p>
<ul>
<li>next-key锁</li>
</ul>
<p>是记录锁和next-key锁的组合，假设在10, 11, 13, 20上有索引（左开右闭），next-key锁范围如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(-负无穷, 10]</span><br><span class="line">(10, 11]</span><br><span class="line">(11, 13]</span><br><span class="line">(13, 20]</span><br><span class="line">(20, +正无穷)</span><br></pre></td></tr></table></figure>



<h2 id="事务（Transaction）"><a href="#事务（Transaction）" class="headerlink" title="事务（Transaction）"></a>事务（Transaction）</h2><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><p>查看当前事务隔离级别（8.0之前）</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> @@tx_isolation</span><br></pre></td></tr></table></figure>

<p>设置隔离级别</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 设置当前会话的隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">SESSION</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> UNCOMMITTED;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">SESSION</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> COMMITTED;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">SESSION</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> REPEATABLE <span class="keyword">READ</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">SESSION</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">SERIALIZABLE</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">-- 设置全局隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> UNCOMMITTED;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">READ</span> COMMITTED;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> REPEATABLE <span class="keyword">READ</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> <span class="keyword">TRANSACTION</span> <span class="keyword">ISOLATION</span> <span class="keyword">LEVEL</span> <span class="keyword">SERIALIZABLE</span>;</span><br></pre></td></tr></table></figure>



<ul>
<li>可重复读（RR Repeatable Read）<ul>
<li>InnoDB默认的事务级别（历史原因，为了在statement的binlog_format下保证主从数据一致）</li>
<li>相同的事务中第一次后建立快照，保证一致性读取（MVCC）</li>
<li>针对加锁读（select .. for update / select … lock in share mode），更新，删除操作<ul>
<li>唯一索引查询到唯一的Key，只对索引记录加锁</li>
<li>范围查询时，使用gap index和next-key index阻塞其他会话插入到间隙中</li>
</ul>
</li>
</ul>
</li>
<li>读已提交（RC Read Committed）<ul>
<li>针对加锁读（select .. for update / select … lock in share mode），更新，删除操作<ul>
<li>仅针对索引记录加锁</li>
</ul>
</li>
<li>禁用间隙锁，可能出现””幻”行（如果只是读取，那就是幻读，如果有操作，那就是幻写）</li>
<li>binlog_format限制，在RC和RU的前提下只能用row模式<ul>
<li>row，把这一行的记录都同步到从库，cancel等binlog同步组件的必备配置</li>
<li>statement，把变更语句都同步到从库，传输体量小，容易造成主从不一致</li>
</ul>
</li>
<li>额外特点<ul>
<li>针对update，delete只是在执行操作时加锁，未匹配的行会释放锁，可以极大的减少死锁的概率</li>
<li>update操作，如果一行已经加锁了，InnoDB执行”半一致”读，先获取最新版本的数据，用于判断是否匹配where条件，如果匹配，则会加锁或等待锁</li>
</ul>
</li>
</ul>
</li>
<li>读未提交（Read Uncommitted）<ul>
<li>造成脏读</li>
</ul>
</li>
<li>串行化（Serializable）<ul>
<li>类似RR，但是InnoDB隐式的将select语句都转化为select …. lock in share mode。如果autocommit关闭了，则select会开启自己的事务</li>
</ul>
</li>
</ul>
<p>小结一下：实际工作中，常用RC，结合间隙锁避免幻读问题。</p>
<h3 id="Consistent-Nonlocking-Reads（一致性视图）"><a href="#Consistent-Nonlocking-Reads（一致性视图）" class="headerlink" title="Consistent Nonlocking Reads（一致性视图）"></a>Consistent Nonlocking Reads（一致性视图）</h3><blockquote>
<p>为了实现MVCC Multiversion Concurrency Control （多版本并发控制）</p>
</blockquote>
<p>也叫快照读，主要依靠隐藏的主键id，隐藏的事务id，前一个undo日志指针及undo日志链，保证不同的select视图中，能够看到当前点之前提交的变更</p>
<ol>
<li><p>数据的undo版本链记录的事务版本（已经提交的事务会落地到数据里，不在undo版本链里），每个数据版本携带trx_id</p>
</li>
<li><p>在一致性视图生成时，需要能识别到undo版本链中，已提交的数据版本。</p>
<p>复杂理解：根据查到的资料可知，生成一致性视图时，保存了活跃事务数组，max_trx_id当前已提交的事务id+1，当前活跃事务最小值min_trx_id。当数据版本 &gt; max_trx_id。说明这个数据版本是生成视图那一刻之后生成的，肯定不可见。如果小于min_trx_id，说明已经提交，肯定可见。如果在min_trx_id - max_trx_id之间，需要判断数据版本是否在活跃数组内，如果在，说明不可见，否则可见。</p>
<p>简单理解：说白了，就是为了识别哪些是未提交的，忽略数据版本中未提交的数据，因此设定了高低位，用于快速区分。</p>
</li>
</ol>
<p>在RR中，一致性视图在同一个视图中第一次查询时生成</p>
<p>在RC中，一致性视图在每一个查询中都生成</p>
<blockquote>
<p>就是每次select会创建快照视图，并且记录已提交的事务id，和当前的事务id，而undo日志链会记录所有变更，从最新的开始，向旧的链路扫描，当扫到已提交的事务时，则可以读取。</p>
<p>快照读应用与select语句，但不一定应用于DML语句（update，delete）</p>
<p>使用begin/start transaction后，执行第一条语句后生成trx_id（事务id）</p>
</blockquote>
<h3 id="Locking-Read"><a href="#Locking-Read" class="headerlink" title="Locking Read"></a>Locking Read</h3><p>也叫当前读，主要是指select时增加锁，确保select的数据不会被修改，有2种方式：</p>
<ul>
<li>select …     lock in share mode</li>
</ul>
<p>这种方式是增加了一把共享锁，其他会话可以读取，但是不能修改</p>
<ul>
<li>select … for update</li>
</ul>
<p>类似于update一样，锁定行</p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><ul>
<li><p>主键索引</p>
</li>
<li><p>列式索引</p>
</li>
<li><p>多列索引（最左匹配）</p>
</li>
<li><p>BTree索引</p>
</li>
</ul>
<p>​    适合  = &gt; &gt;= &lt; &lt;=  between 或者 like 前缀匹配</p>
<ul>
<li>Hash索引</li>
</ul>
<p>​    适用 = &lt;=&gt; 这种等于，安全等于判断（&lt;=&gt; 如果两边都是null，则返回true）</p>
<ul>
<li>索引合并</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE t1 (</span><br><span class="line">  i1 INT NOT NULL DEFAULT 0,</span><br><span class="line">  i2 INT NOT NULL DEFAULT 0,</span><br><span class="line">  d DATE DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (i1, i2),</span><br><span class="line">  INDEX k_d (d)</span><br><span class="line">) ENGINE &#x3D; InnoDB;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT COUNT(*) FROM t1 WHERE i1 &#x3D; 3 AND d &#x3D; &#39;2000-01-01&#39;\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           id: 1</span><br><span class="line">  select_type: SIMPLE</span><br><span class="line">        table: t1</span><br><span class="line">         type: ref</span><br><span class="line">possible_keys: PRIMARY,k_d</span><br><span class="line">          key: k_d</span><br><span class="line">      key_len: 8</span><br><span class="line">          ref: const,const</span><br><span class="line">         rows: 1</span><br><span class="line">        Extra: Using index</span><br></pre></td></tr></table></figure>





<h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h2><blockquote>
<p> 配置：<a href="https://dev.mysql.com/doc/refman/5.7/en/replication-options-binary-log.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/replication-options-binary-log.html</a></p>
</blockquote>
<p>常用于主从复制</p>
<ul>
<li>Crach-Safe，分布式事务保证redo log与binlog的一致性<ul>
<li>刷盘参数：sync_binlog<ul>
<li>N&gt;1：积累到N个事务后，才刷新到硬盘    </li>
<li>N=1（默认）：表示采用同步写磁盘的方式来写二进制日志，这时写操作不使用操作系统的缓冲来写二进制日志，每次事务提交都会写入文件。</li>
<li>N=0：表示MySQL不控制binlog的刷新，由文件系统自己控制它的缓存的刷新。这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失</li>
</ul>
</li>
<li>与Redo log区别<ul>
<li>Redo log仅保存了变更数据，数据体量比binlog小</li>
<li>刷盘有3种策略（刷盘时机受innodb_flush_log_at_trx_commit控制），0表示不刷盘，1表示提交即刷盘（默认），2提交只写入page cache</li>
<li>数据循环写入日志组</li>
</ul>
</li>
<li>保持redo log与binlog一致性，采用二阶段事务，innodb_support_xa控制（默认false，5.7.10后默认true）<ul>
<li>redo log提交时会先prepar，然后binlog写入和redo log 写入执行Commit，每个操作通过事务id关联。</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>数据格式<ul>
<li>Statement<ul>
<li>记录执行的Sql原文（性能好，但数据可能不一致，比如update X set time = now() where id =1）</li>
</ul>
</li>
<li>Row<ul>
<li>记录执行包含具体值数据的Sql语句（性能较差，数据一致）</li>
</ul>
</li>
<li>Mix<ul>
<li>系统自动识别是否会引起数据不一致，不影响则采用Statement，影响则Row</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>开启</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看是否开启</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">VARIABLES</span> <span class="keyword">LIKE</span> <span class="string">'%log_bin%'</span></span><br><span class="line"></span><br><span class="line">log_bin	<span class="keyword">OFF</span></span><br><span class="line">log_bin_basename	</span><br><span class="line">log_bin_index	</span><br><span class="line">log_bin_trust_function_creators	<span class="keyword">OFF</span></span><br><span class="line">log_bin_use_v1_row_events	<span class="keyword">OFF</span></span><br><span class="line">sql_log_bin	<span class="keyword">ON</span></span><br></pre></td></tr></table></figure>

<ul>
<li>打开binlog配置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 开启binlog</span><br><span class="line">log-bin&#x3D;mysql-bin</span><br><span class="line"></span><br><span class="line">sync_binlog&#x3D;1</span><br><span class="line">binlog_format&#x3D;row</span><br></pre></td></tr></table></figure>

<ul>
<li>查看binlog</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysqlbinlog -v mysql-bin.000005</span><br><span class="line"></span><br><span class="line">## UPDATE &#96;www&#96;.&#96;event_logs&#96;</span><br><span class="line">### WHERE</span><br><span class="line">###   @1&#x3D;1586660627051</span><br><span class="line">###   @2&#x3D;1586660627051</span><br><span class="line">###   @3&#x3D;&#39;&#123;&quot;db&quot;:&quot;mysql&quot;,&quot;col&quot;:&quot;pokemon&quot;,&quot;doc&quot;:&#123;&quot;id&quot;:&quot;1&quot;,&quot;name&quot;:&quot;Pikachu&quot;,&quot;power&quot;:300,&quot;trainer_id&quot;:&quot;1&quot;&#125;,&quot;find&quot;:&#123;&quot;id&quot;:&quot;1&quot;&#125;&#125;&#39;</span><br><span class="line">###   @4&#x3D;3</span><br><span class="line">###   @5&#x3D;&#39;&#39;</span><br><span class="line">###   @6&#x3D;&#39;1aQGuedJ5oax8G04L4tkRUCmHJI&#39;</span><br><span class="line">###   @7&#x3D;&#39;1aQGugRGSoDlxsbwrY4enowZIT2&#39;</span><br><span class="line">###   @8&#x3D;&#39;DB_INSERT:1aQGUS39E0HS0gUd9dEkFDBzn44&#39;</span><br><span class="line">###   @9&#x3D;67</span><br><span class="line">###   @10&#x3D;&#39;processed&#39;</span><br><span class="line">###   @11&#x3D;&#39;http:&#x2F;&#x2F;localhost:4122&#x2F;v1&#x2F;api&#x2F;www&#x2F;realtime&#x2F;handle&#39;</span><br><span class="line">###   @12&#x3D;38</span><br><span class="line">### SET</span><br><span class="line">###   @1&#x3D;1586660627051</span><br><span class="line">###   @2&#x3D;1586660627051</span><br><span class="line">###   @3&#x3D;&#39;1111&#39;</span><br><span class="line">###   @4&#x3D;3</span><br><span class="line">###   @5&#x3D;&#39;&#39;</span><br><span class="line">###   @6&#x3D;&#39;1aQGuedJ5oax8G04L4tkRUCmHJI&#39;</span><br><span class="line">###   @7&#x3D;&#39;1aQGugRGSoDlxsbwrY4enowZIT2&#39;</span><br><span class="line">###   @8&#x3D;&#39;DB_INSERT:1aQGUS39E0HS0gUd9dEkFDBzn44&#39;</span><br><span class="line">###   @9&#x3D;67</span><br><span class="line">###   @10&#x3D;&#39;processed&#39;</span><br><span class="line">###   @11&#x3D;&#39;http:&#x2F;&#x2F;localhost:4122&#x2F;v1&#x2F;api&#x2F;www&#x2F;realtime&#x2F;handle&#39;</span><br><span class="line">###   @12&#x3D;38</span><br><span class="line"># at 2099</span><br><span class="line">#240526 13:13:14 server id 2  end_log_pos 2130 CRC32 0x6b3b1752 	Xid &#x3D; 115</span><br><span class="line">COMMIT&#x2F;*!*&#x2F;;</span><br><span class="line">SET @@SESSION.GTID_NEXT&#x3D; &#39;AUTOMATIC&#39; &#x2F;* added by mysqlbinlog *&#x2F; &#x2F;*!*&#x2F;;</span><br></pre></td></tr></table></figure>

<ul>
<li>日志强制刷盘（一般用不不上）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FLUSH LOGS</span><br></pre></td></tr></table></figure>

<ul>
<li>其他问题</li>
</ul>
<p>update没有引起变化是否有binlog数据？</p>
<p>答：如果binlog_format是statement模式，则不管更新行数是否为0都会有一条binlog记录，如果是row，则只有更新行数&gt;0才会有binlog记录</p>
<h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><blockquote>
<p>以下步骤不全，有待补充修正！！！</p>
</blockquote>
<p>搭建两个mysql，用自定义的网络，选择bridge模式，这样可以指定ip</p>
<p>版本选择5.7</p>
<p>详细参考：</p>
<p><a href="https://dev.mysql.com/doc/refman/5.7/en/replication-howto.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.7/en/replication-howto.html</a></p>
<ol>
<li>docker构建mysql容器，并启动，要求slave能够连接到主库</li>
</ol>
<p>启动mysql（作为主库）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name mysql --network=devnet  --network-alias mysql --ip 172.18.0.2 --privileged=<span class="literal">true</span> -p 33061:3306 \</span><br><span class="line">-v /Users/xxx/Documents/7_dev/mysql/conf/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf \</span><br><span class="line">-v /Users/xxx/Documents/7_dev/mysql/data:/var/lib/mysql \</span><br><span class="line">-e TZ=Asia/Shanghai \</span><br><span class="line">-e MYSQL_USER=<span class="string">""</span> \</span><br><span class="line">-e MYSQL_PASSWORD=<span class="string">""</span> \</span><br><span class="line">-e MYSQL_ALLOW_EMPTY_PASSWORD=<span class="string">"yes"</span> \</span><br><span class="line">-d mysql:5.7</span><br></pre></td></tr></table></figure>

<p>第二个mysql（作为从库）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name mysql-slave --network=devnet --link mysql:mysql-master --ip 172.18.0.3 --privileged=<span class="literal">true</span> -p 33062:3306 \</span><br><span class="line">-v /Users/xxx/Documents/7_dev/mysql-slave/conf/mysqld.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf \</span><br><span class="line">-v /Users/xxx/Documents/7_dev/mysql-slave/data:/var/lib/mysql \</span><br><span class="line">-e TZ=Asia/Shanghai \</span><br><span class="line">-e MYSQL_USER=<span class="string">""</span> \</span><br><span class="line">-e MYSQL_PASSWORD=<span class="string">""</span> \</span><br><span class="line">-e MYSQL_ALLOW_EMPTY_PASSWORD=<span class="string">"yes"</span> \</span><br><span class="line">-d mysql:5.7</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置主库和从库的service_id，开启主库的binlog</li>
</ol>
<p>主：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[mysqld] </span><br><span class="line"></span><br><span class="line">log-bin&#x3D;mysql-bin server-id&#x3D;1</span><br><span class="line"></span><br><span class="line"># binlog自动清除时间</span><br><span class="line"></span><br><span class="line">expire_logs_days &#x3D; 1</span><br></pre></td></tr></table></figure>

<p>从：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server-id&#x3D;21</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>一般是innodb，这里先将表锁住，执行dump命令，将数据dump下来，同时记录binlog文件位置</li>
</ol>
<p>主：</p>
<p>FLUSH TABLES WITH READ LOCK;</p>
<p>mysql &gt; SHOW MASTER STATUS; </p>
<p>+——————+———-+————–+——————+ | File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | +——————+———-+————–+——————+ | mysql-bin.000003 | 73       | test         | manual,mysql     | +——————+———-+————–+——————+</p>
<p>从：</p>
<p>迁移数据，修改表引擎</p>
<ol start="4">
<li>在从库配置主库连接</li>
</ol>
<p>从（必须填写user_name）：    </p>
<p>mysql&gt; CHANGE MASTER TO    -&gt;     MASTER_HOST=’source_host_name’,    -&gt;     MASTER_USER=’replication_user_name’,    -&gt;     MASTER_PASSWORD=’replication_password’,    -&gt;     MASTER_LOG_FILE=’recorded_log_file_name’,    -&gt;     MASTER_LOG_POS=recorded_log_position;</p>
<p>开始同步</p>
<p>START SLAVE;</p>
<p>查看同步状态：</p>
<p>SHOW SLAVE STATUS</p>
<h1 id="Mysql杂七杂八"><a href="#Mysql杂七杂八" class="headerlink" title="Mysql杂七杂八"></a>Mysql杂七杂八</h1><ul>
<li>group by 会默认排序，但最好跟上order by ，order by会在group by之后排序。</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>各类组件前沿版本</title>
    <url>/2024/04/18/%E5%90%84%E7%B1%BB%E7%BB%84%E4%BB%B6%E5%89%8D%E6%B2%BF%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<h1 id="Jdk"><a href="#Jdk" class="headerlink" title="Jdk"></a>Jdk</h1><blockquote>
<p>官方路线图：<a href="https://www.oracle.com/java/technologies/java-se-support-roadmap.html" target="_blank" rel="noopener">https://www.oracle.com/java/technologies/java-se-support-roadmap.html</a></p>
<p>jdk发布记录：<a href="https://www.oracle.com/java/technologies/javase/jdk-relnotes-index.html" target="_blank" rel="noopener">https://www.oracle.com/java/technologies/javase/jdk-relnotes-index.html</a></p>
</blockquote>
<h2 id="Jdk-8"><a href="#Jdk-8" class="headerlink" title="Jdk 8"></a>Jdk 8</h2><blockquote>
<p>发布记录新闻：<a href="https://www.oracle.com/java/technologies/javase/8-whats-new.html" target="_blank" rel="noopener">https://www.oracle.com/java/technologies/javase/8-whats-new.html</a></p>
<p>发布记录：<a href="https://blogs.oracle.com/java/post/jdk-8-is-released" target="_blank" rel="noopener">https://blogs.oracle.com/java/post/jdk-8-is-released</a></p>
<p>教程：<a href="https://docs.oracle.com/javase/tutorial/" target="_blank" rel="noopener">https://docs.oracle.com/javase/tutorial/</a></p>
</blockquote>
<p>Lambda表达式，利用ForkJoin并行执行</p>
<p>default接口</p>
<p>新的Datetime类</p>
<h2 id="JDK-9"><a href="#JDK-9" class="headerlink" title="JDK 9"></a>JDK 9</h2><blockquote>
<p><a href="https://openjdk.org/projects/jdk9/" target="_blank" rel="noopener">https://openjdk.org/projects/jdk9/</a></p>
</blockquote>
<p>接近200条特性</p>
<p>模块化jdk包</p>
<p>推出Http Client</p>
<h2 id="Jdk-11"><a href="#Jdk-11" class="headerlink" title="Jdk 11"></a>Jdk 11</h2><blockquote>
<p><a href="https://openjdk.org/projects/jdk/11/" target="_blank" rel="noopener">https://openjdk.org/projects/jdk/11/</a></p>
</blockquote>
<p>HTTP Client正式版（1.9就推出了）</p>
<p>Flight Recorder（黑匣子）</p>
<blockquote>
<p>下载jmc，<a href="https://www.oracle.com/java/technologies/javase/products-jmc9-downloads.html" target="_blank" rel="noopener">https://www.oracle.com/java/technologies/javase/products-jmc9-downloads.html</a></p>
</blockquote>
<p><img src="/2024/04/18/%E5%90%84%E7%B1%BB%E7%BB%84%E4%BB%B6%E5%89%8D%E6%B2%BF%E7%89%88%E6%9C%AC/1.png" alt loading="lazy"></p>
<ul>
<li>vm启动参数</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-XX:StartFlightRecording=disk=<span class="literal">true</span>,dumponexit=<span class="literal">true</span>,filename=recording.jfr,maxsize=1024m,maxage=1d,settings=profile,path-to-gc-roots=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<ul>
<li>jcmd</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 启动</span><br><span class="line">jcmd 21 JFR.start name&#x3D;profile_online maxage&#x3D;1d maxsize&#x3D;1g</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">70501:</span><br><span class="line">Started recording 2.</span><br><span class="line"></span><br><span class="line">Use jcmd 70501 JFR.dump name&#x3D;profile_online filename&#x3D;FILEPATH to copy recording data to file.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 检查状态</span><br><span class="line">jcmd &lt;pid&gt; JFR.check</span><br><span class="line"></span><br><span class="line">Recording 1: name&#x3D;profile_online maxsize&#x3D;1.0GB maxage&#x3D;1d (running)</span><br><span class="line"></span><br><span class="line"># 检查当前配置，如果传入参数则是修改配置</span><br><span class="line"># jcmd &lt;pid&gt; JFR.configure</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">70501:</span><br><span class="line">Current configuration:</span><br><span class="line"></span><br><span class="line">Preserve repository: false</span><br><span class="line">Repository path: &#x2F;private&#x2F;var&#x2F;folders&#x2F;pl&#x2F;cfxhl6md42s4x50x3h7l33zw0000gn&#x2F;T&#x2F;2024_05_05_21_59_01_70501</span><br><span class="line"></span><br><span class="line">Dump path: &#x2F;Users&#x2F;xx&#x2F;Documents&#x2F;3_study&#x2F;my</span><br><span class="line"></span><br><span class="line">Stack depth: 64</span><br><span class="line">Global buffer count: 20</span><br><span class="line">Global buffer size: 512.0 kB</span><br><span class="line">Thread buffer size: 8.0 kB</span><br><span class="line">Memory size: 10.0 MB</span><br><span class="line">Max chunk size: 12.0 MB</span><br><span class="line"></span><br><span class="line"># dump飞行记录</span><br><span class="line">jcmd &lt;pid&gt; JFR.dump</span><br></pre></td></tr></table></figure>

<h2 id="Jdk-17"><a href="#Jdk-17" class="headerlink" title="Jdk 17"></a>Jdk 17</h2><h2 id="Jdk-21"><a href="#Jdk-21" class="headerlink" title="Jdk 21"></a>Jdk 21</h2><blockquote>
<p><a href="https://openjdk.org/projects/jdk/21/" target="_blank" rel="noopener">https://openjdk.org/projects/jdk/21/</a></p>
</blockquote>
<p>字符模板</p>
<p>序列集合</p>
<p>ZGC</p>
<p>模式匹配</p>
<p>虚拟线程</p>
]]></content>
  </entry>
  <entry>
    <title>工作中的坑</title>
    <url>/2024/02/26/2_%E5%B7%A5%E4%BD%9C%E4%B8%AD%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<h1 id="Dubbo线程池无法释放"><a href="#Dubbo线程池无法释放" class="headerlink" title="Dubbo线程池无法释放"></a>Dubbo线程池无法释放</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><blockquote>
<p>使用Redis+Mysql号段生成全局唯一ID</p>
</blockquote>
<ol>
<li><p>同步dubbo接口获取最新ID，当前pod号段失效，需重新获取</p>
</li>
<li><p>触发代码获取新号段</p>
<ol>
<li>生成新号段查询条件，尝试更新号段</li>
<li>更新失败，循环再次重复查询，<strong>但恰好此时其他线程已更新号段</strong>，导致该线程无法通过旧条件获取号段，无限死循环</li>
</ol>
</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol>
<li>增加循环最大值判断</li>
<li>无限循环时，需要考虑<strong>查询条件</strong>因其他线程<strong>变更</strong>的情况，<strong>避免无限循环</strong></li>
</ol>
<h1 id="Pod偶发重启"><a href="#Pod偶发重启" class="headerlink" title="Pod偶发重启"></a>Pod偶发重启</h1><h2 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h2><blockquote>
<p>服务部署在K8s集群，每个服务的健康状态通过周期性healthcheck接口监测，当监测失败时，会触发服务重启</p>
</blockquote>
<ol>
<li>存活探针健康检测设置的周期为3秒超时，5秒间隔，3次失败即标记不存活，pod会自动重启。也就是说，如果3s内没有响应，15s之后很容易触发重启</li>
<li>探针由Spring Actuator暴露，当检测到DataSource配置时，会自动开启DB健康检测org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthContributorAutoConfiguration</li>
<li>xxx服务的druid连接池采用的maxActive是1，等待时间为1分钟，由于对外暴露的接口不多，功能影响不大。但连接池不高，且在慢sql的影响下，会影响pod存活探针的健康检测</li>
<li>在重启的几次监测时间段内，均发生了一次<strong>慢查询请求</strong>，该请求会查询db数据，耗时比较长（1分钟以上）</li>
<li>存活探针相继失败，这里dubbo执行了重试，并根据加权随机路由到仅有的2台机器上，在<strong>最后一次重试</strong>时（前两次都因为接口请求太长而失败），<strong>接口请求会与存活探针请求争抢唯一的mysql连接</strong>，如果存活探针能够抢到连接，则不会发生重启，否则会<strong>由于3次健康检测接口均无响应，导致重启</strong></li>
</ol>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><ol>
<li>减少慢查询</li>
<li>适当增加mysql连接池的连接数，减少健康检查抢占不到mysql连接的情况</li>
</ol>
<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1>]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
  </entry>
  <entry>
    <title>常用代码块</title>
    <url>/2022/05/07/2_%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E5%9D%97/</url>
    <content><![CDATA[<h1 id="过滤富文本中，A标签里href的外链"><a href="#过滤富文本中，A标签里href的外链" class="headerlink" title="过滤富文本中，A标签里href的外链"></a>过滤富文本中，A标签里href的外链</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ATagUtils</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Pattern aHrefCompile = Pattern.compile(<span class="string">"href=\"((?!\").)*\""</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> Pattern allATagCompile = Pattern.compile(<span class="string">"&lt;a[^&gt;]*&gt;((?!&lt;/a&gt;).)*&lt;/a&gt;"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理A标签，去除不在合法域名内的href属性</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> legalDomains 合法域名</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> testStr</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">dealATag</span><span class="params">(Collection&lt;String&gt; legalDomains, String testStr)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1从文本内容提取所有的a标签</span></span><br><span class="line">        StringBuffer updated = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        Matcher m = allATagCompile.matcher(testStr);</span><br><span class="line">        <span class="keyword">while</span> (m.find()) &#123;</span><br><span class="line">            <span class="keyword">boolean</span> shouldIgnore = <span class="keyword">false</span>;</span><br><span class="line">            String filepath = m.group(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">            StringBuffer replaceUpdated = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">            <span class="comment">//匹配a标签内的href</span></span><br><span class="line">            Matcher mHref = aHrefCompile.matcher(filepath);</span><br><span class="line">            <span class="keyword">while</span> (mHref.find()) &#123;</span><br><span class="line">                String hrefPath = mHref.group(<span class="number">0</span>);</span><br><span class="line">                <span class="comment">//取到href里面的内容字符串,href="&#123;&#125;"，就是&#123;&#125;这部分</span></span><br><span class="line">                hrefPath = hrefPath.substring(<span class="number">6</span>, hrefPath.length() - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//url格式：protocol :// hostname[:port] / path / [:parameters][?query]#fragment</span></span><br><span class="line">                <span class="comment">//判断是否有【://】，如果没有，则认为均是内链，跳过判断</span></span><br><span class="line">                <span class="keyword">int</span> doubleSlanting = hrefPath.indexOf(<span class="string">"://"</span>);</span><br><span class="line">                String supposeDomain = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">if</span> (doubleSlanting &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="comment">//取 hostname[:port]，如果没有/，或者第一个就是/ ，则认为该字符串为域名</span></span><br><span class="line">                    hrefPath = hrefPath.substring(doubleSlanting + <span class="number">3</span>);</span><br><span class="line">                    <span class="keyword">int</span> slanting = hrefPath.indexOf(<span class="string">"/"</span>);</span><br><span class="line">                    <span class="keyword">if</span> (slanting &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                        supposeDomain = hrefPath;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        supposeDomain = hrefPath.substring(<span class="number">0</span>, slanting);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (supposeDomain == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//比对a标签内的域名是否需过滤</span></span><br><span class="line">                <span class="keyword">if</span> (legalDomains != <span class="keyword">null</span> &amp;&amp; legalDomains.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (String ignore : legalDomains) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (supposeDomain.equals(ignore)) &#123;</span><br><span class="line">                            shouldIgnore = <span class="keyword">true</span>;</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">if</span> (shouldIgnore) &#123;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//去除正则匹配出来的href属性</span></span><br><span class="line">                mHref.appendReplacement(replaceUpdated, <span class="string">""</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            mHref.appendTail(replaceUpdated);</span><br><span class="line">            m.appendReplacement(updated, replaceUpdated.toString());</span><br><span class="line">        &#125;</span><br><span class="line">        m.appendTail(updated);</span><br><span class="line">        <span class="keyword">return</span> updated.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h1 id="Redis缓存读取防击穿样板代码"><a href="#Redis缓存读取防击穿样板代码" class="headerlink" title="Redis缓存读取防击穿样板代码"></a>Redis缓存读取防击穿样板代码</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import com.alibaba.fastjson.JSON;</span><br><span class="line">import lombok.AllArgsConstructor;</span><br><span class="line">import lombok.extern.slf4j.Slf4j;</span><br><span class="line">import org.redisson.api.RLock;</span><br><span class="line">import org.redisson.api.RedissonClient;</span><br><span class="line">import org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @Description: redis操作，仅依赖redis底层以及分布式锁，存储单个值的时候需要注意，如果是incr等redis操作，由于json序列化之后存储的Value是字符串，可能会导致redis脚本执行异常</span><br><span class="line"> * 1. 目前仅支持单对象</span><br><span class="line"> * 2. 依赖fastjson实现对空对象的处理，null对象会被fastjson序列化成&quot;null&quot;字符串，&quot;null&quot;字符串会被反序列化为&quot;&#123;&#125;&quot;</span><br><span class="line"> *</span><br><span class="line"> * @Author; weiqian</span><br><span class="line"> * @Date: 2021&#x2F;9&#x2F;27 11:05 上午</span><br><span class="line"> * @Version:</span><br><span class="line"> *&#x2F;</span><br><span class="line">@Slf4j</span><br><span class="line">@Component</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">public class RedisReaderHelper &#123;</span><br><span class="line">		&#x2F;&#x2F;redis读取bean</span><br><span class="line">    private final RedisService redisService;</span><br><span class="line">    private final RedissonClient redisson;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 从缓存中加载数据，缓存存储方式为Json字符串</span><br><span class="line">     * @param returnClass 加载的数据类型</span><br><span class="line">     * @param cacheKey 缓存key</span><br><span class="line">     * @param lockKey 缓存加锁Key</span><br><span class="line">     * @param normalSecond 正常缓存存活时间，单位：秒</span><br><span class="line">     * @param loadFromDB 缓存失效后，从db加载数据的方法</span><br><span class="line">     * @param &lt;Return&gt; 泛型：返回对象</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public &lt;Return&gt; Return loadAndSaveToJsonString(Class&lt;Return&gt; returnClass,</span><br><span class="line">                                                   String cacheKey,</span><br><span class="line">                                                   String lockKey,</span><br><span class="line">                                                   long normalSecond,</span><br><span class="line">                                                   Supplier&lt;Return&gt; loadFromDB) &#123;</span><br><span class="line">        return this.loadAndSaveToJsonString(</span><br><span class="line">                returnClass,</span><br><span class="line">                cacheKey,</span><br><span class="line">                lockKey,</span><br><span class="line">                normalSecond,</span><br><span class="line">                TimeUnit.MINUTES.toSeconds(1),</span><br><span class="line">                null,</span><br><span class="line">                loadFromDB);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 从缓存中加载数据，缓存存储方式为Json字符串</span><br><span class="line">     * @param returnClass 加载的数据类型</span><br><span class="line">     * @param cacheKey 缓存key</span><br><span class="line">     * @param lockKey 缓存加锁Key</span><br><span class="line">     * @param normalSecond 正常缓存存活时间，单位：秒</span><br><span class="line">     * @param nullSupplier 空数据缓存存活时间，单位：秒</span><br><span class="line">     * @param loadFromDB 缓存失效后，从db加载数据的方法</span><br><span class="line">     * @param &lt;Return&gt; 泛型：返回对象</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public &lt;Return&gt; Return loadAndSaveToJsonString(Class&lt;Return&gt; returnClass,</span><br><span class="line">                                                   String cacheKey,</span><br><span class="line">                                                   String lockKey,</span><br><span class="line">                                                   long normalSecond,</span><br><span class="line">                                                   Supplier&lt;Return&gt; nullSupplier,</span><br><span class="line">                                                   Supplier&lt;Return&gt; loadFromDB) &#123;</span><br><span class="line">        return this.loadAndSaveToJsonString(</span><br><span class="line">                returnClass,</span><br><span class="line">                cacheKey,</span><br><span class="line">                lockKey,</span><br><span class="line">                normalSecond,</span><br><span class="line">                TimeUnit.MINUTES.toSeconds(1),</span><br><span class="line">                nullSupplier,</span><br><span class="line">                loadFromDB);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 从缓存中加载数据，缓存存储方式为Json字符串</span><br><span class="line">     * @param returnClass 加载的数据类型</span><br><span class="line">     * @param cacheKey 缓存key</span><br><span class="line">     * @param lockKey 缓存加锁Key</span><br><span class="line">     * @param normalSecond 正常缓存存活时间，单位：秒</span><br><span class="line">     * @param nullSecond 空数据缓存存活时间，单位：秒</span><br><span class="line">     * @param nullSupplier 缓存未命中时，空数据的提供方法</span><br><span class="line">     * @param loadFromDB 缓存失效后，从db加载数据的方法</span><br><span class="line">     * @param &lt;Return&gt; 泛型：返回对象</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    private &lt;Return&gt; Return loadAndSaveToJsonString(Class&lt;Return&gt; returnClass,</span><br><span class="line">                                                    String cacheKey,</span><br><span class="line">                                                    String lockKey,</span><br><span class="line">                                                    long normalSecond,</span><br><span class="line">                                                    long nullSecond,</span><br><span class="line">                                                    Supplier&lt;Return&gt; nullSupplier,</span><br><span class="line">                                                    Supplier&lt;Return&gt; loadFromDB) &#123;</span><br><span class="line">        Return returnObj;</span><br><span class="line">        if (nullSupplier &#x3D;&#x3D; null) &#123;</span><br><span class="line">            returnObj &#x3D; null;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            returnObj &#x3D; nullSupplier.get();</span><br><span class="line">        &#125;</span><br><span class="line">        long waitTime &#x3D; 50;</span><br><span class="line">        int i &#x3D; 0;</span><br><span class="line">        while (i &lt; 3) &#123;</span><br><span class="line">            Object obj &#x3D; redisService.get(cacheKey);</span><br><span class="line">            if (obj instanceof String) &#123;</span><br><span class="line">                return JSON.parseObject((String) obj, returnClass);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F;防止缓存击透</span><br><span class="line">            RLock lock &#x3D; redisson.getLock(lockKey);</span><br><span class="line">            if (!lock.tryLock()) &#123;</span><br><span class="line">                &#x2F;&#x2F;当没有获取到锁时，休眠 x ms，再次尝试</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(waitTime);</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    return returnObj;</span><br><span class="line">                &#125;</span><br><span class="line">                i++;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            try &#123;</span><br><span class="line">                Return fromDB &#x3D; loadFromDB.get();</span><br><span class="line">                if (fromDB !&#x3D; null) &#123;</span><br><span class="line">                    redisService.set(cacheKey, JSON.toJSONString(fromDB), normalSecond);</span><br><span class="line">                    &#x2F;&#x2F;获取到数据</span><br><span class="line">                    returnObj &#x3D; fromDB;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    &#x2F;&#x2F;防止缓存穿透</span><br><span class="line">                    redisService.set(cacheKey, JSON.toJSONString(returnObj), nullSecond);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    lock.unlock();</span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">                    log.warn(&quot;可能存在嵌套加锁的情况，异常堆栈如下\n&quot;, e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">        return returnObj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h1 id="批量分批执行"><a href="#批量分批执行" class="headerlink" title="批量分批执行"></a>批量分批执行</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">     * 批量</span><br><span class="line">     *</span><br><span class="line">     * @param keys</span><br><span class="line">     * @param batch</span><br><span class="line">     * @param function</span><br><span class="line">     * @param &lt;T&gt;</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public static  &lt;T&gt; void batchRun(List&lt;T&gt; keys, int batch, Consumer&lt;List&lt;T&gt;&gt; function) &#123;</span><br><span class="line">        if (batch &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        int size &#x3D; keys.size();</span><br><span class="line">        int page &#x3D; 0;</span><br><span class="line">        int maxSize &#x3D; (int) Math.ceil(size &#x2F; batch);</span><br><span class="line">        while (page &lt;&#x3D; maxSize) &#123;</span><br><span class="line">            List&lt;T&gt; part &#x3D; keys.stream().skip(page * batch).limit(batch).collect(Collectors.toList());</span><br><span class="line">            if (part.size() &#x3D;&#x3D; 0) &#123;</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">            function.accept(part);</span><br><span class="line">            page++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h1 id="位的与非判断"><a href="#位的与非判断" class="headerlink" title="位的与非判断"></a>位的与非判断</h1><blockquote>
<p>用位来存储不同情况的组合状态</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//具体的组合子类型</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> exercise = <span class="number">1</span> &lt;&lt; <span class="number">1</span>; <span class="comment">// 锻炼</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> eatBreakfast = <span class="number">1</span> &lt;&lt; <span class="number">2</span>; <span class="comment">//吃早餐</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> readBook = <span class="number">1</span> &lt;&lt; <span class="number">3</span>;  <span class="comment">//读书</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> drinkMilk = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">//喝牛奶</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> study = <span class="number">1</span> &lt;&lt; <span class="number">5</span>; <span class="comment">//学习</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//不同组合</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> type1 = exercise | eatBreakfast;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> type2 = eatBreakfast;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> type3 = exercise | eatBreakfast | readBook | study;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> type4 = exercise | eatBreakfast | drinkMilk | study;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> all = exercise | eatBreakfast | readBook | drinkMilk | study;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//判断组合内是否存在子组合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">canStep</span><span class="params">(<span class="keyword">int</span> type, <span class="keyword">int</span> step)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (type &amp; step) == step;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> b = BitCompare.canStep(type1, exercise);</span><br><span class="line">        System.out.println(b);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line"><span class="keyword">true</span></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
      <tags>
        <tag>代码</tag>
      </tags>
  </entry>
  <entry>
    <title>常用工具命令</title>
    <url>/2022/07/23/2_%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="Mave统一修改版本号"><a href="#Mave统一修改版本号" class="headerlink" title="Mave统一修改版本号"></a>Mave统一修改版本号</h1><ul>
<li><p>要求子模块里直接写父模块的依赖版本号，不要用占位符替换</p>
<p>父模块</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">&lt;parent&gt;</span><br><span class="line">	&lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">	&lt;version&gt;2.2.6.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;parent&gt;</span><br><span class="line">&lt;groupId&gt;com.aa&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;parent-bos&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;version&gt;1.0.2-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">&lt;packaging&gt;pom&lt;&#x2F;packaging&gt;</span><br><span class="line"></span><br><span class="line">&lt;modules&gt;</span><br><span class="line">	&lt;module&gt;child-interface&lt;&#x2F;module&gt;</span><br><span class="line">	&lt;module&gt;child-core&lt;&#x2F;module&gt;</span><br><span class="line">&lt;&#x2F;modules&gt;</span><br></pre></td></tr></table></figure>

<p>​    子模块child-interface</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">  &lt;parent&gt;</span><br><span class="line">      &lt;groupId&gt;com.aa&lt;&#x2F;groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;parent-bos&lt;&#x2F;artifactId&gt;</span><br><span class="line">      &lt;version&gt;1.0.2-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">  &lt;&#x2F;parent&gt;</span><br><span class="line">  &lt;artifactId&gt;child-interface&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.0.2-SNAPSHOT&lt;&#x2F;version&gt;</span><br></pre></td></tr></table></figure>

<p>​    子模块child-core</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">&lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line">  &lt;parent&gt;</span><br><span class="line">      &lt;groupId&gt;com.aa&lt;&#x2F;groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;parent-bos&lt;&#x2F;artifactId&gt;</span><br><span class="line">      &lt;version&gt;1.0.2-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">  &lt;&#x2F;parent&gt;</span><br><span class="line">  &lt;artifactId&gt;child-core&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.0.2-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">  &lt;dependency&gt;</span><br><span class="line">      &lt;dependency&gt;</span><br><span class="line">          &lt;groupId&gt;com.aa&lt;&#x2F;groupId&gt;</span><br><span class="line">          &lt;artifactId&gt;child-interface&lt;&#x2F;artifactId&gt;</span><br><span class="line">          &lt;version&gt;1.0.2-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">      &lt;&#x2F;dependency&gt;</span><br><span class="line">  &lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>在父模块pom目录下执行，则会自动把上面看到的版本号统一更新</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mvn -DnewVersion&#x3D;1.0.3-SNAPSHOT -DgenerateBackupPoms&#x3D;false versions:set</span><br></pre></td></tr></table></figure>

<p>相关参数介绍，可参考versions-maven-plugin的官网：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>默认值</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>allowSnapshots</td>
<td>false</td>
<td>是否更新-snapshot快照版</td>
</tr>
<tr>
<td>artifactId</td>
<td>${project.artifactId}</td>
<td>指定artifactId</td>
</tr>
<tr>
<td>generateBackupPoms</td>
<td>true</td>
<td>是否生成备份文件用于回退版本号</td>
</tr>
<tr>
<td>groupId</td>
<td>${project.groupId}</td>
<td>指定groupId</td>
</tr>
<tr>
<td>newVersion</td>
<td></td>
<td>设置的新版本号</td>
</tr>
<tr>
<td>nextSnapshot</td>
<td>false</td>
<td>更新版本号为下一个快照版本号</td>
</tr>
<tr>
<td>oldVersion</td>
<td>${project.version}</td>
<td>指定需要更新的版本号可以使用缺省’*’</td>
</tr>
<tr>
<td>processAllModules</td>
<td>false</td>
<td>是否更新目录下所有模块无论是否声明父子节点</td>
</tr>
<tr>
<td>processDependencies</td>
<td>true</td>
<td>是否更新依赖其的版本号</td>
</tr>
<tr>
<td>processParent</td>
<td>true</td>
<td>是否更新父节点的版本号</td>
</tr>
<tr>
<td>processPlugins</td>
<td>true</td>
<td>是否更新插件中的版本号</td>
</tr>
<tr>
<td>processProject</td>
<td>true</td>
<td>是否更新模块自身的版本号</td>
</tr>
<tr>
<td>removeSnapshot</td>
<td>false</td>
<td>移除snapshot快照版本，使之为release稳定版</td>
</tr>
<tr>
<td>updateMatchingVersions</td>
<td>true</td>
<td>是否更新在子模块中显式指定的匹配版本(如/项目/版本</td>
</tr>
</tbody></table>
<h1 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h1>]]></content>
      <categories>
        <category>工作日常</category>
      </categories>
  </entry>
  <entry>
    <title>《Presto实战》笔记</title>
    <url>/2023/02/13/1_%E3%80%8APresto%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<blockquote>
<p> Presto是一款开源的高效的查询引擎。目前市面上有两款Presto，一个是Prestodb，由Facebook开源维护。一个是Trino（又名Prestosql），由Starburst公司开源维护。其中Presto的核心创始人之前在Facebook研发，19年后离开Facebook，重新fork分支后开发了trino，所以两款Presto的基础思想都类似，为避免歧义，本文分析的是trino，以下Presto均代表Trino。</p>
</blockquote>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在大数据的背景下，数据存储日益增多：关系型，文档型，NoSql，键值对，对象存储。每一种存储都有特定的查询方式，且数据存储在不同的孤岛上。数据分析师想要分析时，往往需要通过ETL过程数据抽取到数据仓库中，这个过程费时费力。而Presto通过众所周知的技术执行分布式查询，包括并行处理，跨集群节点管道执行，多线程执行模型，高效的内存结构和Java字节码生成等技术，实现高性能的联邦查询。</p>
<h1 id="常规概念"><a href="#常规概念" class="headerlink" title="常规概念"></a>常规概念</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>Presto是java程序，且需要至少java11。同时需要python2.6版本以上。启动是需要日志配置，节点配置，jvm配置。添加好数据源之后，run起来即可</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>Presto提供了cli，通过执行对应的presto-cli-xxx-executable.jar即可查询，每一个命令以”;”结束。下载地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget -O presto https://repo.maven.apache.org/maven2/io/prestosql/presto-cli/330/presto-cli-330-executable.jar</span><br></pre></td></tr></table></figure>

<p>java程序可以通过Presto-JDBC驱动连接Presto，下载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://repo.maven.apache.org/maven2/io/prestosql/presto-jdbc/330/presto-jdbc-330.jar</span><br></pre></td></tr></table></figure>

<p>启动Presto后，有一个UI界面，可以查看presto的查询任务运行信息，默认路径是<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
<h2 id="源码本地启动"><a href="#源码本地启动" class="headerlink" title="源码本地启动"></a>源码本地启动</h2><p>git地址：<a href="https://github.com/trinodb/trino" target="_blank" rel="noopener">https://github.com/trinodb/trino</a> 基本问题不大，就是注意一下，低版本中使用了antlr4，这是一个语言识别的工具。不做特殊处理，会导致编译时找不到类，这些类需要通过antlr4生成。在Idea中可以通过安装插件。（注，不要用trino较高的版本，比如强制要求jdk17及以上的版本，会存在SA无法加载的情况）</p>
<p><img src="/2023/02/13/1_%E3%80%8APresto%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0/image1.png" alt="image-20220625171540368" loading="lazy"></p>
<p>启动时，按照官网的执行顺序</p>
<ol>
<li>先编译一下，编译前记得启动docker！</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;mvnw clean install -DskipTests</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>启动devService</li>
</ol>
<blockquote>
<p>Trino comes with sample configuration that should work out-of-the-box for development. Use the following options to create a run configuration:</p>
</blockquote>
<blockquote>
<p>Main Class: io.trino.server.DevelopmentServer<br>VM Options: -ea -Dconfig=etc/config.properties -Dlog.levels-file=etc/log.properties -Djdk.attach.allowAttachSelf=true<br>Working directory: $MODULE_DIR$<br>Use classpath of module: trino-server-dev</p>
</blockquote>
<ol start="3">
<li>由于maven仓库于2020年不支持http://repo1.maven.org/maven2和http://repo.maven.apache.org/maven2/（详见：<a href="https://links.sonatype.com/central/501-https-required" target="_blank" rel="noopener">https://links.sonatype.com/central/501-https-required</a> ，且maven-compat:3.0.4默认的远程respority是http开头，所以无法正常启动，因此，为了本地能正常启动，修改了parent的pom文件，在根目录的pom.xml中增加以下配置</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.airlift<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>airbase<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>134<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.trino<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>trino-root<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>412<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">		//省略...</span><br><span class="line"></span><br><span class="line">		<span class="comment">&lt;!-- 手动指定maven的仓库地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>Central Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repo.maven.apache.org/maven2<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">layout</span>&gt;</span>default<span class="tag">&lt;/<span class="name">layout</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>在根目录执行启动命令行连接，client/trino-cli/target/trino-cli-*-executable.jar</p>
</li>
<li><p>导入数据，需要通过java命令行打开jar时，使用batch mode导入</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  trino git:(my_study) ✗ java -jar client/trino-cli/target/trino-cli-*-executable.jar -f iris-data-set/iris-data-set.sql</span><br><span class="line">USE</span><br><span class="line">CREATE TABLE</span><br><span class="line">INSERT: 150 rows</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>查看导入数据</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➜  trino git:(my_study) ✗ java -jar client/trino-cli/target/trino-cli-*-executable.jar</span><br><span class="line">trino&gt; select * from memory.default.iris;</span><br><span class="line"> sepal_length_cm | sepal_width_cm | petal_length_cm | petal_width_cm |  species</span><br><span class="line">-----------------+----------------+-----------------+----------------+------------</span><br><span class="line">             5.1 |            3.5 |             1.4 |            0.2 | setosa</span><br><span class="line">             4.9 |            3.0 |             1.4 |            0.2 | setosa</span><br><span class="line">             4.7 |            3.2 |             1.3 |            0.2 | setosa</span><br></pre></td></tr></table></figure>





<h1 id="深入理解Presto"><a href="#深入理解Presto" class="headerlink" title="深入理解Presto"></a>深入理解Presto</h1><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Presto是一个分布式SQL查询引擎，类似于大规模并行处理MPP（Massively parallel processing），通过分配处理任务来实现横向扩展提高强大的处理能力。包含协调器和工作节点的架构图如下</p>
<p><img src="/2023/02/13/1_%E3%80%8APresto%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0/image2.png" alt="image-202206251715403" loading="lazy"></p>
<ul>
<li>协调器</li>
</ul>
<p>协调器负责<strong>接收用户Sql请求</strong>，<strong>解析查询语句</strong>，<strong>规划查询执行</strong>并<strong>管理工作节点</strong>，是Presto的大脑，客户端直接连接的就是它。一旦接收到一条Sql语句，协调器负责解析、分析、优化和调度查询任务。查询语句会被翻译成一系列的任务（task），任务被分发到各个工作节点执行，工作节点处理数据的同时，协调器会将结果抽取出来放到缓冲区。一旦客户端读完缓冲区的内容，迭代器会代表客户端想工作节点请求更多数据，工作节点也不断从数据源交互读取数据，直至查询结束。</p>
<ul>
<li>节点发现服务</li>
</ul>
<p>每一个Presto实例启动时会注册到发现服务并定期发送心跳信号。为了简化部署，<strong>Presto协调器通常会运行一个内嵌版节点发现服务</strong>，因此工作节点将发现服务的配置指想协调器的主机名和端口</p>
<ul>
<li>工作节点</li>
</ul>
<p>工作节点使用连接器从数据源获取数据，它们之间也会交换中间数据。 工作节点会在启动时将自己注册到节点发现服务。</p>
<blockquote>
<p> 上述节点通信均以HTTP格式</p>
</blockquote>
<h2 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h2><h3 id="基于连接器的架构"><a href="#基于连接器的架构" class="headerlink" title="基于连接器的架构"></a>基于连接器的架构</h3><p>Presto提供了服务提供者接口（SPI），连接器实现API的三部分：</p>
<ol>
<li>获取表、视图、schema元数据的操作</li>
<li>产生数据分区的逻辑单元的操作，用于Presto的并行读写</li>
<li>在源数据和查询引擎所需的内存数据格式</li>
</ol>
<h3 id="执行模型"><a href="#执行模型" class="headerlink" title="执行模型"></a>执行模型</h3><p>Sql语句以文本的形式提交到协调器，协调器解析和分析这条语句，之后创建一个由Presto内部数据结构表示的执行计划，叫做<strong>查询计划</strong>。利用源数据SPI和数据统计SPI创建查询计划，协调器会通过SPI直接连接到数据源，收集有关表和其他源数据的信息</p>
<p><img src="/2023/02/13/1_%E3%80%8APresto%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0/image3.png" alt="image-202206251715403" loading="lazy"></p>
<ul>
<li>元数据SPI</li>
</ul>
<p>可以获取表、列和数据结构信息</p>
<ul>
<li>统计SPI</li>
</ul>
<p>获取行数和表大小信息，从而在计划期间进行基于代价的查询优化。</p>
<h3 id="查询计划解析"><a href="#查询计划解析" class="headerlink" title="查询计划解析"></a>查询计划解析</h3><ol>
<li>协调器将查询计划切分成Stage，从而分配给集群中的多个工作节点进行并行处理，Stage的数量依赖于查询的复杂度。分布式查询计划定义了Stage和查询方式</li>
<li>协调器使用它在工作节点上进一步计划和调度任务，一个Stage通常包含一个或多个任务，每个任务负责处理一小部分任务</li>
<li>源Stage的任务以page的形式生产数据，每个page都是以列式存储格式标识一系列行，这些page传输到下流的中间Stage，Exchange算子从上游Stage中读取数据，从而在不同的Stage之间传输page。</li>
<li>任务运行时分配给一个工作节点的计划片段，在任务创建之后，它会为每个切面初始化一个驱动。每个驱动都是包含多个算子的<strong>流水线</strong>的一个实例，并且负责处理切片的数据。<strong>算子</strong>处理数据并为下游算子生产输出数据，最后一个算子会将输出的page放置在任务的输出缓冲区中。</li>
</ol>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>要处理一条查询，协调器首先根据来自连接器的元数据创建切片列表。使用该切片列表，协调器开始在工作节点上调度任务，获取其中的数据。在查询执行期间，协调器跟踪所有可用的切片和工作节点上执行的位置。一旦任务完成了处理，并产生了很多供下游处理的切片，协调器会继续调度更多任务处理他们，直到没有待处理的切片</p>
<h2 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h2><ol>
<li>解析分析</li>
</ol>
<p>识别查询用的表</p>
<p>识别用到的列</p>
<p>识别ROW值中的字段引用（如c.bound）</p>
<ol start="2">
<li>初始化查询计划</li>
</ol>
<h2 id="优化规则"><a href="#优化规则" class="headerlink" title="优化规则"></a>优化规则</h2><h3 id="谓词下推"><a href="#谓词下推" class="headerlink" title="谓词下推"></a>谓词下推</h3><p>最简单和最重要的规则，这一规则将过滤条件移动到尽可能接近数据源的位置，因此数据量在查询开始后尽可能的缩减。这一规则是将Filter算子的一部分条件保留在新Filter算子中，另一部分和下层的CrossJoin算子合并成新的InnerJoin算子。</p>
<p>优化前：</p>
<p>– Filter [c.nationkey = n.nationkey AND c.custkey = o.custkey]</p>
<p>​    – CrossJoin</p>
<p>​        – CrossJoin</p>
<p>优化后：</p>
<p>– Filter[c.nationkey = n.nationkey]</p>
<p>​    – InnerJoin[o.custkey = c.custkey]</p>
<p>​        – CrosJoin</p>
<h3 id="Cross-Join消除"><a href="#Cross-Join消除" class="headerlink" title="Cross Join消除"></a>Cross Join消除</h3><p>CrossJoin是（表没有Join条件的笛卡尔积），在绝大数实际场景下，我们不希望产生Cross Join。</p>
<p>优化前：</p>
<p>– Filter[c.nationkey = n.nationkey]</p>
<p>​    – InnerJoin[o.custkey = c.custkey]</p>
<p>​        – CrosJoin</p>
<p>优化后：</p>
<p>– InnerJoin[c.custkey = o.custkey]</p>
<p>​    – InnerJoin[n.nationkey = c.nationkey]</p>
<h3 id="TopN"><a href="#TopN" class="headerlink" title="TopN"></a>TopN</h3><p>通常，如果一个查询有limit语句，那么它之前会有一个order  by语句，常规方式，计算复杂度是O(行数* log(行数))，空间复杂度是O(行数)，因此有一个优化规则将order by 紧跟着limit会合并成TopN计划节点，在查询执行时，TopN节点在堆中维护所需行数的结果，以流处理的方式读取输入数据并更新堆。这样计算复杂度简化为O(行数* log(limit))，空间复杂度为O(limit)。</p>
<h3 id="局部聚合"><a href="#局部聚合" class="headerlink" title="局部聚合"></a>局部聚合</h3><p>也就是预聚合，通过预聚合，减少经由下游join的数据量。预聚合不一定总能提高性能，因此优化规划目前默认是禁用的，可以通过push_partial_aggregation_through_join来激活。</p>
<h3 id="Lateral-Join-去关联化"><a href="#Lateral-Join-去关联化" class="headerlink" title="Lateral-Join 去关联化"></a>Lateral-Join 去关联化</h3><p>Lateral（侧面）连接，是一种常见的join关联，在其他的组件中均有体现。例如，PostgreSQL，hive，flink。Lateral-Join相当于以nation作为外层表，region作为内层表，每获取外层表的每一行，对应查询内层表遍历查询。mysql 8同样支持Lateral派生表，最主要的使用场景就是【如何查找每个部门中薪水最高的 Top 5 和对应的员工】，mysql语句如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">	d.department_name,</span><br><span class="line">	t.first_name,</span><br><span class="line">	t.last_name,</span><br><span class="line">	t.salaryFROM departments dLEFT</span><br><span class="line">	<span class="keyword">JOIN</span> <span class="keyword">LATERAL</span> (</span><br><span class="line">	<span class="keyword">SELECT</span></span><br><span class="line">		e.department_id,</span><br><span class="line">		e.first_name,</span><br><span class="line">		e.last_name,</span><br><span class="line">		e.salaryFROM employees eWHERE e.department_id = d.department_idORDER <span class="keyword">BY</span> e.salary <span class="keyword">DESC</span> </span><br><span class="line">		<span class="keyword">LIMIT</span> <span class="number">5</span> </span><br><span class="line">	) tON d.department_id = t.department_id </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span></span><br><span class="line">	d.department_name,</span><br><span class="line">	t.salary <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<p>Presto，对于如下sql：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">	(<span class="keyword">select</span> <span class="keyword">name</span> <span class="keyword">from</span> region r <span class="keyword">where</span> regionkey = n.regionkey)</span><br><span class="line">		<span class="keyword">as</span> region_name,</span><br><span class="line">	n.name <span class="keyword">as</span> nation_name</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">	nation n</span><br></pre></td></tr></table></figure>

<p>会变换成</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">	r.name <span class="keyword">as</span> region_name,</span><br><span class="line">	n.name <span class="keyword">as</span> nation_name</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">	nation n <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> region r <span class="keyword">on</span> regionkey = n.regionkey</span><br></pre></td></tr></table></figure>

<p>同时，为了维持【相同regionkey的重复条目会执行失败】，Presto在join之外还会进行额外查询，如果检测出重复行，则查询失败。</p>
<blockquote>
<p> 子查询1</p>
</blockquote>
<h3 id="Semi-Join-去关联化"><a href="#Semi-Join-去关联化" class="headerlink" title="Semi-Join 去关联化"></a>Semi-Join 去关联化</h3><p>上面是处理Select的子查询，in之中同样存在子查询，和Lateral Join一样，同样可以通过循环外部查询行并多次调用子查询来实现。Presto会通过去除关联条件，将外部查询join一起，确保join不会重复返回结果行。</p>
<blockquote>
<p>子查询2</p>
</blockquote>
<h2 id="基于代价的优化器"><a href="#基于代价的优化器" class="headerlink" title="基于代价的优化器"></a>基于代价的优化器</h2><ul>
<li>代价的概念</li>
</ul>
<p>无论在单查询还是并发查询任务中，<strong>CPU时间</strong>、内存需求和<strong>网络带宽</strong>的使用都是构成查询执行的三个维度，这构成了Presto的代价</p>
<ul>
<li>Join的代价</li>
</ul>
<p>使用=join两个表时，Presto实现HashJoin的扩展版算法。其中一个表称为<strong>构建侧</strong>，这个表的内容以Join条件使用的列作为键，构成一个散列查询表。另一个表称为<strong>探测侧</strong>，一旦散列查询表构建完成，就会使用探测表行去构建侧的散列表中匹配行，默认情况下，Presto会使用三层散列以尽可能并行处理：</p>
<ol>
<li>基于Join条件列的散列值将两个Join的表的内容分配到各个工作节点。应该匹配在一起的行具有相同的join条件列，因此也会分配到同一个节点。</li>
<li>在节点级别，构建侧进一步使用散列函数将任务分散到多个工作线程。多线程提高吞吐量。</li>
<li>每个工作线程最后给出最后给出完成散列查询表的一个分区，每个分区合并会形成第二层查询散列表，因此我们通过将探测侧处理也分散到多个线程。</li>
</ol>
<p>为了控制Join的内存开销，哪张表会成为构建表由CBO选择，为达到这一目的，CBO需要了解Join表的大小，这些数据由表统计信息提供。</p>
<h3 id="表统计信息"><a href="#表统计信息" class="headerlink" title="表统计信息"></a>表统计信息</h3><p>表统计信息由连接器提供，包括：</p>
<ol>
<li>表中行的数量</li>
<li>列中不同值的数量（基数）</li>
<li>列中NULL值所占比例</li>
<li>列的最大值，最小值</li>
<li>列平均数据大小</li>
<li>…</li>
</ol>
<h3 id="Join方式"><a href="#Join方式" class="headerlink" title="Join方式"></a>Join方式</h3><ul>
<li>广播式（broadcast）</li>
</ul>
<p>构建侧广播到并行执行的Join的所有工作节点。在构建侧数据较小，或者探测侧数据较大时效果明显。</p>
<ul>
<li>分布式（Hash）</li>
</ul>
<p>数据根据分区算法重分布，通过某种分区算法，将匹配的Join键值发送到同一节点。在两边数据量均很大，而一台机器无法保存构建侧全部数据时，效果明显。</p>
<h3 id="使用表统计信息"><a href="#使用表统计信息" class="headerlink" title="使用表统计信息"></a>使用表统计信息</h3><p>截止目前，明确Hive连接器提供了表统计信息，其他数据源对应连接器并未找到相关文档支持。接口为：io.trino.spi.connector.ConnectorMetadata#getTableStatistics</p>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>每个查询都被翻译为分布式查询计划，查询计划由任务组成的多个Stage构成，数据以切片形式由连接器返回，并在多个Stage中执行，直到最终结果可用并由协调器提供给用户。</p>
<h1 id="论文知识点"><a href="#论文知识点" class="headerlink" title="论文知识点"></a>论文知识点</h1><blockquote>
<p>论文连接：<a href="https://trino.io/Presto_SQL_on_Everything.pdf" target="_blank" rel="noopener">https://trino.io/Presto_SQL_on_Everything.pdf</a></p>
</blockquote>
<h2 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h2><p>可选配置，常规内存池、预留内存池。当查询超过常规内存池时，可以将查询中最耗费内存的一个查询转移到预留内存池，如果内存池和预留内存池都慢了，则该节点上的所有查询均被暂停。预留内存池需要有足够的查询，这样配置起来有点浪费，可以不配置预留内存池，使用集群杀死大部分查询。</p>
<h2 id="失败容忍"><a href="#失败容忍" class="headerlink" title="失败容忍"></a>失败容忍</h2><p>Presto<strong>没有</strong>内置失败重试策略，协调器失败会导致集群不可用，工作节点失败会导致该节点的所有查询失败。</p>
<h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><p>选择Jvm的G1垃圾回收器，同时避免大内存的对象分配</p>
<h2 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h2><ul>
<li>表达式计算</li>
</ul>
<p>为了加快生产计算速度，Presto使用字节码生成处理本地变量，函数调用，变量引用，惰性短路操作。</p>
<ul>
<li>JIT启发式优化</li>
</ul>
<p>为几个关键运算和运算组合运算生成字节码，生成器利用上级知识生成比一般循环更易于优化的字节码</p>
<blockquote>
<p>字节码生成提高了将中间结果存储在寄存器或缓存中而不是内存中的能力</p>
</blockquote>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h2><ul>
<li>生产部署配置</li>
<li>连接器介绍，Hive连接器最为完善，因为是主要就是接入Hive数据源</li>
<li>常用Sql命令</li>
<li>高级Sql特效（函数，表达式）</li>
</ul>
<blockquote>
<p>内容太多，详情请参考官网文档：<a href="https://trino.io/docs/current/" target="_blank" rel="noopener">https://trino.io/docs/current/</a></p>
</blockquote>
<h2 id="Presto实际应用"><a href="#Presto实际应用" class="headerlink" title="Presto实际应用"></a>Presto实际应用</h2><h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><ul>
<li>Ldap</li>
<li>Kerberos</li>
</ul>
<h3 id="与其他工具集成"><a href="#与其他工具集成" class="headerlink" title="与其他工具集成"></a>与其他工具集成</h3><ul>
<li>集成Superset</li>
<li>RubiX缓存框架提高性能</li>
</ul>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《java多线程编程实战指南》笔记</title>
    <url>/2022/01/06/1_%E3%80%8Ajava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<h1 id="并发简史"><a href="#并发简史" class="headerlink" title="并发简史"></a>并发简史</h1><ul>
<li>为什么需要多个程序同时进行呢：<ul>
<li>资源利用率，程序会等待某个外部操作完成，等待时程序无法执行其他工作</li>
<li>公平性，不同用户和程序对计算机上资源有同等使用权。可以利用粗粒度的时间分片使这些用户和程序共享一个资源。</li>
<li>便利性，通常情况下，在计算多个任务时，应该编写多个程序。</li>
</ul>
</li>
</ul>
<p>线程是轻量级进程，同一个进程的多个线程都将共享进程的内存空间，这就需要一种比进程间共享数据更细粒度的数据共享机制。</p>
<ul>
<li>线程的优势<ul>
<li>发挥多处理器的能力</li>
<li>建模的简单性</li>
</ul>
</li>
</ul>
<p>如果程序中只包含同一种类型的任务，比包含不同类型的任务更易于编写。通过线程，可以将复杂并且异步的工作流进一步分解为一组简单并且同步的工作流，每一个工作流在一个单独的线程中运行，并在特定的同步位置进行交互。</p>
<ul>
<li>异步事件的简化处理</li>
</ul>
<p>线程带来的风险</p>
<ul>
<li>安全性问题</li>
</ul>
<p>因为指令重排，可能导致执行过程和想象中的不一样，导致执行的结果不可预期。</p>
<ul>
<li>活跃性问题</li>
</ul>
<p>某件重要的事情最终会发生，常见的问题如死锁，饥饿或活锁。</p>
<ul>
<li>性能问题</li>
</ul>
<p>线程总会带来额外开销，上下文切换，保存和恢复上下文，当线程共享数据时，必须使用同步机制，这些机制往往会抑制某些编译器的优化。</p>
<h1 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h1><p>良好的面向对象设计技术，有助于编写结构优雅，可维护性高的类，访问某一个变量的代码越少，越容易确保对变量的所有访问实现正确的同步。<br>在任何情况下，只有当类中仅包含自己的状态时，线程安全类才是有意义的。线程安全性只是一个代码上使用的术语，但它只与状态相关，因此只能应用于封装某状态的整个代码，可能是一个对象，也可能是一个程序。</p>
<ul>
<li>线程安全性</li>
</ul>
<p>某个类的行为与其规范完全一致，在良好的规范中通常会定义各种不变性条件来约束对象的状态，以及定义后验条件来描述对象操作的结果。</p>
<ul>
<li>原子性</li>
</ul>
<p>判断操作是否原子的，例如自增操作，一般包含【读取-修改-写入】，这种操作属于复合操作。<br>当某个计算的正确性取决与多个线程交替执行时序时，就会发生竞态条件，最常见的竞态类型就是【先检查后执行】。例如延迟初始化的竞态条件。注意【数据竞争】。</p>
<ul>
<li>加锁机制</li>
</ul>
<p>添加足够多的线程安全的状态变量（例如AtomicInteger）并不能够确保程序是线程安全的</p>
<ul>
<li>内置锁，同步代码块，同步代码块的锁为该方法的对象。</li>
<li>重入，非重入【当线程请求一个由某个线程持有的锁时，发出的请求就会被阻塞】。重入意味着获取锁的操作是”线程”而不是”调用”。<ul>
<li>用锁来保护状态</li>
</ul>
</li>
</ul>
<p>当用锁来保护变量时，所有访问该变量的位置都需要同步。常见的加锁约定是，把所有可变的状态封装在对象内部，并通过对象的内置锁对所有可变状态的代码路径进行同步。这种方法比较low，但比较实用。<br>当类的不变性涉及多个状态变量时，不变性的每个状态变量都需要由同一个锁来保护。</p>
<ul>
<li>活跃性和性能</li>
</ul>
<p>尽管利用锁机制可以保证正确性，但性能很差，确保同步代码足够短，无需加锁的地方不加锁。当执行时间足够长，或者可能无法快速完成的操作，如（网络IO时），不要持有锁。</p>
<h1 id="对象的共享"><a href="#对象的共享" class="headerlink" title="对象的共享"></a>对象的共享</h1><ul>
<li>可见性</li>
</ul>
<p>在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。当缺乏有效同步时，会读取到失效数据，并且，只对set进行同步是不够的，对get也需要同步。<br>一般情况，java对变量的读取和写入都是原子操作，但是对于<strong>非volatile的long和double</strong>，jvm允许将64位的读写操作分解位32位的，此时会发生数据失效问题。<br>加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作都必须在同一个锁上同步</p>
<ul>
<li>volatile</li>
</ul>
<p>是一种轻量的锁，从内存可见性的角度上来讲，写入volatile相当于退出同步代码块，读取volatile相当于进入同步代码块。<br><strong>使用条件</strong>，对变量的写入不依赖变量的当前值，或者能保证只有单个线程更新当前值；该变量不会与其他状态变量一起纳入不变性条件；在访问变量时不需要加锁。</p>
<ul>
<li>逸出</li>
</ul>
<p>发布的意思是指使对象能够在当前的作用域之外使用。例如将对象的引用保存在一个公有的静态变量中，以便任何类和线程都能看到该对象。<br>利用匿名内部类时也可能会逸出当前对象，并且在构造函数中发布对象时，只是发布了一个尚未构造完成的对象。构造函数形如：<br><img src="https://cdn.nlark.com/yuque/0/2021/png/406465/1617270767983-1c5a4618-8b32-4651-97dc-9678c8dcec6a.png" alt="image.png" loading="lazy"><br>需要确保构造函数结束后，this引用才可以被其他线程使用。</p>
<ul>
<li>不变性<ul>
<li>ad hoc线程封</li>
</ul>
</li>
</ul>
<p>ad hoc线程封闭是指维护线程封闭性的职责完全由程序实现来承担。ad hoc本意在拉丁文中是“为了这个目的”，或者“仅仅如此”。</p>
<ul>
<li>栈封闭</li>
</ul>
<p>在栈封闭中，只有通过局部变量才能访问变量。局部变量的固有属性之一就是封闭在执行线程中。</p>
<ul>
<li>ThreadLocal</li>
</ul>
<p>推荐做法，本质上相当于一个Map，key是线程id，value中有很多全局变量。使用时需要注意不要有过多耦合。</p>
<ul>
<li>不变性对象</li>
</ul>
<p>不变对象的特点是状态不变。需满足以下三个特点：对象创建后其状态不能变更，对象所有域都是final类型，对象是正确创建的（没有在构造函数this逸出）。一般搭配volatile和final对象结合使用，保证线程安全</p>
<ul>
<li>安全发布</li>
</ul>
<p>导致的结果，除了发布的线程，其他线程看到的可能是失效值。由于指令重排原因，就算是在构造函数中，也会存在其他线程访问到默认值。（这一段是理论问题，没找到实际出问题的代码）<br>常用的安全发布方式：在静态初始化函数中初始化一个对象引用（例如：public static Hoder holder = new Holder(42)）静态初始化器由jvm进行加锁控制；将对象引用保存在volatile类型的域中；将对象的引用保存在某个正确发布的对象的final域中；将对象的引用保存在一个由锁保护的域中（例如线程安全容器，Vector，CopyOnWriteXXX，synchorizedXX，BlockQueue）<br>安全的使用对象，当发布一个对象时，需要明确对象的访问方式。<br><strong>常用策略</strong></p>
<ol>
<li>线程封闭，对象封闭在当前线程，只能由当前线程修改</li>
<li>只读共享，多个线程并发访问，在没有额外同步情况下，任何线程线程不能修改。</li>
<li>线程安全共享，线程安全对象内部实现同步，多个线程可以通过公有方法进行访问</li>
<li>保护对象，被保护的对象必须通过锁访问。</li>
</ol>
<h1 id="对象的组合"><a href="#对象的组合" class="headerlink" title="对象的组合"></a>对象的组合</h1><p>关注3个基本要素</p>
<ol>
<li>找出构成对象状态的所有变量。对象域取决于对象内变量的所有域</li>
<li>找出约束状态变量的不变性条件。</li>
<li>建立对象状态的并发访问管理策略。</li>
</ol>
<p>考虑依赖状态的操作，复合状态，讲多个状态封闭在同一个对象中，可以利用对象自身的锁<br>将数据封装在对象的内部，可以将数据访问限制在对象的方法上，从而确保线程访问时能够正确的持有锁</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title>《数据密集型应用系统设计》笔记</title>
    <url>/2022/07/02/1_%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">



<h1 id="数据系统介绍"><a href="#数据系统介绍" class="headerlink" title="数据系统介绍"></a>数据系统介绍</h1><blockquote>
<p>当今许多新型应用都数据数据密集型，而非计算密集型，数据量、数据复杂度及数据的快速多变是限制系统发展的因素。</p>
</blockquote>
<p>许多应用系统包含以下模块：</p>
<ol>
<li><p>数据库：存储数据，以便下次访问</p>
</li>
<li><p>高速缓存：缓存复杂或代价高的结果，加速访问</p>
</li>
<li><p>索引：用户根据关键字搜索并支持过滤</p>
</li>
<li><p>流式处理：异步持续发送消息至另一个进程</p>
</li>
<li><p>批处理：定期处理大量累计数据</p>
</li>
</ol>
<h2 id="认识数据系统"><a href="#认识数据系统" class="headerlink" title="认识数据系统"></a>认识数据系统</h2><p>今年来许多用于数据存储和处理的工具，它们针对不同应用场景进行优化。Redis既可以用于数据存储也适用预消息队列，Kafka作为消息队列也提供了持久化存储保证。<strong>系统之间的接线正在变得模糊</strong>。越来越多的应用系统需求广泛，单个组件往往无法满足所有数据处理与存储需求。常常多个组件依靠应用层代码驱动有机衔接。例如，包含缓存和全文检索服务器，二者与数据库保持关联，通常由应用系统负责三者之间同步。</p>
<h2 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h2><p>一般期望软件满足：</p>
<ol>
<li><p>应用系统执行用户期望的功能</p>
</li>
<li><p>可以容忍用户出现错误或不正确的软件使用方式</p>
</li>
<li><p>性能可以应对典型场景，合理负载应用和数据量</p>
</li>
<li><p>系统可以防止任何未经授权的访问和滥用</p>
</li>
</ol>
<p>可能出错的事情称为错误（faults）或故障，系统可以应对错误则称为容错（fault-tolerant）或者弹性（resilient）。失效意味着系统作为一个整体停止，无法向用户提供所需的服务。通常，我们不太可能将故障概率降低到0，因此通常设计容错机制避免从故障引发系统失效。</p>
<h3 id="硬件故障"><a href="#硬件故障" class="headerlink" title="硬件故障"></a>硬件故障</h3><p>常见的故障有很多，比如磁盘崩溃，内存故障，停电，断网。通常来说，当磁盘集群数量过高时，总会有一个磁盘发生故障。常见反应是增加硬件冗余，当一个组件发生故障时，冗余组件可以快速接管。</p>
<p>在云平台的背景下，数据量和应用计算需求增加，系统强调总体灵活性和弹性，而非单台机器的可靠性，硬件故障也需要软件容错来做兜底补偿。</p>
<h3 id="软件错误"><a href="#软件错误" class="headerlink" title="软件错误"></a>软件错误</h3><p>一般硬件故障之间是独立的，但软件是跨域多个节点，软件故障会导致更多的系统故障。软件故障可能长时间无法发现，只在特定的时间爆发，比如，2012年6月30号的闰秒；应用共享了cpu，但失控了等。软件故障只能进行全面测试，允许进程崩溃重启，等前期预防。</p>
<h2 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h2><p>可扩展性是用来描述系统应对负载增加能力的术语。</p>
<h3 id="描述负载"><a href="#描述负载" class="headerlink" title="描述负载"></a>描述负载</h3><p>负载可以用称为负载参数的若干数字赖描述，可以是没秒处理次数，数据库写入比例，缓存命中率等。</p>
<h3 id="描述性能"><a href="#描述性能" class="headerlink" title="描述性能"></a>描述性能</h3><p>在批处理系统中，我们通常关注吞吐量（throughtput），即每秒可处理的记录次数，或者某指定数据集上运行作业所需的总时间。</p>
<p>在线系统通常更看中服务的响应时间（response time），即客户端从发送请求到接收响应之间的间隔。</p>
<blockquote>
<p>延迟一般表示请求花费在处理上的时间，而响应时间处理处理时间还包括网络延迟、排队延迟等。</p>
</blockquote>
<h3 id="应对负载增加的方法"><a href="#应对负载增加的方法" class="headerlink" title="应对负载增加的方法"></a>应对负载增加的方法</h3><p>无状态服务分布然后扩展至多台机器相对比较容易。对于特定应用来说，扩展能力好的架构通常会做出某些假设，然后有针对性地优化设计，如哪些操作是最频繁的，哪些负载是少数情况。</p>
<h2 id="可维护性"><a href="#可维护性" class="headerlink" title="可维护性"></a>可维护性</h2><blockquote>
<p>因为众所周知的原因，软件大部分成本不在于最初的开发阶段，而在于整个生命周期内持续的投入，如维护与缺陷，监控系统，技术缺陷等。</p>
</blockquote>
<p>三个设计原则：</p>
<ol>
<li>可维护性，方便运营团队赖保持系统平稳运行</li>
<li>简单性，简化系统复杂性，使新工程师能够轻松理解系统。</li>
<li>可演化性，后续工程师能够轻松对系统进行改进，根据需求变化将其适配到非典型场景</li>
</ol>
<h3 id="运营轻松"><a href="#运营轻松" class="headerlink" title="运营轻松"></a>运营轻松</h3><p>运营团队可以监控系统健康状况。追踪问题原因，例如系统故障或性能下降。建立部署使用的工具包。指定流程规范操作行为</p>
<p>高价值的贡献：提供系统运行时行为。内部可观测性，避免绑定特定机器，以便允许停机维护。提供良好的默认配置。尝试自我修复，允许手动控制系统状态。</p>
<h3 id="简化复杂性"><a href="#简化复杂性" class="headerlink" title="简化复杂性"></a>简化复杂性</h3><p>复杂性有各种各样的表现方式：状态空间的膨胀，模块紧耦合，令人纠结的相互依赖关系，不一致的命名和术语，为了性能而采取的特殊处理，为解决某特定问题而引入的特殊框架等。</p>
<p>简化系统设计并不意味着减少系统功能，而是主要意味着消除意外方面的复杂性。消除意外复杂性最好手段之一是抽象。比如高级编程语言作为一种抽象，可以屏蔽机器汇编代码、CPU寄存器和系统调用等细节和复杂性。抽象还是很有挑战性。</p>
<h3 id="易于改变"><a href="#易于改变" class="headerlink" title="易于改变"></a>易于改变</h3><p>毋庸置疑，系统需求经常随着想法和目标在不断变化。在流程方面，敏捷开发模式为适应改变提供了很好的帮助。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>一个应用必须完成预期的多重需求，主要包括功能性需求和非功能性需求，这里主要探讨非功能性需求，可靠性，可扩展性，可维护性。</p>
<p>可靠性意味着即使发生故障，系统人可以工作</p>
<p>可扩展性指负载增加时，有效保证系统性能的相关技术策略</p>
<p>可维护性本质是让工程和运营团队更为轻松</p>
<h1 id="数据模型与查询语言"><a href="#数据模型与查询语言" class="headerlink" title="数据模型与查询语言"></a>数据模型与查询语言</h1><blockquote>
<p>大多数应用程序是通过一层一层叠加数据模型赖构建的。复杂的应用程序可能会有更多的中间层，每层都通过一个简洁的数据模型来隐藏下层的复杂性</p>
</blockquote>
<h2 id="关系模型与文档模型"><a href="#关系模型与文档模型" class="headerlink" title="关系模型与文档模型"></a>关系模型与文档模型</h2><p>1970年 Edgar Codd提供关系模型理论。1980后，RDBMS和SQL已经称为大多数存储的首选。70-80年代，网络模型和层次模型也是一个选择，但80年代后，关系模型主宰了这一个领域。</p>
<h3 id="NoSql的诞生"><a href="#NoSql的诞生" class="headerlink" title="NoSql的诞生"></a>NoSql的诞生</h3><p>严格来说，NoSql最初只是2009年非关系型数据库见面会上的一个标签。可以理解为”not only Sql”或者”no-relationSQL”，没有严格定义。采用NoSql有几个驱动因素：</p>
<ul>
<li>比关系数据库有更好的扩展需求，支持超大数据集或超高写入吞吐量</li>
<li>普遍偏爱免费喝开源软件</li>
<li>关系模型不能很好支持一些特定的查询操作</li>
<li>关系模式的限制，渴望更具动态和表达力的数据模型</li>
</ul>
<h3 id="对象-关系不匹配"><a href="#对象-关系不匹配" class="headerlink" title="对象-关系不匹配"></a>对象-关系不匹配</h3><p>也有说法叫做<strong>对象关系阻抗</strong>、<strong>阻抗失谐</strong>，因为应用开发普遍采用面向对象的编程语言，对象模型与关系模型需要一层转换层。  </p>
<h3 id="多对一与多对多关系"><a href="#多对一与多对多关系" class="headerlink" title="多对一与多对多关系"></a>多对一与多对多关系</h3><p>为了消除重复，数据库规范化定义了许多范式。为了支持多对一及多对多关系，关系型数据库用联结来表达这种关系，如果数据库本身不支持联结，则需要由应用程序来完成。</p>
<h3 id="文档模型的历史发展"><a href="#文档模型的历史发展" class="headerlink" title="文档模型的历史发展"></a>文档模型的历史发展</h3><p>在20世纪70年代，IMS使用了层次模型，也是从根节点触发，把相关的数据都嵌套在记录中，与文档数据库类似，处理一对多关系时，可以很好的表示。但同样无法处理多对多关系。为此展开了一场关系模型与网络模型的争论。</p>
<h4 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h4><p>网络模型是层次模型的特例，每一个记录有多个父节点，因此，同一个数据可以有多个记录指向，完成多对多关联。但带来的弊端是，访问数据必须沿着访问路径从根节点遍历，并且，如果修改访问路径，需要大量手写数据库查询代码。</p>
<h4 id="关系模型"><a href="#关系模型" class="headerlink" title="关系模型"></a>关系模型</h4><p>关系模型定义了数据的格式，关系只是元祖的集合，查询优化器自动决定以何种顺序执行查询，相当于访问路径。最大的好处是，只需要构造一次查询优化器，所有使用该数据库的所有应用都从中受益。</p>
<h4 id="文档数据库的比较"><a href="#文档数据库的比较" class="headerlink" title="文档数据库的比较"></a>文档数据库的比较</h4><p>文档数据库的父记录今保存了嵌套记录（支持了一对多的关系），同时在表达多对多关系时，相关项也保留唯一标识符引用，在文档模型中称为文档引用。</p>
<h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><p>如果应用数据具有类似文档的一对多关系树，那么使用文档模型更为适合，而关系型模型则倾向于某种数据的分解。</p>
<h4 id="文档模型中的模式灵活性"><a href="#文档模型中的模式灵活性" class="headerlink" title="文档模型中的模式灵活性"></a>文档模型中的模式灵活性</h4><p>文档数据有时称为无模式，因为读数据的代码通常采用某种结构，银耳存在某种隐形模式，而不是由数据库强制执行。更准确的说，读时模式（数据结构是隐式的，读取时解析）与写时模式（模式是显式的，并且数据库确保数据写入时必须遵守）相对应。两种方式有利有弊，写时模式升级伴随着字段变更，停机更新（也不全是，可以通过字段兼容的方式）。</p>
<h4 id="查询局部性"><a href="#查询局部性" class="headerlink" title="查询局部性"></a>查询局部性</h4><p>文档模型可以提供查询局部性（如果查询需要包含文档的大部分信息，那文档模型可以减少多次查询），减少磁盘IO。</p>
<h4 id="融合"><a href="#融合" class="headerlink" title="融合"></a>融合</h4><p>大部分关系型数据库如mysql也支持了xml，json。并同时支持xml字段查询。文档数据库如RethinkDB方面，也在探索支持关系型类似的链接，未来可探讨融合发展。</p>
<h2 id="数据查询语言"><a href="#数据查询语言" class="headerlink" title="数据查询语言"></a>数据查询语言</h2><p>声明式查询语言。相比而言，命令式指定了特定的执行顺序，很难在多核和多台机器上并行化。在web浏览器中被广泛应用（CSS样式表）。</p>
<p>MapReduce是一种编程模型，在NoSql中被广泛应用。通过申明多个map和reduce函数，处理数据，比如mongo中，提供了管道式声明查询，像sql的声明时查询靠拢。</p>
<h2 id="图数据模型"><a href="#图数据模型" class="headerlink" title="图数据模型"></a>图数据模型</h2><p>图由两个对象组成：顶点和边。有两种代表建模思想，属性图模型和三元存储模型。Cypher、Sparql和Datalog是常见的三种声明式查询语言。</p>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>关系型数据库作为基础，表示了多对多关系，同时NoSql在两个方向上逐步发力</p>
<ul>
<li>文档数据库的目标用例是数据来自自包含的文档，且文档与其他文档之间关联很少</li>
<li>图数据库则针对相反的场景，目标用例都可能相互关联。</li>
</ul>
<p>每个数据模型都有自己的查询语言，如：SQL、MapReduce，Mongo聚合管道、图数据库查询语言。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title>《微服务系列》笔记</title>
    <url>/2022/01/06/1_%E3%80%8A%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%B3%BB%E5%88%97%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<blockquote>
<p>摘自：Chris Richardson 微服务系列，博客地址：<a href="http://blog.daocloud.io/microservices-1/" target="_blank" rel="noopener">http://blog.daocloud.io/microservices-1/</a></p>
</blockquote>
<h1 id="一、微服务架构概念"><a href="#一、微服务架构概念" class="headerlink" title="一、微服务架构概念"></a>一、微服务架构概念</h1><blockquote>
<p>以一个打车软件为例，描述微服务的架构是因何诞生</p>
</blockquote>
<h2 id="单体应用"><a href="#单体应用" class="headerlink" title="单体应用"></a>单体应用</h2><p>一般的单体应用，应用的核心是商务逻辑，由服务，领域对象和各模块事件组成，依赖各种适配器与外部进行交互，比如，数据库访问组件，web的ui组件和Rest-Api等，框架依赖语言，打包成特定文件（war包），部署在特定服务器上（tomcat），早期，配合ide开发还是比较方便的，应用可以简单的复制，做负载均衡进行扩展</p>
<h2 id="重构困难"><a href="#重构困难" class="headerlink" title="重构困难"></a>重构困难</h2><p>开发方面考虑：随着开发时间的增长，代码库也越来越大，各种包之间的依赖越来越理不清，更加不可能由一个人了解整个项目，最终修复bug和实现新功能就越发耗时，长此以往，代码库越来越难以理解。这种项目最终延迟开发时间，应用越大，启动时间越长，等待时间越长，效率越低。<br>部署方面考虑：复杂的应用想要更新单个部分，也需重新部署整个应用，带来的漫长的等待时间加上全面的测试。<br>安全性考虑：所有模块运行在同一进程中，一旦出现bug，会影响其他模块，导致应用出现bug，可靠性降低。<br>最后，框架重写变得更为艰难，难以大范围的采用新框架。</p>
<h2 id="采用微服务"><a href="#采用微服务" class="headerlink" title="采用微服务"></a>采用微服务</h2><p>一个微服务一般完成某个特定的功能，每个微服务有着自己的商务逻辑和各种接口，有的微服务通过暴露api被其他服务或客户端调用，运行时，每个实例可能是云虚拟机或docker容器。<br>应用的功能由自身的微服务实施，网页应用被拆分成一套简单的网页应用（乘客应用和司机应用），每个后端服务包括一个REST API和由其他服务提供的服务API，这些服务可以用基于消息的异步通信。<br>有的REST API也对乘客和司机的移动应用开放，虽然这些应用不能直接访问后端服务器，但是可以通过名为”Api Gateway”的中间人调节，Api Gateway负责负载均衡、缓存、访问控制、api计费、监控等，通过nginx高效实施。<br>Scale Cube的3D模型显示，x轴表示的是horizontal dumplication，通过负载均衡器后的多个应用实现；y轴表示functional decomposition，通过微服务的架构范式实现；z轴data partitioning，通过数据分割，将需求路由到相关服务。<br>微服务架构范式对应用和数据库的关系影响巨大，每个服务有自身的数据库计划，不与其他服务共享一个数据库，虽然会带来部分数据的重复，但是可以保证松耦合，发挥微服务的作用。</p>
<h2 id="微服务的好处"><a href="#微服务的好处" class="headerlink" title="微服务的好处"></a>微服务的好处</h2><p>第一：首先是解耦，分解巨大的单体应用，在功能不变的情况下，应用被分解成多个可管理的分支或服务，每个服务有用rpc或者消息驱动api定义的边界。<br>第二：还是开发的适用性，每个服务可以由专门的开发团队来开发，可以根据api采用相应的技术，而不拘泥于过时的技术。因为单个服务相对简单，即使用新技术重写，难度也大大的降低。<br>第三：微服务独立部署，可以部署在docker容器或不同虚拟机上，ui可以快速部署测试，也可以持续化部署。<br>第四：可以使得每个服务独立扩展。哪个服务依赖什么，就单独换某个服务或某个服务的环境。</p>
<h2 id="微服务的不足"><a href="#微服务的不足" class="headerlink" title="微服务的不足"></a>微服务的不足</h2><p>第一：微服务过于的小，也影响开发和部署，微服务最终的结果是通过拆分应用实现快速开发和部署。<br>第二：由于微服务是分布式系统，必然会带来开发上的复杂性，开发者需要在RPC或消息传递之间选择并完成进程间的通讯机制，同时还需要写代码处理消息传递过慢或不可用等局部失效的问题。<br>第三：分区的数据库架构。在单体式应用中，同时更新多个业务主题可以依靠数据库来保证原子性。但对于微服务来说，数据库可能多重多样，使用分布式事务并不一定是好的选择，不仅仅因为CAP理论，更由于消息传递中间件和nosql数据库不支持（大概是不支持事务回滚机制），不得不采用最终一致性，从而增加开发的难度。<br>第四：测试基于微服务的应用也比较复杂，测试单个服务，需要启动它有关的所有服务。<br>第五：应用的改变会影响多个服务，可能这些服务之间有依赖关系，A依赖B，B依赖C，在单体应用中，只需修改相关模块，整合变化，部署就好了。但是在微服务中，需要考虑服务的依赖，要先更新C然后是B最后才是A。但是，一般来说，变化一般只影响一个服务。<br>第六：部署麻烦，因为每个服务都可能有自己的数据库和消息中间件等基础服务。这需要大量的配置，监控，同时，还需要一个”服务发现机制”，用来发现与它通讯的服务的地址（包括服务器和端口），部署一个微服务应用需要有足够的控制部署方法，并实现高度自动化。自动化方法之一是采用Cloud Foundry这样的PaaS服务，或者从Mesos或Kubernets集群管理方案入手，配合docker，构建自己的基础PaaS系统。作为软件的应用交付方法，nginx可以方便的在微服务层面提供缓冲，权限、监控等功能。</p>
<h1 id="二、使用Api网关构建微服务"><a href="#二、使用Api网关构建微服务" class="headerlink" title="二、使用Api网关构建微服务"></a><strong>二、使用Api网关构建微服务</strong></h1><blockquote>
<p>从一个问题出发，讲解Api网关搭建的必要性</p>
</blockquote>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>提问微服务会暴露一系列的细粒度的接口，客户端如何与服务端交互？</p>
<p>回答<br>客户端与微服务通信，因为每个服务都有一个公开的端口，该url映射到微服务的负载均衡器，由后者在可用实例上分发请求。<br>分析</p>
<ol>
<li>客户端与每个微服务暴露的api粒度不匹配。再更复杂的应用中，客户端要发送更多的请求，导致客户端通过LAN发送许多请求，在公网上效率低下，移动网根本不行，同时还导致客户端代码复杂。</li>
<li>部分微服务的协议对web不友好，可能有的服务使用二进制RPC，有的可能使用AMQP协议，对浏览器和防火墙不好，尽可能使用HTTP或WebSocket之类的协议。</li>
<li>使得微服务难以重构。随着事件的推移，可能需要拆分服务或合并服务。</li>
</ol>
<p>结论：<strong>不可行</strong></p>
<p>回答<br>构建Api网关。API网关类似于Facade，是进入系统的唯一节点，在服务器端。API网关封装了内部系统架构，提供各个API给客户端。在API网关做服务的合并处理，协议的转换。<br>分析<br>优点：封装了内部结构，减少客户端和服务端交互，简化客户端代码。利用Http协议提供统一接口，屏蔽了不同微服务之间的通信细节。<br>缺点：增加了一个必须的组件，可能成为开发瓶颈。<br>结论：<strong>推荐采用</strong></p>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><ol>
<li>性能考虑，API网关必须搭建在支持异步，I/O非阻塞的平台上，类似于Netty、Spring Reactor。或者node.js，或者Nginx Plus。</li>
<li>响应式编程。对于客户端的部分请求，API网关需要合并请求，并发的执行请求，达到最小化相应时间的目的。但是，有的请求之间存在依赖，比如，请求订单详情必须先查询用户信息。传统的异步回调的方法使代码变得混乱，难以理解且容易出错。</li>
<li>服务调用。基于微服务应用程序是一个分布式系统，需要一种进程间通讯机制。一种是使用异步的，基于消息传递的机制。一种是使用HTTP或Thrift那样的同步机制。</li>
<li>服务发现。在微服务架构中，应用程序的服务位置经常随系统的升级发生变化。</li>
<li>局部失效。当一个服务调用另一个服务时，后者相应慢或不可用时，API网关不能应为无限期的等待下游服务而阻塞。需要根据业务需求做出相应的处理。如果缓存可用。可以考虑利用缓存，减少客户端的体验。</li>
</ol>
<h1 id="三、微服务架构中的进程间通信"><a href="#三、微服务架构中的进程间通信" class="headerlink" title="三、微服务架构中的进程间通信"></a>三、微服务架构中的进程间通信</h1><blockquote>
<p>单体应用中，各模块之间是通过编程语言级别的方法或函数调用的，但是在微服务中，各个服务是基于分布式运行在多台机器上，通常每个服务都是一个进程，服务之间的交互必须通过进程通信（IPC）来实现</p>
</blockquote>
<h2 id="交互模式"><a href="#交互模式" class="headerlink" title="交互模式"></a>交互模式</h2><p>从两个维度归类，第一个维度是一对一还是一对多，一对一是指每个客户端请求有一个服务实例来响应。一对多是指每个客户端请求有多个服务实例来响应。第二个维度是这些交互是同步还是异步的。</p>
<ul>
<li><p>一对一</p>
<ul>
<li>请求/响应，客户端向服务端请求，等待响应，客户端期望即使响应，并在等待中阻塞线程。</li>
<li>通知：客户端请求，但不期望服务端响应。</li>
<li>请求/异步响应，客户端发送请求，服务端异步响应请求，客户端不阻塞，并默认认为响应不会立刻到达。</li>
</ul>
</li>
<li><p>一对多</p>
<ul>
<li>发布/订阅，客户端发布消息，被多个服务消费。</li>
<li>发布/异步响应：客户端发布消息，然后异步等待响应。</li>
</ul>
</li>
</ul>
<h2 id="定义Api"><a href="#定义Api" class="headerlink" title="定义Api"></a>定义Api</h2><p>API是服务端和客户端的契约，重点是使用某种交互定义语言（IDL），API的定义依赖于选定的IPC机制，如果使用消息机制，API则由消息通道（channel）和消息类型构成，如果采用HTTP机制，API则由url和请求、响应格式构成。</p>
<h2 id="Api的迭代"><a href="#Api的迭代" class="headerlink" title="Api的迭代"></a>Api的迭代</h2><p>在常见的单体应用中，Api如果修改会直接修改所有调用者。但是在微服务中，通常不能强制客户端和服务端保持同步更新，此外，还需要增量部署服务的新版本，保持和旧版本同时运行。在设计客户端和服务时，很有必要遵循健壮性原则。但如果Api需要进行大范围改动，且不兼容旧版本，需要让旧版本运行一段时间，或部署不同实例，每个实例处理一个版本的请求。</p>
<h2 id="处理局部失败"><a href="#处理局部失败" class="headerlink" title="处理局部失败"></a>处理局部失败</h2><p>分布式系统普遍存在局部失败的问题，由于服务端和客户端是独立的进程，服务端可能无法及时响应客户端请求，造成客户端无限等待，不仅影响用户体验，而且还会占用之前的资源。Netfilix提供了较好的解决方案：</p>
<ol>
<li>网络超时。</li>
<li>限制请求次数。</li>
<li>断路器模式（Cicuit Breaker Pattern）记录成功和失败请求的数量。如果失效率超过一个阈值，触发断路器使得后续请求立刻失败。如果大量失败请求，可能这个服务不可用。失效期后，客户端再试，如果成功，关闭断路器。</li>
<li>提供回滚，当一个请求失败后进行回滚。例如返回缓存数据或一个系统默认值。</li>
</ol>
<h2 id="IPC技术"><a href="#IPC技术" class="headerlink" title="IPC技术"></a>IPC技术</h2><p>服务间通讯可以使用同步的请求/响应模式，比如基于HTTP的REST或Thrift。也可以选择异步的、基于消息的通信模式，比如AMQP或者STOMP。可以选择JSON或XML，也可以选择效率更高的Protocol Buffer或Avro<br>异步，基于消息的异步通信。客户端通过想服务端发送请求，服务端如果回复，则发送另一条独立的消息给客户端。消息一般包含数据头（即发送方的元数据）和消息正文。消息通过渠道发送，任何数量的生产者都可以发送消息到渠道，任何消费者可以从渠道接受数据。渠道一般是点对点和发布订阅模式。<br>优点：第一，解耦客户端和服务端，客户端和服务端不需要发现机制确定服务实例的位置；第二，消息缓冲，在消息模式中，消息中间人将所有写入渠道的消息按照队列方式管理，直到被消费者消费；第三，消息机制支持所有交互模式；第四，基于RPC的通信机制让唤醒远程服务就像调用本地服务一样，但是并不可能完全一样，消息机制让这些差异直观明确。<br>缺点：第一，操作复杂，消息系统需要单独安装，配置和部署，且消息代理必须高可用，否则系统可靠性受到影响；第二，实现基于请求/响应模式的复杂性，每个请求消息必须包含一个回复渠道ID和相关ID。服务端发送一个包含相关ID的响应消息到渠道，使用相关ID来将响应对应到发出请求的客户端。<br>同步，基于请求/响应的进程通信。客户端向服务端发送请求，服务端处理请求并返回响应。有的客户端会采用异步的，基于事件驱动的客户端diamagnetic，然而，客户端需要响应即使返回，这里有两种常见协议。<br>REST<br>REST基于HTTP协议，其核心概念是资源典型地代表单一业务对象或一组业务对象、业务对象包括“消费者”或产品。REST提供了一系列架构系统参数。<br>REST有一个成熟度模型，包含一下四个层次：<br>level 0：本层及的web服务只使用HTTP作为传输方式，实际上只是远程方法调用的具体形式，如SOAP和XML-RPC。<br>level 1：引入了资源的概念，要执行对资源的操作，客户端发出指定的执行的操作和任何参数的POST请求。<br>level 2：使用HTTP语法来执行操作，如GET表示获取、POST表示创建，PUT表示更新，请求参数和主题指定操作的参数。<br>level 3：基于HATEOAS（Hypertext As The Engine Of application），基本思想是由GET请求返回资源信息中包含的连接，这些连接能执行该资源允许的操作。例如，客户端通过订单资源中包含的连接取消某以订单，GET请求被发送去获取该订单。<br>Thrift（不熟）</p>
<h2 id="消息格式"><a href="#消息格式" class="headerlink" title="消息格式"></a>消息格式</h2><p>一般是文本和二进制，文本有json和xml，二进制有Protocol Buffer和Avro</p>
<h1 id="四、服务发现的可行方案以及实践案例"><a href="#四、服务发现的可行方案以及实践案例" class="headerlink" title="四、服务发现的可行方案以及实践案例"></a>四、服务发现的可行方案以及实践案例</h1><p>基于云端的微服务架构中，服务实例的网路地址是动态分配的，由于扩展升级，服务实例经常动态改变。客户端代码需要更为复杂的机制去发现服务。一般有两种模式，一种是客户端发现，一种是服务端发现。</p>
<ol>
<li>客户端发现模式</li>
</ol>
<p>客户端从服务注册服务中查询，然后使用负载均衡算法从多个实例中选择一个，然后发出请求。客户端发现模式相对直接，但客户端与服务注册绑定，针对服务端用到的每个编程语言和框架，实现客户端的服务发现逻辑。</p>
<ol start="2">
<li>服务端发现模式</li>
</ol>
<p>客户端通过负载均衡器向某个服务发出请求，负载均衡器查询服务注册表，并将请求转发到可用的得服务实例。例如，HTTP服务器与类似Nginx这样的负载均衡可以作为服务端的发现混衡器。优点是客户端无需关注发现的细节，减少发现逻辑，缺点是负载混衡器需要部署和管理。</p>
<ol start="3">
<li>服务注册表</li>
</ol>
<p>服务注册表是包含服务实例的网络地址数据库，必须高可用，且随时更新，如：zookeeper</p>
<ol start="4">
<li>服务注册方式。</li>
</ol>
<p>一种是自注册方式，服务实例负责在服务注册表中注册和注销，如果需要，一个服务实例也要发送心跳来保证注册信息不会过时。这种方式简单，但需要将服务实例和服务注册表耦合，且在每个编程语言和框架内实现注册代码。<br>一种是第三方注册模式。被称为服务注册器的另外一个系统模块注册服务实例。服务注册器会通过查询部署环境和订阅事件的方式跟踪运行实例的更改。如，Registrator，能够自动注册和注销被部署为docker容器的服务实例。优点是解耦，缺点和服务端发现机制一样，需要单独部署一个高可用的系统组件。</p>
<h1 id="五、微服务的事件驱动数据管理"><a href="#五、微服务的事件驱动数据管理" class="headerlink" title="五、微服务的事件驱动数据管理"></a>五、<strong>微服务的事件驱动数据管理</strong></h1><blockquote>
<p>微服务及分布式数据管理中存在的问题及解决方案</p>
</blockquote>
<p>单体应用通常使用单个关系型数据库，好处是可以使用ACID事务，提供了原子性，一致性，隔离性和持久性。可以简单的开始事务及提交事务。另一个好处是可以是以哦那个SQL，RDBMS查询调度器决定执行最优方法，由于所有数据都在一个数据库中，很容易查询。但是，微服务中，每个微服务有专门的数据用于该微服务，仅通过API访问，这种数据封装保证了微服务的松散耦合，并且可以独立更新，但如果多个服务访问相同数据，架构更新会耗费时间，也需要所有服务的协调更新。但是，不同的微服务通常使用不同类型的数据库。现代应用存储和处理各种类型的数据，关系型数据库并非总是好的选择。<br>小结：分区的，多语言留存的架构对于数据存储有很多好处，包括服务的松耦合，更高的性能和可扩展性，但是也带来了分布式数据管理的挑战。</p>
<ul>
<li>挑战1：</li>
</ul>
<p>如何实现业务逻辑，保证多种服务的一致性。例如，在下单过程中，订单服务管理订单，客户服务管理用户信息。在微服务架构中，订单表和客户表分别为客户服务和订单服务私有。订单服务无法直接访问客户表，只能通过客户服务提供的api，订购服务可通过分布式事务（2pc也叫两步提交。其实就是弄个事务协调器，干啥事先跟协调器说一下，最终协调好了再一起提交事务）。</p>
<ul>
<li>挑战2：</li>
</ul>
<p>检索多个服务数据的查询。例如，应用需要显示一位客户和最近的订单，订单服务只能通过订单主键查询订单，不提供根据客户查询订单。</p>
<h2 id="事件驱动架构"><a href="#事件驱动架构" class="headerlink" title="事件驱动架构"></a>事件驱动架构</h2><p>当有显著事件发生时，如更新业务实体，某微服务会发布事件，其他微服务订阅这些事件，当某一微服务接收到事件就可以更新自己的业务实体，实现更多的事件被发布。<br>用户能够使用事件跨多个服务的业务逻辑。事务由一系列步骤组成，每一步有一个微服务更新业务实体，然后发布促发下一步事件。微服务之间通过消息代理来交换事件。<br>例如：<br>（1）订单服务创建状态为NEW的订单（向订单表添加一条记录），并发布“订单已创建事件”。<br>（2）客户服务获取“订单已创建”，为此    订单保留信用（添加一条客户信用记录），发布“信用保留”事件。<br>（3）订单服务获取“信用保留”事件，把订单状态修改为OPEN（修改订单的状态）。<br>基于（a）每个服务自动更新数据库和发布事件，以及（b）消息代理确保事件传递至少一次，用户能跨越多个服务完成业务逻辑。但，此时业务操作并非ACID业务，这种模式提供弱确定性，这种模型也被称为BASE模型。<br>用户也可以使用事件来维护不同微服务用友的预连接数据的物化视图（就是一些关联不同服务的视图），维护此视图的服务订阅事件，并更新视图。例如，当这个物化视图的服务收到客户或订单发出的服务，就会更新客户订单查看的数据存储。用户能够通过其他方式查询这个视图，通过预览查询服务（就是这个物化视图提供的另外一个查询服务）预览数据存储，处理来自客户和最近订单的请求。<br><strong>优点</strong>：可以使事务跨多个服务并提供最终一致性，也让应用维护物化视图。<br><strong>缺点</strong>：编程模型更为复杂；由于临时事务造成的变化显而易见，因此应用必须处理不一致的数据；此外如果应用从物化视图读物的数据没有更新，也会不一致；用户必须检测并忽略重复事件。</p>
<h2 id="实现原子化"><a href="#实现原子化" class="headerlink" title="实现原子化"></a>实现原子化</h2><p>事件驱动架构存在以原子粒度更新数据库并发布事件的问题。例如，上述的订单服务中，下订单时，插入订单记录和发布事件必须有原子性，如果订单插入数据后，没有发布事件，也会使系统变得不一致，此时只能使用分布式事务。然而很难实现。<br>（1）一种方式是使用本地事务发布事件。通过使用多步骤过程来发布事件，该进程只包含本地事务。在存储业务实体状态的数据库中，有一个事件表充当消息队列。应用启动一个本地数据库事务，更新业务实体的状态，同时在事件表插入一个事件，并提交该事务。<br>例如，订单服务在订单表插入一条记录，然后在事件表中插入“订单已创建”的事件。事件发布线程在事件表中查询未发布的事件，并发布，然后更新事件表，将事件标记为已发布。<br><strong>优点</strong>：保证每个更新都有对应的事件发布，且不依赖2PC.此外，应用发布业务级别的事务，消除了推断事件的需要。<br><strong>缺点</strong>：开发难度大，开发者必须牢记发布事件，且nosql支持力度不大。<br>（2）挖掘数据库事务日志。通过线程和进程他觉数据库事务或提交日志来发布事件。<br>优缺点很明显，事务发布独立应用逻辑，缺点是和数据库绑定。</p>
<h2 id="事件源（事件驱动的微服务架构的支柱）"><a href="#事件源（事件驱动的微服务架构的支柱）" class="headerlink" title="事件源（事件驱动的微服务架构的支柱）"></a>事件源（事件驱动的微服务架构的支柱）</h2><p>通过采取一种截然不同的、以事件为中心的方法来留存业务实体。不同于存储实体的当前状态，应用存储状态改变的事件序列。应用通过重播事件来重构实体的当前状态。每当业务实体的状态改变，新事件就被附加到事件列表。<br>例如，在传统的方法中，每个订单映射为订单表的一行。使用事件源时，订单服务以状态更改事件的方式存储订单。包括已创建、已批准、已发货等等，并存储足够的信息，以便重建订单状态（订单表存储订单的基本信息，状态信息由事件表来重建）。<br>事件数据长期保存在事件数据库中，使用API添加和检索实体事件。事件存储类似上述的事件代理，服务通过API订阅事件，将事件传达给订阅者。<br><strong>优点</strong>：只要状态改变就可靠的发布事件，同时由于存储的是事件而不是领域对象，也避免了对象关系阻抗不匹配的问题。事件源提供了100%可靠的业务实体变化的审计日志，使得获取任何时间点的实体状态变为可能。业务逻辑由松耦合的、事件交换的业务实体构成，便于从单体应用想微服务架构迁移。<br><strong>缺点</strong>：由于采用了不同的编程风格，有一定的学习曲线，事件存储只支持通过主键查询实体，用户需要使用CQRS完成查询，应用必须处理最终一致性的数据。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title>《深入理解Java虚拟机》笔记</title>
    <url>/2022/01/06/1_%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<blockquote>
<p>读《深入理解Java虚拟机 JVM高级特性与最佳实践》笔记</p>
</blockquote>
<h1 id="内存区域分析"><a href="#内存区域分析" class="headerlink" title="内存区域分析"></a>内存区域分析</h1><h2 id="运行区数据区域"><a href="#运行区数据区域" class="headerlink" title="运行区数据区域"></a>运行区数据区域</h2><blockquote>
<p>jvm中整体的内存区域</p>
</blockquote>
<p>![image-20220201112959311](/Users/weiqian/Library/Application Support/typora-user-images/image-20220201112959311.png)</p>
<p>程序计数器：因为java虚拟机需要通过多线程轮流切换，并分配处理器执行时间来实现多线程，在某一个时刻，一个处理器（一般来说也就是一个内核)只会执行一条指令，因此，为了线程切换后能回复到正确的位置，每条线程需要一个独立的程序计数器，<strong>各条线程之间互不影</strong>响。【异常】，这块区域是java中唯一没有规定任何OutOfMemoryError的区域</p>
<p><strong>虚拟机栈</strong>（也就是通常意义上讲的堆栈中的栈）：<strong>生命周期与线程相同</strong>，每个方法在执行的同时创建一个栈帧，方法从调用到执行结束，对应着栈帧入栈到出栈的过程，里面存放着局部变量表，比方说各种基本类型，对象引用（这里这是一个引用，具体的对象信息还是在堆上）。【异常】，如果线程请求栈深度大于虚拟机允许的深度，将抛出StoackOverflowError异常，一般无限递归会报这个错。如果虚拟机栈允许动态扩展，但是扩展时无法申请足够的内存，会抛出OutOfMemoryError异常。</p>
<p>本地方法栈：和虚拟机栈类似，只不过本地方法栈是虚拟机为Native方法准备的。【异常】，如果线程请求栈深度大于虚拟机允许的深度，将抛出StoackOverflowError异常，一般无限递归会报这个错。如果虚拟机栈允许动态扩展，但是扩展时无法申请足够的内存，会抛出OutOfMemoryError异常。</p>
<p><strong>堆：</strong>是java虚拟机所管理内存的最大的一块，<strong>各线程共享</strong>。在虚拟机启动时创建，几乎所有的对象实例都在这里分配内存，在物理上不是不连续的内存中，逻辑上时连续的，【异常】，如果堆中没有内存完成实例分配，而且堆无法扩展时，将会抛出OutOfMemoryError异常。</p>
<p>方法区：各线程共享区域，用于存放虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。这块区域比较模糊，不同的虚拟机实现逻辑不同，有的放在永久代，有的放到Native Memory，【异常】，当方法去无法满足内存分配需求，将抛出，OutOfMemoryError异常。</p>
<p>运行时常量池：是方法区的一部分，存放类的版本，字段，方法等描述信息。</p>
<p>直接内存：Native函数库操作的堆外内存。</p>
<h2 id="创建对象的例子"><a href="#创建对象的例子" class="headerlink" title="创建对象的例子"></a>创建对象的例子</h2><blockquote>
<p>举个例子，某一个对象创建的内存占用</p>
</blockquote>
<h3 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h3><p>虚拟机执行new指令时，会加载对象符号引用，并判断对象是否加载，解析，初始化。执行响应的类加载后，虚拟机将开始为新生代分配内存，对象所需内存大小在类加载完成后便可完全确定，分配过程为了考虑并发情况，通过CAS配上分配失败重试保证分配的原子性。接下来虚拟机对对象进行必要的设置，比如填充类的元数据信息，对象哈希码，对象GC代信息。执行new指令后，对象字段都给了零值，接着才开始执行真正的构造函数（init()）。</p>
<h3 id="对象内存布局"><a href="#对象内存布局" class="headerlink" title="对象内存布局"></a>对象内存布局</h3><p>![image-20220201113014460](/Users/weiqian/Library/Application Support/typora-user-images/image-20220201113014460.png)</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink（未完成）</title>
    <url>/2022/02/20/3_Flink/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<p>Flink是apache基金会孵化的项目，是一个框架和分布式处理引擎，用于无界流数据上进行状态计算。</p>
<h1 id="状态后端存储"><a href="#状态后端存储" class="headerlink" title="状态后端存储"></a>状态后端存储</h1><p>本地配置RocksDB</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;采用rocksdb状态存储</span><br><span class="line">EmbeddedRocksDBStateBackend backend &#x3D; new EmbeddedRocksDBStateBackend();</span><br><span class="line">backend.setDbStoragePath(&quot;file:&#x2F;&#x2F;&#x2F;Users&#x2F;xxx&#x2F;Documents&#x2F;7_dev&#x2F;flink-1.13.6&#x2F;tmp&#x2F;rocksDb&quot;);</span><br><span class="line">env.setStateBackend(backend);</span><br></pre></td></tr></table></figure>



<h1 id="本地安装"><a href="#本地安装" class="headerlink" title="本地安装"></a>本地安装</h1><blockquote>
<p>安装官网步骤 <a href="https://nightlies.apache.org/flink/flink-docs-master/zh/docs/deployment/resource-providers/standalone/overview/" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-master/zh/docs/deployment/resource-providers/standalone/overview/</a></p>
</blockquote>
<ol>
<li>官网下载安装包，url： <a href="https://flink.apache.org/zh/downloads/" target="_blank" rel="noopener">https://flink.apache.org/zh/downloads/</a> 并解压，安装二进制带bin的版本，已经打过包</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar xzf flink-*.tgz</span><br><span class="line">cd flink-*</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>通过maven生成jar包，并配置pom，指定mainClass，将jar包复制到flink-*的目录下，方便启动</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>robot.RobotJob<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>修改集群配置文件（flink-conf.yaml）1.19之后换名字了，这里注意classloader.resolve-order，详见（<a href="https://nightlies.apache.org/flink/flink-docs-release-1.8/monitoring/debugging_classloading.html#inverted-class-loading-and-classloader-resolution-order" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.8/monitoring/debugging_classloading.html#inverted-class-loading-and-classloader-resolution-order</a> ）</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim conf/flink-conf.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment">## 类加载反转</span></span><br><span class="line">classloader.resolve-order: parent-first</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>启动集群</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/start-cluster.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加job</span></span><br><span class="line">bin/jobmanager.sh ((start|start-foreground) [args] [webui-port])|stop|stop-all</span><br><span class="line"><span class="comment"># 增加task</span></span><br><span class="line">bin/taskmanager.sh start|start-foreground|stop|stop-all</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>提交任务</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/flink run --detached ./lib/frauddetection-0.1.jar</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>停止任务</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 优雅停止</span><br><span class="line">bin&#x2F;flink stop --savepointPath tmp&#x2F;flink-savepoints $JOB_ID</span><br><span class="line"></span><br><span class="line"># 暴力停止</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>从SavePoint启动</li>
</ol>
<blockquote>
<p>注意，不要使用–s（有两个-），与–fromSavepoint相同的命令是-s（只有一个-），而且–fromSavepoint（-s）需放在run与jar之间</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 格式</span></span><br><span class="line">run [OPTIONS] &lt;jar-file&gt; &lt;arguments&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">bin/flink run --detached --fromSavepoint tmp/flink-savepoints/savepoint-992cea-2ff0041b0e56 localJar/frauddetection-0.1.jar</span><br></pre></td></tr></table></figure>



<h1 id="精准一次"><a href="#精准一次" class="headerlink" title="精准一次"></a>精准一次</h1><ul>
<li>以Kafka为例，需要下游支持事务</li>
</ul>
<ol>
<li>发送任务时使用事务消息</li>
</ol>
<blockquote>
<p>Flink配置说明：<a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/connectors/datastream/kafka/#kafka-producer-%e5%92%8c%e5%ae%b9%e9%94%99" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/connectors/datastream/kafka/#kafka-producer-%e5%92%8c%e5%ae%b9%e9%94%99</a></p>
<p>Kafka集群配置：<a href="https://kafka.apache.org/documentation/#producerconfigs_transaction.timeout.ms" target="_blank" rel="noopener">https://kafka.apache.org/documentation/#producerconfigs_transaction.timeout.ms</a></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 消息发送方，3步都不能少</span></span><br><span class="line"></span><br><span class="line">Properties outProperties = <span class="keyword">new</span> Properties();</span><br><span class="line">outProperties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line"><span class="comment">//1 开启事务，配置transaction_id</span></span><br><span class="line">outProperties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="keyword">true</span>);</span><br><span class="line">outProperties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">"my-tx1"</span>);</span><br><span class="line"><span class="comment">//2. 配置 transaction.timeout.ms 小于等于集群配置</span></span><br><span class="line"><span class="comment">// 集群默认 transaction.max.timeout.ms =15分钟，Flink有默认配置 超过了15分钟，会报错，错误信息：org.apache.kafka.common.KafkaException: Unexpected error in InitProducerIdResponse; The transaction timeout is larger than the maximum value allowed by the broker (as configured by transaction.max.timeout.ms).</span></span><br><span class="line">outProperties.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG,<span class="number">15</span>*<span class="number">60</span>*<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 开启精准一次</span></span><br><span class="line">FlinkKafkaProducer&lt;Message&gt; readOutProducer = <span class="keyword">new</span> FlinkKafkaProducer&lt;Message&gt;(</span><br><span class="line">  <span class="string">"read-out-topic"</span>                  <span class="comment">// 目标 topic</span></span><br><span class="line">  ,<span class="keyword">new</span> MessageDeserialization()     <span class="comment">// 序列化 schema</span></span><br><span class="line">  ,outProperties                  <span class="comment">// producer 配置</span></span><br><span class="line">  ,<span class="keyword">new</span> FlinkFixedPartitioner&lt;&gt;()</span><br><span class="line">  ,FlinkKafkaProducer.Semantic.EXACTLY_ONCE<span class="comment">//精准一次</span></span><br><span class="line">  ,<span class="number">2</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>消费方也需要配置事务读取，否则没效果</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Map&lt;String, Object&gt; props &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:9092&quot;);</span><br><span class="line">&#x2F;&#x2F;取消自动提交</span><br><span class="line">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);</span><br><span class="line">&#x2F;&#x2F; 设置事务相关的参数</span><br><span class="line">props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, &quot;read_committed&quot;);</span><br></pre></td></tr></table></figure>



<h1 id="备忘"><a href="#备忘" class="headerlink" title="备忘"></a>备忘</h1><ul>
<li>webui上面期交任务，会出现序列化不对报错，或者jar版本不对的情况，原因不明</li>
</ul>
<ul>
<li>本地打包的flink版本，需要和环境的flink版本一致（小版本也要一致，1.13.6），否则会出现各种序列化失败的情况，例如</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Caused by: java.io.InvalidClassException: org.apache.flink.runtime.checkpoint.InflightDataRescalingDescriptor$NoRescalingDescriptor; local class incompatible: stream classdesc serialVersionUID &#x3D; -5544173933105855751, local class serialVersionUID &#x3D; 1</span><br><span class="line">	at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:689) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2012) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1862) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2169) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679) ~[?:?]</span><br><span class="line">	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:493) ~[?:?]</span><br></pre></td></tr></table></figure>



<ul>
<li>尝试查看rocksdb的数据（失败）</li>
</ul>
<p>下载RocksDB，官网下载链接：<a href="https://github.com/facebook/rocksdb/releases" target="_blank" rel="noopener">https://github.com/facebook/rocksdb/releases</a> 用java程序连接查看（并没有看到数据）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> robot;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.rocksdb.DBOptions;</span><br><span class="line"><span class="keyword">import</span> org.rocksdb.Options;</span><br><span class="line"><span class="keyword">import</span> org.rocksdb.RocksDB;</span><br><span class="line"><span class="keyword">import</span> org.rocksdb.RocksDBException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RocksdbReader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// RocksDB 数据目录路径</span></span><br><span class="line">        String dbPath = <span class="string">"/Users/xxx/Documents/7_dev/flink-1.13.6/tmp/rocksDb/job_e5d0d01a1e9a7a63ed98ffdeb91041c4_op_KeyedProcessOperator_570f707193e0fe32f4d86d067aba243b__1_1__uuid_810f8ac4-b576-455a-8010-206c8aa243c9/db"</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> (<span class="keyword">final</span> Options options = <span class="keyword">new</span> Options();</span><br><span class="line">             <span class="keyword">final</span> RocksDB db = RocksDB.openReadOnly(options, dbPath)) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 键</span></span><br><span class="line">            <span class="keyword">byte</span>[] key = <span class="string">"1"</span>.getBytes();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 读取数据</span></span><br><span class="line">            <span class="keyword">byte</span>[] value = db.get(key);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (value != <span class="keyword">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">"Key: "</span> + <span class="keyword">new</span> String(key) + <span class="string">", Value: "</span> + <span class="keyword">new</span> String(value));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">"Key not found: "</span> + <span class="keyword">new</span> String(key));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RocksDBException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li>Kafka之前配置了事务，但去掉事务参数（enable.idempotence，transactional.id），启动报错</li>
</ul>
<blockquote>
<p>参考： <a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/connectors/datastream/kafka/#%e5%8d%87%e7%ba%a7%e5%88%b0%e6%9c%80%e8%bf%91%e7%9a%84%e8%bf%9e%e6%8e%a5%e5%99%a8%e7%89%88%e6%9c%ac" target="_blank" rel="noopener">https://nightlies.apache.org/flink/flink-docs-release-1.13/zh/docs/connectors/datastream/kafka/#%e5%8d%87%e7%ba%a7%e5%88%b0%e6%9c%80%e8%bf%91%e7%9a%84%e8%bf%9e%e6%8e%a5%e5%99%a8%e7%89%88%e6%9c%ac</a> </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 1.修改uid</span><br><span class="line">stream.addSink(readOutProducer)</span><br><span class="line">                .uid(&quot;read-out-alerts2&quot;)  &#x2F;&#x2F;升级后修改成新的uid，修改name没用</span><br><span class="line">                .name(&quot;read-out-alerts&quot;);</span><br><span class="line">                </span><br><span class="line">&#x2F;&#x2F; 打包后，检查点启动，需要携带allowNonRestoredState，调过无法恢复的状态（因为删除了一个算子）</span><br><span class="line">bin&#x2F;flink run --detached -s tmp&#x2F;flink-savepoints&#x2F;savepoint-f0be79-90342a900f1d --allowNonRestoredState localJar&#x2F;frauddetection-0.1.jar</span><br></pre></td></tr></table></figure>



<ul>
<li>taskmanager 没有自动启动（未知）</li>
</ul>
<ul>
<li>onTIme是Key维度的，即使过期时间小于注册时间，当任务恢复后，注册时间到了，依然会执行onTime方法</li>
</ul>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>小结</tag>
      </tags>
  </entry>
  <entry>
    <title>3_Kafka-stream</title>
    <url>/2022/02/18/3_Kafka-stream/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<blockquote>
<p> 官网操作手册：<a href="https://kafka.apache.org/31/documentation/streams/developer-guide/" target="_blank" rel="noopener">https://kafka.apache.org/31/documentation/streams/developer-guide/</a></p>
</blockquote>
<p>Kafka Streams是个客户端类库，通过存储在输入和输出都存储在Kafka集群中，有着编写方便和部署便捷的优点。</p>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><ol>
<li>设计上目标是简单轻量的客户端类库，可以方便的内嵌在java客户端或者其他系统中，可以自行管理打包部署。</li>
<li>没有其他额外依赖。使用Kafka分区模型去水平扩展、顺序性保证。</li>
<li>支持失败容忍的本地<strong>状态</strong>，支持快速高效的状态操作，例如时间窗口，聚合计算。</li>
<li>支持<strong>精确一次</strong>计算语义，即使流客户端或者kafka brokers处理过程中异常也能保证精确一次。</li>
<li>使用记录时间处理来达到毫秒级处理延迟，支持基于<strong>窗口</strong>的事件时间支持乱序数据。</li>
<li>提供必要的流处理原语，高级别的流DSL和低级别的处理API</li>
</ol>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><h2 id="流分区任务"><a href="#流分区任务" class="headerlink" title="流分区任务"></a>流分区任务</h2><p>消息层Kafka分区为了存储和传输数据。Kafka Streams分区为了处理数据。相似点都在于分区可以使数据本地话，弹性，扩展性，高性能和容错性。Kafka Streams基于Topic分区使用<strong>流分区</strong>和<strong>任务</strong>作为逻辑单元并行模型。</p>
<ul>
<li>每一个Topic分区都有一个流分区与其对应，且流分区是有序的数据片段</li>
<li>从Tpoic接收到的消息会映射到流中的数据记录</li>
<li>数据的key决定着Kafka消息和Kafka Streams的分区。即如何路由到特定的分区中</li>
</ul>
<p>Kafka Streams会根据输入分区创建固定数量的任务。每一个任务关联输入流（Topic）的分区列表，关联分区的任务不会改变，所以每一个任务都是一个固定的执行并行单元。任务可以基于分配的分区进行初始化。他们会为分配的分区和消息处理维护缓冲区，导致streams的任务可以独立运行无需人工干预。</p>
<p>简单来说，最大的并行读取决于能运行多少个任务，决定于有多少个输入分区数，尽管运行多个实例，但多余的示例会处于闲置状态，等待运行的实例故障后，会接替继续工作。</p>
<p>非常重要的是，Kafka Streams不是资源管理，但是库会运行在每一个streams处理应用程序上，不管多个示例是在同一个物理机还是分割在不同物理机，任务会由库自动分配地运行在每一个应用实例上，分配的任务不会改变，如果某一个应用下线，则关联的任务会自动在另一个应用上重启，继续消费分区消息。</p>
<h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><h3 id="拓扑结构"><a href="#拓扑结构" class="headerlink" title="拓扑结构"></a>拓扑结构</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/406465/1645170601355-00e54680-9f6f-4082-8220-1ba81e6ec211.png" alt="img" loading="lazy"></p>
<ul>
<li><p>stream，表示误解的时序性的数据集，流是有顺序的可重现的失败容忍的不可变的数据片段。</p>
</li>
<li><p>stream prossessor 是一个节点，通过处理输入数据并转化魏输出数据，使用响应的操作，也可以产生1个或多个下游数据。</p>
</li>
<li><p>stream应用程序，表示包含stream processor和stream的整个拓扑结构</p>
</li>
</ul>
<h3 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h3><blockquote>
<p>和Flink的概念基本类似</p>
</blockquote>
<ul>
<li><p>Event Time事件时间，表示数据发生时的真实时间</p>
</li>
<li><p>Processing Time处理时间，表示流处理程序处理这个时间的时间，可能晚事件时间若干秒、时、天，取决于从何处录入</p>
</li>
<li><p>Ingestion Time摄入时间，表示时间记录持久化到Kafka broker的时间，如果记录一直没有处理会出现有摄入时间，无处理时间的情况</p>
</li>
</ul>
<h3 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h3><p>输入可以是Kafka stream或者Ktable，但是输出一直是KTable。</p>
<h3 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h3><p>可以使用聚合函数，同时可以对窗口使用宽限期，以接收迟到的记录。在窗口+宽限期都过去之后，这条记录将会被丢弃。</p>
<h3 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h3><p>允许聚合，分组等相关操作。本地存储存在在KV数据库、内存或其他地方。同时Kafka Streams支持直接操作状态存储。</p>
<h3 id="处理过程保证"><a href="#处理过程保证" class="headerlink" title="处理过程保证"></a>处理过程保证</h3><p>在Kafka0.11.0之前的版本，Kafka仅支持<strong>至少一次</strong>的传输保证，所以以Kafka作为后端存储（例如使用Kafka输入或输出）的流处理系统都无法实现<strong>精确一次</strong>的语义。在0.11.0版本，Kafka支持允许事务（<a href="https://kafka.apache.org/documentation/#semantics" target="_blank" rel="noopener">https://kafka.apache.org/documentation/#semantics</a> ），以实现精确一次的语义。2.6.0还做了一波升级。</p>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>小结</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch</title>
    <url>/2022/11/26/3_Elasticsearch/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">



<p>参考文档：<a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch</a></p>
<p>git上的介绍：Elasticsearch是一个分布式基于restful的java语言编写的，服务于云端的搜索引擎，有以下几个优点。</p>
<ol>
<li>分布式高可用，每一个索引可以被配置为完全共享的分片，每一个分片有一个或多个副本，每一个分片的副本均提供查询搜索的功能操作。</li>
<li>多租户，支持多索引，索引级别的租户配置。</li>
<li>各种api支持，http，restful，api，所有的api操作会自动被节点操作重定向。</li>
<li>面向文档的，不用预先定义格式，可以为索引过程自定义结构。</li>
<li>可靠，对长期持久化提供异步后台写入。</li>
<li>近实时查询。</li>
<li>构建在lucene上，所有的分片都是全功能的lucene分片，lucene的功能均可以简单通过配置开放出来。</li>
<li>每一个操作都满足一致性的，简单的文档级别操作均是acid的。</li>
</ol>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>​    </p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/documents-indices.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.3/documents-indices.html</a></p>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ol>
<li>为app或者website增加一个搜索的组件</li>
<li>存储分析日志，测量值，安全事件</li>
<li>实时使用机器学习自动对数据行为分析建模</li>
<li>作为自动化工作流的存储引擎</li>
<li>作为地理信息管理系统，管理，集成，分析空间数据</li>
<li>作为生物科学的搜索工具存储遗传进化的数据</li>
</ol>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>ES将复杂的数据结构序列化成json格式，当文档被存储后，ES使用名为inverted index（倒排索引）来支持快速的全文索引，倒排索引列举了文档中的每一个单词及标识出单词在哪一个文档中出现。</p>
<p>索引可以被认为是优化过的文档的集合，每一个文档都是字段的集合，字段都是以键值对的方式存储着数据。默认的，每一种字段都有专门的优化过的数据存储结构。例如，大文本存储在倒排索引中，数值和地理字段存储在BKD中。通过使用每一种字段数据结构去拼接和返回结果达到高效查询的目的。</p>
<p>可以通过<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/query-dsl.html" target="_blank" rel="noopener">json风格</a>的查询语言或着<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/sql-overview.html" target="_blank" rel="noopener">sql风格</a>的查询语言进行搜索。同时ES支持聚合搜索</p>
<h1 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h1><ul>
<li>query和filter的区别，query会计算相关性，filter不会</li>
<li>查询时可结合分词器，在字段定义时，可同时指定构建时分析器</li>
<li>在某些情况下，如果是前缀匹配，可以考虑结合edge-egram，或者Suggester（一种提示语，可以根据term或者phase进行近似匹配）</li>
</ul>
<h2 id="常用查询"><a href="#常用查询" class="headerlink" title="常用查询"></a>常用查询</h2><p>检索内嵌对象中，某个字段不存在</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;nested&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;skuDocuments&quot;,</span><br><span class="line">            &quot;query&quot;: &#123;</span><br><span class="line">              &quot;bool&quot;: &#123;</span><br><span class="line">                &quot;must_not&quot;: &#123;</span><br><span class="line">                  &quot;exists&quot;: &#123;</span><br><span class="line">                    &quot;field&quot;: &quot;skuDocuments.price&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="查询数量"><a href="#查询数量" class="headerlink" title="查询数量"></a>查询数量</h2><p>常用的查询使用search的RestApi，查询匹配的数量使用的是count的RestApi，相比使用聚合，效率快的多</p>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.14/search-count.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/search-count.html</a></p>
<h2 id="查询分析语句"><a href="#查询分析语句" class="headerlink" title="查询分析语句"></a>查询分析语句</h2><p>如果想查看DSL语句（类似json格式的查询语句），可以增加profile字段，显示耗时情况</p>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.14/search-profile.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/search-profile.html</a></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET saas-mcloud-plug-saas_cdp_bid_tag_user_match_tag_att/_search?human=true</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>同时也可以在kibana上查看到耗时情况</p>
<p><img src="/2022/11/26/3_Elasticsearch/image2.png" alt="image-20220625171540368" loading="lazy"></p>
<h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><p>更新有两种方式，bulk的put。或者update_by_query。</p>
<p>自测小数据量（1K）的情况下，update_by_query更新速度要优于put。但update_by_query不会受限查询大小限制，不用分批滚动。</p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><h3 id="Term-Dictionary"><a href="#Term-Dictionary" class="headerlink" title="Term Dictionary"></a>Term Dictionary</h3><p>为了加快查询速度，这里建立了倒排索引，可以根据关键字快速查询到文档，结构如下，Term对应到具体的DocId</p>
<p><img src="/2022/11/26/3_Elasticsearch/image8.png" alt loading="lazy"></p>
<h3 id="Term-Index"><a href="#Term-Index" class="headerlink" title="Term Index"></a>Term Index</h3><p>在磁盘中保存Term，查询时性能影响较大，Elasticsearch采用内存保存Term，但Term太多，放内存不太合适，所以有了Term Index，</p>
<p><img src="/2022/11/26/3_Elasticsearch/image9.png" alt loading="lazy"></p>
<p>树上不会存储所有的term，值保存term的前缀，通过前缀可以快速定位到term directionary的offset，从offset向后查找</p>
<p><img src="/2022/11/26/3_Elasticsearch/image10.png" alt loading="lazy"></p>
<p>但是Term Index还是比较大，如果以Map的形式存储，空间占用还是比较大，这里采用FST的的压缩技术，从而将Term Index存储到内存中。</p>
<p>定位到posting list后，即可找到对应文档，但是posting list还是比较大，为了压缩存储，采用增量编码压缩。每个id按照顺序存放在bitmap里，但是以65535（2^16-1）作为一个块，第二个块从65536~131071，以此类推。普通的bitmap，一个字节可以存储8个文档。有关id的选择，有一篇博客：<a href="https://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html。" target="_blank" rel="noopener">https://blog.mikemccandless.com/2014/05/choosing-fast-unique-identifier-uuid.html。</a></p>
<h1 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>主要包含3个基本的概念：字符过滤器（Character filters），词元器（Tokenizer），词元过滤器（Token filter）</p>
<h3 id="Character-Filter"><a href="#Character-Filter" class="headerlink" title="Character Filter"></a>Character Filter</h3><p>将原始文本以流的形式接收，输出字符，并对流中做增加，删除，修改部分字符等操作，例如去除html中的&lt;br&gt;标签。一个分词器可包含<strong>0或多个</strong>字符过滤器</p>
<h3 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h3><p><strong>重点使用</strong>。接收流形式过来的字符，拆分成独立的词元，并输出。例如whitespace分词器把”Quick brown fox!”分成[Quick, brown, fox!]。一个分词器只能包含<strong>1个</strong>词元器。</p>
<h3 id="Token-Filter"><a href="#Token-Filter" class="headerlink" title="Token Filter"></a>Token Filter</h3><p>过滤处理词元流，比如，把所有词元小写化，去除停顿词。一个分词器可以包含<strong>0或多个</strong>词元过滤器</p>
<h2 id="分词插件"><a href="#分词插件" class="headerlink" title="分词插件"></a>分词插件</h2><p>elasticsearch提供了很多分词工具，但是对中文不友好，需要自行安装中文分词插件，目前较为常用的是IK分词</p>
<p>es内置了很多分词器，可以满足常用需求，有面向词语的：Standard Tokenizer（默认），Lowercase Tokenize。有将单词分割为部分的：n-gram Tokenizer，Edge n-gram Tokenizer。有结构化处理文本的：Pattern Tokenizer，Path tokenizer</p>
<h2 id="简单应用"><a href="#简单应用" class="headerlink" title="简单应用"></a>简单应用</h2><h3 id="模糊查询"><a href="#模糊查询" class="headerlink" title="模糊查询"></a>模糊查询</h3><p>在某些特殊的情况下，需要实现类似数据库的模糊匹配需求，尽管可通过Wildcard实现，但检索性能较差，可考虑在构建索引时，利用分词器，将原始文本拆分为多个部分，后续检索时，可根据单词匹配快速检索数据，以空间换时间。</p>
<ol>
<li><p>字段定义</p>
<blockquote>
<p>由于n-gram默认的最大元数量有限制，这里可以通过max_ngram_diff进行调整。定义时，自定义了分词器，分词器采用ngram类型，并指定了最小最大元，单词仅收集单词（字母中文）和数字（123等），<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/analysis-ngram-tokenizer.html" target="_blank" rel="noopener">官网详情介绍</a>。定义时username在构建时根据ngram分词，检索词根据标准分词</p>
</blockquote>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT saas-export-goods-reviews-base2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"max_ngram_diff"</span>:<span class="number">3</span>,</span><br><span class="line">    <span class="attr">"analysis"</span>: &#123;</span><br><span class="line">      <span class="attr">"analyzer"</span>: &#123;</span><br><span class="line">        <span class="attr">"my_analyzer"</span>: &#123;</span><br><span class="line">          <span class="attr">"tokenizer"</span>: <span class="string">"my_tokenizer"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"tokenizer"</span>: &#123;</span><br><span class="line">        <span class="attr">"my_tokenizer"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"ngram"</span>,</span><br><span class="line">          <span class="attr">"min_gram"</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="attr">"max_gram"</span>: <span class="number">3</span>,</span><br><span class="line">          <span class="attr">"token_chars"</span>: [</span><br><span class="line">            <span class="string">"letter"</span>,</span><br><span class="line">            <span class="string">"digit"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"comment"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"email"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"goodsCode"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"personalName"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"my_analyzer"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"reviewsCode"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"username"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"my_analyzer"</span>,</span><br><span class="line">        <span class="attr">"search_analyzer"</span>: <span class="string">"standard"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询检索，确定分词效果</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">POST saas-export-goods-reviews-base2/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"analyzer"</span>: <span class="string">"my_analyzer"</span>,</span><br><span class="line">  <span class="attr">"text"</span>: <span class="string">"uu325t4"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>效果</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT saas-export-goods-reviews-base2/_doc/12312</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"username"</span>: <span class="string">"uu3321"</span></span><br><span class="line">&#125; </span><br><span class="line">POST saas-export-goods-reviews-base2/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"should"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"username"</span>: <span class="string">"uu3"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 效果</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"took"</span> : <span class="number">261</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"_shards"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"successful"</span> : <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"skipped"</span> : <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"failed"</span> : <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hits"</span> : &#123;</span><br><span class="line">    <span class="attr">"total"</span> : &#123;</span><br><span class="line">      <span class="attr">"value"</span> : <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"relation"</span> : <span class="string">"eq"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"max_score"</span> : <span class="number">10.640834</span>,</span><br><span class="line">    <span class="attr">"hits"</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"saas-export-goods-reviews-base2"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"12312"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">10.640834</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"username"</span> : <span class="string">"uu3321"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




</li>
</ol>
<h1 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h1><blockquote>
<p>lucene文件结构：<a href="https://lucene.apache.org/core/9_9_1/core/org/apache/lucene/codecs/lucene99/package-summary.html#package.description" target="_blank" rel="noopener">https://lucene.apache.org/core/9_9_1/core/org/apache/lucene/codecs/lucene99/package-summary.html#package.description</a></p>
</blockquote>
<p>底层基于Lucene存储，    </p>
<h1 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h1><p>一般在修改数据字段时，不允许直接在已经新建的索引上修改，但日常工作中，难免遇到提前定义错了mapping类型，或索引内数据需要合并，分割。</p>
<p>经测试，只要通过spring自动创建的索引（会根据字段类型自动匹配映射类型），再想修改都不可能了。但是如果只是新增一个字段，同时指定正确的类型，这样是可以的。</p>
<h2 id="Reindex"><a href="#Reindex" class="headerlink" title="Reindex"></a>Reindex</h2><ol>
<li>先建立别名映射，将查询saas-export-goods-aliases的链接到export_goods</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"add"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"export_goods"</span>,</span><br><span class="line">        <span class="string">"alias"</span>: <span class="string">"saas-export-goods-aliases"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>将程序中的索引换成别名</li>
</ol>
<p><img src="/2022/11/26/3_Elasticsearch/image.png" alt loading="lazy"></p>
<ol start="3">
<li><p>创建新的正确映射的索引，为数据迁移做准备</p>
<p>获取到原有索引映射</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /export_goods/_mappings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"export_goods"</span> : &#123;</span><br><span class="line">    <span class="string">"mappings"</span> : &#123;</span><br><span class="line">      <span class="string">"properties"</span> : &#123;</span><br><span class="line">        <span class="string">"count"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"long"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"goodsMaps"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"nested"</span>,</span><br><span class="line">          <span class="string">"properties"</span> : &#123;</span><br><span class="line">            <span class="string">"groupCode"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">              <span class="string">"fields"</span> : &#123;</span><br><span class="line">                <span class="string">"keyword"</span> : &#123;</span><br><span class="line">                  <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">                  <span class="string">"ignore_above"</span> : 256</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"sort"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"long"</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"goodsMaps2"</span> : &#123;</span><br><span class="line">          <span class="string">"properties"</span> : &#123;</span><br><span class="line">            <span class="string">"groupCode"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">              <span class="string">"fields"</span> : &#123;</span><br><span class="line">                <span class="string">"keyword"</span> : &#123;</span><br><span class="line">                  <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">                  <span class="string">"ignore_above"</span> : 256</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"id"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="string">"fields"</span> : &#123;</span><br><span class="line">            <span class="string">"keyword"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="string">"ignore_above"</span> : 256</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"name"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"pid"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"long"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>创建新的索引</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /export_goods_copy/</span><br><span class="line"> &#123;</span><br><span class="line">   <span class="string">"mappings"</span> : &#123;</span><br><span class="line">      <span class="string">"properties"</span> : &#123;</span><br><span class="line">        <span class="string">"count"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"long"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"goodsMaps"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"nested"</span>,</span><br><span class="line">          <span class="string">"properties"</span> : &#123;</span><br><span class="line">            <span class="string">"groupCode"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">              <span class="string">"fields"</span> : &#123;</span><br><span class="line">                <span class="string">"keyword"</span> : &#123;</span><br><span class="line">                  <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">                  <span class="string">"ignore_above"</span> : 256</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"sort"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"long"</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"goodsMaps2"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"nested"</span>,</span><br><span class="line">          <span class="string">"properties"</span> : &#123;</span><br><span class="line">            <span class="string">"groupCode"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">              <span class="string">"fields"</span> : &#123;</span><br><span class="line">                <span class="string">"keyword"</span> : &#123;</span><br><span class="line">                  <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">                  <span class="string">"ignore_above"</span> : 256</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"id"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="string">"fields"</span> : &#123;</span><br><span class="line">            <span class="string">"keyword"</span> : &#123;</span><br><span class="line">              <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="string">"ignore_above"</span> : 256</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"name"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"pid"</span> : &#123;</span><br><span class="line">          <span class="string">"type"</span> : <span class="string">"long"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>执行reIndex</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /_reindex?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"source"</span>: &#123;</span><br><span class="line">    <span class="string">"index"</span>: <span class="string">"export_goods"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"dest"</span>: &#123;</span><br><span class="line">    <span class="string">"index"</span>: <span class="string">"export_goods_copy"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>将别名映射到新的索引中，之前的索引可以删掉了。保证别名未删除就行</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"remove"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"export_goods"</span>,</span><br><span class="line">        <span class="string">"alias"</span>: <span class="string">"saas-export-goods-aliases"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"add"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"export_goods_copy"</span>,</span><br><span class="line">        <span class="string">"alias"</span>: <span class="string">"saas-export-goods-aliases"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>查看映射关系</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">GET _alias/saas-export-goods-aliases</span><br></pre></td></tr></table></figure>





<h1 id="Spring-data"><a href="#Spring-data" class="headerlink" title="Spring-data"></a>Spring-data</h1><ul>
<li>如果使用Repository，必须继承ElasticsearchRepository，在启动时会检查索引是否存在，如果不存在则会尝试根据Annotation构建Index。如果启动后删除了index，或者修改了index，没找到办法重新修改。手动再修改回来。</li>
</ul>
<h2 id="别名"><a href="#别名" class="headerlink" title="别名"></a>别名</h2><ul>
<li>在重建索引的过程中，如果遇到字段映射发生变更，是需要删除索引重建的。</li>
</ul>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><ul>
<li>内嵌对象排序</li>
</ul>
<p>可以利用bool构造多个查询条件，sort根据多个字段进行排序</p>
<p>查询：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.14/query-dsl-nested-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/query-dsl-nested-query.html</a></p>
<p>排序：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.14/sort-search-results.html#nested-sorting" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.14/sort-search-results.html#nested-sorting</a></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">GET /export_goods/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "bool": &#123;</span><br><span class="line">      "must": [</span><br><span class="line">        &#123;</span><br><span class="line">          "nested": &#123;</span><br><span class="line">            "path": "goodsMaps",</span><br><span class="line">            "query": &#123;</span><br><span class="line">                "match": &#123; "goodsMaps.groupCode": "DDDDD" &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "sort": [</span><br><span class="line">    &#123;</span><br><span class="line">      "goodsMaps.sort": &#123;</span><br><span class="line">        "order": "asc",</span><br><span class="line">        "nested": &#123;</span><br><span class="line">          "path": "goodsMaps",</span><br><span class="line">          "filter": &#123;</span><br><span class="line">             "match": &#123; "goodsMaps.groupCode": "DDDDD" &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "count": &#123;</span><br><span class="line">        "order": "asc"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>spring-data-elasticsearch</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BoolQueryBuilder queryBuilder = boolQuery();</span><br><span class="line">MatchQueryBuilder matchQueryBuilder = <span class="keyword">new</span> MatchQueryBuilder(<span class="string">"goodsMaps.groupCode"</span>,<span class="string">"DDDDD"</span>);</span><br><span class="line">NestedQueryBuilder nestedQueryBuilder = <span class="keyword">new</span> NestedQueryBuilder(<span class="string">"goodsMaps"</span>,matchQueryBuilder, ScoreMode.Avg);</span><br><span class="line">queryBuilder.must(nestedQueryBuilder);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">FieldSortBuilder sortBuilder = <span class="keyword">new</span> FieldSortBuilder(<span class="string">"goodsMaps.sort"</span>);</span><br><span class="line">NestedSortBuilder nestedSortBuilder = <span class="keyword">new</span> NestedSortBuilder(<span class="string">"goodsMaps"</span>);</span><br><span class="line">nestedSortBuilder.setFilter(matchQueryBuilder);</span><br><span class="line">sortBuilder.setNestedSort(nestedSortBuilder);</span><br><span class="line">sortBuilder.order(SortOrder.ASC);</span><br><span class="line"></span><br><span class="line">NativeSearchQuery nativeSearchQuery = <span class="keyword">new</span> NativeSearchQueryBuilder()</span><br><span class="line">    .withQuery(queryBuilder)</span><br><span class="line">    .withSort(sortBuilder)</span><br><span class="line">    .withPageable(PageRequest.of(<span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">    .build();</span><br><span class="line">Page&lt;Goods&gt; search = repository.search(nativeSearchQuery);</span><br></pre></td></tr></table></figure>



<h2 id="字段映射"><a href="#字段映射" class="headerlink" title="字段映射"></a>字段映射</h2><ul>
<li>一般text字段默认会被索引，如果需要精确查询时，建议采用term</li>
<li>当需要精确匹配时，可以设置Field的别名，将别名类型设置为keyword，查询时指定别名查询，如下所示，goodsCode原本类型为text，别名keyword，类型为keyword</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">"goodsCode"</span> : &#123;</span><br><span class="line">    <span class="string">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">    <span class="string">"fields"</span> : &#123;</span><br><span class="line">        <span class="string">"keyword"</span> : &#123;</span><br><span class="line">            <span class="string">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="string">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>spring-data-elasticsearch的注解映射时，如果是String类型，会映射成muti-field，主类型为text，辅类型有一个keyword</li>
</ul>
<h1 id="简单安装"><a href="#简单安装" class="headerlink" title="简单安装"></a>简单安装</h1><ol>
<li>安装elastisearch软件包，<a href="https://www.elastic.co/cn/downloads/elasticsearch" target="_blank" rel="noopener">前往这里</a></li>
<li>解压安装</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">elasticsearch-7.3.2</span><br><span class="line">ll</span><br><span class="line">total 1048</span><br><span class="line">drwxr-xr-x@ 14 weiqian  staff     448  8 30 21:23 .&#x2F;</span><br><span class="line">drwxr-xr-x  27 weiqian  staff     864  8 31 17:38 ..&#x2F;</span><br><span class="line">-rw-r--r--@  1 weiqian  staff   13675  9  6  2019 LICENSE.txt</span><br><span class="line">-rw-r--r--@  1 weiqian  staff  502598  9  6  2019 NOTICE.txt</span><br><span class="line">-rw-r--r--@  1 weiqian  staff    8500  9  6  2019 README.textile</span><br><span class="line">drwxr-xr-x@ 22 weiqian  staff     704  9  6  2019 bin&#x2F;</span><br><span class="line">drwxr-xr-x@ 10 weiqian  staff     320  8 30 21:39 config&#x2F;</span><br><span class="line">drwxr-xr-x   3 weiqian  staff      96  8 30 18:32 data&#x2F;</span><br><span class="line">drwxr-xr-x@  3 weiqian  staff      96  9  6  2019 jdk&#x2F;</span><br><span class="line">drwxr-xr-x@ 42 weiqian  staff    1344  9  6  2019 lib&#x2F;</span><br><span class="line">drwxr-xr-x@ 14 weiqian  staff     448 10 25 13:42 logs&#x2F;</span><br><span class="line">drwxr-xr-x@ 33 weiqian  staff    1056  9  6  2019 modules&#x2F;</span><br><span class="line">-rw-r--r--   1 weiqian  staff       5  8 30 21:38 pid</span><br><span class="line">drwxr-xr-x@  2 weiqian  staff      64  9  6  2019 plugins&#x2F;</span><br></pre></td></tr></table></figure>

<ol>
<li>进入bin目录，执行./elasticsearch</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  elasticsearch-7.3.2 cd</span><br><span class="line">➜  bin .&#x2F;elasticsearch</span><br></pre></td></tr></table></figure>

<ol>
<li>加入两个节点集群，将data和日志输出到不同的目录即可，配置文件默认读取的是conf下的</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;elasticsearch -Epath.data&#x3D;data2 -Epath.logs&#x3D;log2</span><br><span class="line">.&#x2F;elasticsearch -Epath.data&#x3D;data3 -Epath.logs&#x3D;log3</span><br></pre></td></tr></table></figure>

<ol>
<li>正常情况下会输出</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2020-10-25T13:42:41,898][INFO ][o.e.c.s.ClusterApplierService] [weiqiandeMacBook-Pro.local] master node changed &#123;previous [], current [&#123;weiqiandeMacBook-Pro.local&#125;&#123;zCAE8hSGR9-B3GYbxI7dsw&#125;&#123;GALzOcCeQPeeFos5e7K7zQ&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;&#123;dim&#125;&#123;xpack.installed&#x3D;true&#125;]&#125;, term: 4, version: 26, reason: Publication&#123;term&#x3D;4, version&#x3D;26&#125;</span><br><span class="line">[2020-10-25T13:42:41,925][INFO ][o.e.h.AbstractHttpServerTransport] [weiqiandeMacBook-Pro.local] publish_address &#123;127.0.0.1:9200&#125;, bound_addresses &#123;[::1]:9200&#125;, &#123;127.0.0.1:9200&#125;</span><br><span class="line">[2020-10-25T13:42:41,925][INFO ][o.e.n.Node               ] [weiqiandeMacBook-Pro.local] started</span><br><span class="line">[2020-10-25T13:42:42,096][INFO ][o.e.l.LicenseService     ] [weiqiandeMacBook-Pro.local] license [909422ec-ff18-4f81-9379-013fd25f0dea] mode [basic] - valid</span><br><span class="line">[2020-10-25T13:42:42,097][INFO ][o.e.x.s.s.SecurityStatusChangeListener] [weiqiandeMacBook-Pro.local] Active license is now [BASIC]; Security is disabled</span><br><span class="line">[2020-10-25T13:42:42,101][INFO ][o.e.g.GatewayService     ] [weiqiandeMacBook-Pro.local] recovered [2] indices into cluster_state</span><br><span class="line">[2020-10-25T13:42:42,300][INFO ][o.e.c.r.a.AllocationService] [weiqiandeMacBook-Pro.local] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[my-index-000001][0], [test][0]] ...]).</span><br></pre></td></tr></table></figure>

<ol>
<li>可通过访问<a href="http://localhost:9200，验证是否单节点">http://localhost:9200，验证是否单节点</a></li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET http:&#x2F;&#x2F;localhost:9200&#x2F;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;weiqiandeMacBook-Pro.local&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;ZJ0Bs8TNQpq5dBgT9UUH1A&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;7.3.2&quot;,</span><br><span class="line">    &quot;build_flavor&quot; : &quot;default&quot;,</span><br><span class="line">    &quot;build_type&quot; : &quot;tar&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;1c1faf1&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2019-09-06T14:40:30.409026Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;8.1.0&quot;,</span><br><span class="line">    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,</span><br><span class="line">    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>通过健康检查接口查看集群是否正常，status为green表示正常，当为yellow时，表示一个节点功能全部正常，但是数据不能从另一个节点复制过来，如果时红色，表示数据不可用</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">config       curl -X GET &quot;localhost:9200&#x2F;_cat&#x2F;health?v&amp;pretty&quot;</span><br><span class="line"></span><br><span class="line">epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent</span><br><span class="line">1603609613 07:06:53  elasticsearch green           3         3      4   2    0    0        0             0                  -                100.0%</span><br></pre></td></tr></table></figure>

<ol>
<li>一些参数</li>
</ol>
<p>搜索的结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot; : 63,</span><br><span class="line">  &quot;timed_out&quot; : false,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 5,</span><br><span class="line">    &quot;successful&quot; : 5,</span><br><span class="line">    &quot;skipped&quot; : 0,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : &#123;</span><br><span class="line">        &quot;value&quot;: 1000,</span><br><span class="line">        &quot;relation&quot;: &quot;eq&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;max_score&quot; : null,</span><br><span class="line">    &quot;hits&quot; : [ &#123;</span><br><span class="line">      &quot;_index&quot; : &quot;bank&quot;,</span><br><span class="line">      &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">      &quot;_id&quot; : &quot;0&quot;,</span><br><span class="line">      &quot;sort&quot;: [0],</span><br><span class="line">      &quot;_score&quot; : null,</span><br><span class="line">      &quot;_source&quot; : &#123;&quot;account_number&quot;:0,&quot;balance&quot;:16623,&quot;firstname&quot;:&quot;Bradshaw&quot;,&quot;lastname&quot;:&quot;Mckenzie&quot;,&quot;age&quot;:29,&quot;gender&quot;:&quot;F&quot;,&quot;address&quot;:&quot;244 Columbus Place&quot;,&quot;employer&quot;:&quot;Euron&quot;,&quot;email&quot;:&quot;bradshawmckenzie@euron.com&quot;,&quot;city&quot;:&quot;Hobucken&quot;,&quot;state&quot;:&quot;CO&quot;&#125;</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">      &quot;_index&quot; : &quot;bank&quot;,</span><br><span class="line">      &quot;_type&quot; : &quot;_doc&quot;,</span><br><span class="line">      &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">      &quot;sort&quot;: [1],</span><br><span class="line">      &quot;_score&quot; : null,</span><br><span class="line">      &quot;_source&quot; : &#123;&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;&#125;</span><br><span class="line">    &#125;, ...</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>took</code> 表示es花费了多久时间运行查询，单位：毫秒</p>
<p><code>timed_out</code> 查询是否超时</p>
<p>_shards 搜索了多少分片，包括成功，失败，跳过</p>
<p>max_score 相关的文档查询的分数</p>
<p>hit.total.value 多少文档被匹配</p>
<p>hit.sort 文档排序位置</p>
<p>hit._score 文档的相关性得分（不适用match_all）</p>
<p>字段中搜索特定单词，可以使用match</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET &quot;localhost:9200&#x2F;bank&#x2F;_search?pretty&quot; -H &#39;Content-Type: application&#x2F;json&#39; -d&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>

<p>需要执行词组搜索，而不是匹配单个词，使用match_phrase</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET &quot;localhost:9200&#x2F;bank&#x2F;_search?pretty&quot; -H &#39;Content-Type: application&#x2F;json&#39; -d&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>

<p>可以使用bool组合查询，可以使用指定范围（必须包含must match，渴望包含should match，和不希望包含must not match）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET &quot;localhost:9200&#x2F;bank&#x2F;_search?pretty&quot; -H &#39;Content-Type: application&#x2F;json&#39; -d&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;must_not&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>

<p>must，should会贡献相关性分数，must_not作为过滤器，不贡献相关性分数，返回的结果会根据相关性排序，越相关越在前面。也可以使用其他的过滤器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -X GET &quot;localhost:9200&#x2F;bank&#x2F;_search?pretty&quot; -H &#39;Content-Type: application&#x2F;json&#39; -d&#39;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;balance&quot;: &#123;</span><br><span class="line">            &quot;gte&quot;: 20000,</span><br><span class="line">            &quot;lte&quot;: 30000</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>

<p>聚合查询时，先通过terms将数据聚合，内嵌avg聚合函数将聚合的数据进行分组</p>
<h1 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h1><p>集成了promethus+grafana+elasticsearch_exporter。也可以用cerbro看。</p>
<ul>
<li>elasticsearch_exporter</li>
</ul>
<p>github：<a href="https://github.com/prometheus-community/elasticsearch_exporter" target="_blank" rel="noopener">https://github.com/prometheus-community/elasticsearch_exporter</a></p>
<p>比较傻瓜，下载下来之后，配置一下链接的elasticsearch_exporter即可，访问<a href="http://localhost:9114/metrics可以测试是否取到监控数据" target="_blank" rel="noopener">http://localhost:9114/metrics可以测试是否取到监控数据</a></p>
<ul>
<li>promethus</li>
</ul>
<p>github：<a href="https://github.com/prometheus/prometheus" target="_blank" rel="noopener">https://github.com/prometheus/prometheus</a></p>
<p>需要找到安装目录下的prometheus.yml文件，配置一下scrape_configs这一节，把exporter的地址配上去，配置手册如下：<a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config" target="_blank" rel="noopener">https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  # The job name is added as a label &#96;job&#x3D;&lt;job_name&gt;&#96; to any timeseries scraped from this config.</span><br><span class="line">  - job_name: &quot;elasticsearch_exporter&quot;</span><br><span class="line"></span><br><span class="line">    # metrics_path defaults to &#39;&#x2F;metrics&#39;</span><br><span class="line">    # scheme defaults to &#39;http&#39;.</span><br><span class="line"></span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&quot;localhost:9114&quot;]</span><br></pre></td></tr></table></figure>

<p>配置成功后，直接启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;prometheus --config.file&#x3D;prometheus.yml</span><br></pre></td></tr></table></figure>

<p>启动后，可以通过访问<a href="http://localhost:9090/metrics测试是否获取到监控指标数据" target="_blank" rel="noopener">http://localhost:9090/metrics测试是否获取到监控指标数据</a></p>
<ul>
<li>grafana</li>
</ul>
<p>官网：<a href="https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1&amp;platform=mac" target="_blank" rel="noopener">https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1&amp;platform=mac</a></p>
<p>下载后，配置文件在conf目录下，defaults.ini（里面有admin密码），官方文档如下：</p>
<p><a href="https://grafana.com/docs/grafana/latest/setup-grafana/configure-grafana/" target="_blank" rel="noopener">https://grafana.com/docs/grafana/latest/setup-grafana/configure-grafana/</a></p>
<p>启动命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;grafana-server web</span><br></pre></td></tr></table></figure>

<p>启动后，访问<a href="http://localhost:3000，默认账号密码都是admin">http://localhost:3000，默认账号密码都是admin</a></p>
<p>新增一个prometheus的数据源</p>
<p><img src="/2022/11/26/3_Elasticsearch/image5.png" alt="image-20220625171540368" loading="lazy"></p>
<p>然后可以导入相应的模板，elasticsearch的id：2322</p>
<p><img src="/2022/11/26/3_Elasticsearch/image4.png" alt="image-20220625171540368" loading="lazy"></p>
<p>会从官网下载一个模板，里面指标挺丰富的</p>
<p><img src="/2022/11/26/3_Elasticsearch/image5.png" alt="image-20220625171540368" loading="lazy"></p>
<p>效果如下：</p>
<p><img src="/2022/11/26/3_Elasticsearch/image5.png" alt="image-20220625171540368" loading="lazy"></p>
<h1 id="源码调试"><a href="#源码调试" class="headerlink" title="源码调试"></a>源码调试</h1><blockquote>
<p>源码使用的是gradlew构建，官网介绍：<a href="https://github.com/elastic/elasticsearch/blob/7.16/TESTING.asciidoc" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch/blob/7.16/TESTING.asciidoc</a></p>
</blockquote>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>组件</tag>
      </tags>
  </entry>
  <entry>
    <title>Kudu</title>
    <url>/2023/02/28/3_Kudu/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">



<blockquote>
<p>官网：<a href="https://kudu.apache.org/docs/" target="_blank" rel="noopener">https://kudu.apache.org/docs/</a></p>
<p>官网FAQ：<a href="https://kudu.apache.org/faq.html" target="_blank" rel="noopener">https://kudu.apache.org/faq.html</a></p>
<p>git：<a href="https://github.com/apache/kudu/tree/master/docs/design-docs" target="_blank" rel="noopener">https://github.com/apache/kudu/tree/master/docs/design-docs</a></p>
<p>变更历史：<a href="https://kudu.apache.org/blog/" target="_blank" rel="noopener">https://kudu.apache.org/blog/</a></p>
</blockquote>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Kudu是一款分布式，列式，OLAP的存储引擎。在OLAP负载下有着较快的处理速度，结构化数据模型，随机和顺序工作场景下的高性能，HDFS/impala/NiFi/Spark/hive等集成，健壮/灵活的一致性模型，RPC加密解密，高可用（Raft），自动失败监测（失败分片自动转移到另一个tabletServer上），机架感知，多行事务，易于管理，逻辑备份。</p>
<p><img src="/2023/02/28/3_Kudu/2.png" alt="image-20230228221535616" loading="lazy"></p>
<p>​                                                                                        Kudu网络架构（来自官网）</p>
<h2 id="Docker本地安装"><a href="#Docker本地安装" class="headerlink" title="Docker本地安装"></a>Docker本地安装</h2><ul>
<li>下载git源码</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;kudu</span><br><span class="line">cd kudu</span><br></pre></td></tr></table></figure>

<ul>
<li>暴露kudu ip</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUDU_QUICKSTART_IP=$(ifconfig | grep <span class="string">"inet "</span> | grep -Fv 127.0.0.1 |  awk <span class="string">'&#123;print $2&#125;'</span> | tail -1)</span><br></pre></td></tr></table></figure>

<ul>
<li>调整kudu版本</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUDU_QUICKSTART_VERSION=<span class="string">"1.12.0"</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动集群，-d表示后台运行，官网会启动5个tablet server（测试用3个tablet server），3个master节点，启动后<a href="http://localhost:8050/tablets" target="_blank" rel="noopener">http://localhost:8050/tablets</a> Ui界面可以查看集群情况</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose -f quickstart.yml up -d</span><br></pre></td></tr></table></figure>

<ul>
<li>测试运行</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUDU_USER_NAME=kudu</span><br><span class="line"><span class="built_in">cd</span> examples/java/java-example</span><br><span class="line">mvn package</span><br><span class="line">java -DkuduMasters=localhost:7051,localhost:7151,localhost:7251 -jar target/kudu-java-example-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<ul>
<li>查看日志</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker logs $(docker ps -aqf <span class="string">"name=kudu-tserver-1"</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>关闭</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose -f quickstart.yml down</span><br><span class="line">docker stop $(docker ps -aqf <span class="string">"name=kudu"</span>)</span><br><span class="line">docker rm $(docker ps -aqf <span class="string">"name=kudu"</span>)</span><br><span class="line">docker volume rm $(docker volume ls --filter name=kudu -q)</span><br></pre></td></tr></table></figure>





<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="Tablet"><a href="#Tablet" class="headerlink" title="Tablet"></a>Tablet</h2><p>Tablet刷新过程（来自官网）</p>
<p><img src="/2023/02/28/3_Kudu/4.png" alt loading="lazy"></p>
<p>小结（来自官网）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-----------+</span><br><span class="line">| MemRowSet |</span><br><span class="line">+-----------+</span><br><span class="line">  |</span><br><span class="line">  | flush: creates a new DiskRowSet 0</span><br><span class="line">  v</span><br><span class="line">+---------------+</span><br><span class="line">| DiskRowSet 0  |</span><br><span class="line">+---------------+</span><br><span class="line"></span><br><span class="line">DiskRowSet 1:</span><br><span class="line">+---------+     +------------+      +---------+     +---------+     +---------+     +---------+</span><br><span class="line">| UNDOs 0 | --&gt; | base data  | &lt;--- | REDOs 0 | &lt;-- | REDOS 1 | &lt;-- | REDOs 2 | &lt;-- | REDOs 3 |</span><br><span class="line">+---------+     +------------+      +---------+     +---------+     +---------+     +---------+</span><br><span class="line">\____________________________________________________________&#x2F;</span><br><span class="line">                           | major compaction</span><br><span class="line">                           v</span><br><span class="line"></span><br><span class="line">+---------+     +------------+      +---------+     +---------+</span><br><span class="line">| UNDOs 0&#39;| --&gt; | base data&#39; | &lt;--- | REDOs 2 | &lt;-- | REDOs 3 |</span><br><span class="line">+---------+     +------------+      +---------+     +---------+</span><br><span class="line">\____________________________&#x2F;</span><br><span class="line">      compaction result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DiskRowSet 2:</span><br><span class="line">+---------+     +------------+      +---------+     +---------+     +---------+     +---------+</span><br><span class="line">| UNDOs 0 | --&gt; | base data  | &lt;--- | REDOs 0 | &lt;-- | REDOS 1 | &lt;-- | REDOs 2 | &lt;-- | REDOs 3 |</span><br><span class="line">+---------+     +------------+      +---------+     +---------+     +---------+     +---------+</span><br><span class="line">                                    \_________________________&#x2F;</span><br><span class="line">                                         | minor compaction</span><br><span class="line">                                         v</span><br><span class="line">+---------+     +------------+      +---------+      +---------+     +---------+</span><br><span class="line">| UNDOs 0 | --&gt; | base data  | &lt;--- | REDOS 0&#39;|  &lt;-- | REDOs 2 | &lt;-- | REDOs 3 |</span><br><span class="line">+---------+     +------------+      +---------+      +---------+     +---------+</span><br><span class="line">                                    \_________&#x2F;</span><br><span class="line">                                 compaction result</span><br><span class="line"></span><br><span class="line">+-----------------+ \</span><br><span class="line">| DiskRowSet 3    | |</span><br><span class="line">+-----------------+ |</span><br><span class="line">                    |</span><br><span class="line">+-----------------+ |                              +----------------+</span><br><span class="line">| DiskRowSet 4    | |&#x3D;&#x3D;&#x3D;&gt; Merging compaction &#x3D;&#x3D;&#x3D;&gt;  | new DiskRowSet |</span><br><span class="line">+-----------------+ |                              +----------------+</span><br><span class="line">                    |</span><br><span class="line">+-----------------+ |</span><br><span class="line">| DiskRowSet 5    | |</span><br><span class="line">+-----------------+ &#x2F;</span><br></pre></td></tr></table></figure>





<ul>
<li>主要读取操作</li>
</ul>
<blockquote>
<p>通过各种迭代器，从内存和磁盘中读取相关数据，这里的迭代器各种封装，最终磁盘底层由CFile或DeltaTracker检索，内存检索BTree，并结合去重，合并，谓词下推，Key范围剪枝等迭代器进行优化，最终返回数据</p>
</blockquote>
<p><img src="/2023/02/28/3_Kudu/5.png" alt loading="lazy"></p>
<ul>
<li>主要写入操作</li>
</ul>
<blockquote>
<ol>
<li>插入和部分更新删除（MemRowSet未flush到磁盘时），会写入到MemRowSet，MemRowSet是BTree结构；</li>
<li>当MemRowSet超过一定大小后，会溢写到磁盘，形成BaseFile（CFile），一个RowSet也包含多行记录，按rowid排序。同时会保留UndoFile；</li>
<li>BaseFile和RedoFIle会触发Major Compact，减少DeltaFile数量。较早的UndoFile会因为时间较久而被清理</li>
<li>大部分更新删除操作会写入Delta MemStore，也是一个BTree结构；</li>
<li>当Memstore超过一定大小，会溢写到磁盘，形成RedoFile（CFile）；</li>
<li>部分RedoFile会频繁执行小范围的 Minor Compact，减少DeltaFile数量；</li>
<li>多个DiskRowSet会触发Merge Compact，减少重复的主键Key的重叠率。</li>
</ol>
</blockquote>
<p><img src="/2023/02/28/3_Kudu/3.png" alt="image-20230228221535616" loading="lazy"></p>
<h2 id="查询加速"><a href="#查询加速" class="headerlink" title="查询加速"></a>查询加速</h2><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><p>Hase</p>
<p>Range</p>
<p>混合</p>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>主键索引</p>
<p>跳表索引（Skip Scan Index）</p>
<h1 id="基准测试"><a href="#基准测试" class="headerlink" title="基准测试"></a>基准测试</h1><h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1><h1 id="其他组件对比"><a href="#其他组件对比" class="headerlink" title="其他组件对比"></a>其他组件对比</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>Kudu读取流程：<a href="https://zhuanlan.zhihu.com/p/496397719" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/496397719</a></p>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
  </entry>
  <entry>
    <title>Kafka</title>
    <url>/2022/11/13/3_Kafka/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<p>Kafka作为高性能事件流平台，可以存储，发布订阅，处理各种流事件，被广泛用于消息中间件，流处理组件等应用上。</p>
<p>Log消息存储</p>
<p><a href="https://kafka.apache.org/0100/documentation.html#log" target="_blank" rel="noopener">https://kafka.apache.org/0100/documentation.html#log</a></p>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><h2 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h2><ul>
<li>发送消息</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/kafka-console-producer.sh --broker-list localhost:9092  --topic tmp-offset</span><br></pre></td></tr></table></figure>

<ul>
<li>消费消息</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic tmp-offset --from-beginning --group aaaa123</span><br></pre></td></tr></table></figure>

<ul>
<li>查看消费者偏移量</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic tmp-offset</span><br></pre></td></tr></table></figure>



<h2 id="spring-kafka"><a href="#spring-kafka" class="headerlink" title="spring-kafka"></a>spring-kafka</h2><ul>
<li>定义kafka配置</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ConsumerFactory&lt;Integer, String&gt; <span class="title">consumerFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerProps());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">consumerProps</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; props = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"group"</span>);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br><span class="line">        <span class="comment">//2 手动提交offset</span></span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="string">"false"</span>);</span><br><span class="line"><span class="comment">//3. 分配策略，改为随机分配</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, "org.apache.kafka.clients.consumer.RoundRobinAssignor");</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerFactory&lt;Integer, String&gt; <span class="title">producerFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(senderProps());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">senderProps</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; props = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">10</span>);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        <span class="comment">//...</span></span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"> <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> KafkaTemplate&lt;Integer, String&gt; <span class="title">kafkaTemplate</span><span class="params">(ProducerFactory&lt;Integer, String&gt; producerFactory)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> KafkaTemplate&lt;Integer, String&gt;(producerFactory);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafkaContainerFactory(ConsumerFactory&lt;Integer, String&gt; consumerFactory) &#123;</span><br><span class="line">        ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = <span class="keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();</span><br><span class="line">        factory.setConsumerFactory(consumerFactory);</span><br><span class="line">        factory.setConcurrency(<span class="number">3</span>);</span><br><span class="line">        factory.getContainerProperties().setPollTimeout(<span class="number">3000</span>);</span><br><span class="line">        <span class="keyword">return</span> factory;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>消费者</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Service</span><br><span class="line">public class TestConsumer &#123;</span><br><span class="line"></span><br><span class="line">    @KafkaListener(topics &#x3D; &quot;bid-uc&quot;,</span><br><span class="line">            groupId &#x3D; &quot;saas-mcloud-cdp-bid-uc-tag-core&quot;,</span><br><span class="line">            containerFactory &#x3D; &quot;kafkaContainerFactory&quot;)</span><br><span class="line">    public void test(ConsumerRecord&lt;String, String&gt; record)&#123;</span><br><span class="line">        System.out.println(&quot;项目2收到消息：&quot;+record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>查看topic详情，调整partitions到3（提前设置好partitions）</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --zookeeper localhost:2181 --describe --topic bid-uc</span><br><span class="line">./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group saas-mcloud-cdp-bid-uc-tag-core</span><br><span class="line">./kafka-topics.sh --zookeeper localhost:2181 --alter --topic bid-uc --partitions 3</span><br></pre></td></tr></table></figure>

<ul>
<li>发送消息</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;kafka-console-producer.sh --broker-list localhost:9092  --topic bid-uc 123</span><br></pre></td></tr></table></figure>

<p>当topic已经创建后，partitions调整到3，等待一段时间后，kafka会自动重新分配。</p>
<ul>
<li>根据时间重放消息</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1. 定义消费者</span></span><br><span class="line">Map&lt;String, Object&gt; props = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"localhost:9092"</span>);</span><br><span class="line">props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"><span class="comment">//消费组名</span></span><br><span class="line">props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"aaaa123"</span>);</span><br><span class="line"><span class="comment">//取消自动提交</span></span><br><span class="line">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">//批量消费数量</span></span><br><span class="line">props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, <span class="number">10</span>);</span><br><span class="line"><span class="comment">//批量消费数量</span></span><br><span class="line">props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, <span class="number">2000</span>);</span><br><span class="line"><span class="comment">//重置策略</span></span><br><span class="line">props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"latest"</span>);</span><br><span class="line"></span><br><span class="line">String topicName=<span class="string">"tmp-offset"</span>;</span><br><span class="line"><span class="comment">//初始化</span></span><br><span class="line">KafkaConsumer kafkaConsumer = <span class="keyword">new</span> KafkaConsumer(props);</span><br><span class="line">kafkaConsumer.subscribe(Arrays.asList(topicName));</span><br><span class="line"></span><br><span class="line"><span class="comment">//等待重分配后，保证kafkaConsumer.assignment()有值</span></span><br><span class="line"><span class="keyword">while</span> (kafkaConsumer.assignment().isEmpty()) &#123;</span><br><span class="line">  kafkaConsumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//指定时间点</span></span><br><span class="line"><span class="keyword">long</span> startTime = LocalDateTime.of(<span class="number">2023</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">19</span>, <span class="number">29</span>).</span><br><span class="line">  toInstant(ZoneOffset.ofHours(<span class="number">8</span>)).toEpochMilli();</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过通过seek重定位到待消费的地方</span></span><br><span class="line">Map&lt;TopicPartition, Long&gt; timeToSearch = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">Set&lt;TopicPartition&gt; assignment = kafkaConsumer.assignment();</span><br><span class="line"><span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line">  timeToSearch.put(topicPartition, startTime);</span><br><span class="line">&#125;</span><br><span class="line">Map&lt;TopicPartition, OffsetAndTimestamp&gt; map = kafkaConsumer.offsetsForTimes(timeToSearch);</span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;TopicPartition, OffsetAndTimestamp&gt; entry : map.entrySet()) &#123;</span><br><span class="line">  System.out.println(<span class="string">"entry.getValue().offset()="</span>+entry.getValue().offset());</span><br><span class="line">  kafkaConsumer.seek(entry.getKey(), entry.getValue().offset());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//开始消费</span></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">  ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">  <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">    System.out.printf(<span class="string">"消费到消息 partition = %d, offset = %d, key = %s, value = %s%n"</span>, record.partition(),record.offset(), record.key(), record.value());</span><br><span class="line">  &#125;</span><br><span class="line">  Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="Offset为什么会中间不连续"><a href="#Offset为什么会中间不连续" class="headerlink" title="Offset为什么会中间不连续"></a>Offset为什么会中间不连续</h2><p>大概率是启用了事务，开启事务时，Kafka会先提交消息，占用offset，但该消息并不被”读已提交隔离级别的”的消费者可见，直到再次发送方确定事务提交后，消费者才能看到该消息。</p>
<h2 id="如果本地没有提交偏移量，那下次拉取还能拉取到这个消息吗？"><a href="#如果本地没有提交偏移量，那下次拉取还能拉取到这个消息吗？" class="headerlink" title="如果本地没有提交偏移量，那下次拉取还能拉取到这个消息吗？"></a>如果本地没有提交偏移量，那下次拉取还能拉取到这个消息吗？</h2><p>严格来说，需要分为3种场景，简而言之，保险起见，可以调用seek方法，重置消费者的Subscription，确保能够再次拉取到消息</p>
<ul>
<li>a) 消费者客户端重启，此时由于<strong>Subscriptions重置</strong>，会从当前offset开始拉取，则下次拉取可以拉到旧消息；</li>
<li>b) 消费者未重启，消费线程报错，但恰好本轮poll时间结束，进入下一轮拉取，未提交偏移量，那在下一次拉取时，由于<strong>Subscriptitions会重置</strong>，依然可以拉取到旧消息；</li>
<li>c) 消费者未重启，消费线程报错，但依然在本轮poll内，由于消费者拉取时，缓存了Subscriptitions，不会重置，因此，会拉取到最新的消息。</li>
</ul>
<p>Fetch流程图</p>
<p><img src="/2022/11/13/3_Kafka/image7.png" alt="image-20230228221535616" loading="lazy"></p>
<p>源码流程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.kafka.clients.consumer.KafkaConsumer#poll(org.apache.kafka.common.utils.Timer, boolean)</span><br><span class="line"></span><br><span class="line">private ConsumerRecords&lt;K, V&gt; poll(final Timer timer, final boolean includeMetadataInTimeout) &#123;</span><br><span class="line">        acquireAndEnsureOpen();</span><br><span class="line">        try &#123;</span><br><span class="line">            &#x2F;&#x2F; 省略校验 </span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; poll for new data until the timeout expires</span><br><span class="line">            do &#123;</span><br><span class="line">                &#x2F;&#x2F; 省略前置处理，updateAssignmentMetadataIfNeeded需要重点关注下，这里是缓存消费方偏移量的地方，通过定时拉取，获取每个topic，partition的当前offset（未提交的offset）</span><br><span class="line">                </span><br><span class="line">								&#x2F;&#x2F; 拉取的核心方法</span><br><span class="line">                final Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records &#x3D; pollForFetches(timer);</span><br><span class="line">                if (!records.isEmpty()) &#123;</span><br><span class="line">                    &#x2F;&#x2F; 省略拉取到消息的超时处理</span><br><span class="line"></span><br><span class="line">										&#x2F;&#x2F; 返回结果</span><br><span class="line">                    return this.interceptors.onConsume(new ConsumerRecords&lt;&gt;(records));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; while (timer.notExpired());</span><br><span class="line"></span><br><span class="line">            return ConsumerRecords.empty();</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            release();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    org.apache.kafka.clients.consumer.KafkaConsumer#pollForFetches</span><br><span class="line">    private Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollForFetches(Timer timer) &#123;</span><br><span class="line">        long pollTimeout &#x3D; coordinator &#x3D;&#x3D; null ? timer.remainingMs() :</span><br><span class="line">                Math.min(coordinator.timeToNextPoll(timer.currentTimeMs()), timer.remainingMs());</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 尝试获取拉取到的数据</span><br><span class="line">        final Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records &#x3D; fetcher.fetchedRecords();</span><br><span class="line">        if (!records.isEmpty()) &#123;</span><br><span class="line">            return records;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 发送拉取数据的请求</span><br><span class="line">        fetcher.sendFetches();</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 省略一堆看不懂的有关时间和的处理</span><br><span class="line"></span><br><span class="line">    		&#x2F;&#x2F; 获取拉取的数据</span><br><span class="line">        return fetcher.fetchedRecords();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    org.apache.kafka.clients.consumer.internals.Fetcher#sendFetches</span><br><span class="line">    public synchronized int sendFetches() &#123;</span><br><span class="line">        &#x2F;&#x2F; Update metrics in case there was an assignment change</span><br><span class="line">        sensors.maybeUpdateAssignment(subscriptions);</span><br><span class="line"></span><br><span class="line">        Map&lt;Node, FetchSessionHandler.FetchRequestData&gt; fetchRequestMap &#x3D; prepareFetchRequests();</span><br><span class="line">        for (Map.Entry&lt;Node, FetchSessionHandler.FetchRequestData&gt; entry : fetchRequestMap.entrySet()) &#123;</span><br><span class="line">            &#x2F;&#x2F; 省略 构造拉取数据请求</span><br><span class="line">            </span><br><span class="line">            &#x2F;&#x2F; 发起客户端调用，拉取数据，返回Future对象</span><br><span class="line">            RequestFuture&lt;ClientResponse&gt; future &#x3D; client.send(fetchTarget, request);</span><br><span class="line">          </span><br><span class="line">          	&#x2F;&#x2F; 省略部分代码</span><br><span class="line">            this.nodesWithPendingFetchRequests.add(entry.getKey().id());</span><br><span class="line">            </span><br><span class="line">            &#x2F;&#x2F; Future调用成功后回调</span><br><span class="line">            future.addListener(new RequestFutureListener&lt;ClientResponse&gt;() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onSuccess(ClientResponse resp) &#123;</span><br><span class="line">                    synchronized (Fetcher.this) &#123;</span><br><span class="line">                        try &#123;</span><br><span class="line">                            @SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">                            FetchResponse&lt;Records&gt; response &#x3D; (FetchResponse&lt;Records&gt;) resp.responseBody();</span><br><span class="line">                            </span><br><span class="line">                        		&#x2F;&#x2F; 省略拉取到数据的处理方法</span><br><span class="line">                            for (Map.Entry&lt;TopicPartition, FetchResponse.PartitionData&lt;Records&gt;&gt; entry : response.responseData().entrySet()) &#123;</span><br><span class="line">                                TopicPartition partition &#x3D; entry.getKey();</span><br><span class="line">                                FetchRequest.PartitionData requestData &#x3D; data.sessionPartitions().get(partition);</span><br><span class="line">                                if (requestData &#x3D;&#x3D; null) &#123;</span><br><span class="line">                                	 &#x2F;&#x2F; 省略未获取到数据的情况</span><br><span class="line">                                &#125; else &#123;</span><br><span class="line">                                    long fetchOffset &#x3D; requestData.fetchOffset;</span><br><span class="line">                                    &#x2F;&#x2F; 省略获取到数据的处理</span><br><span class="line">                                    </span><br><span class="line">                                    &#x2F;&#x2F; 1. 重点，返回参数里，会根据请求参数，获取最新未完成提交的fetchOffset（情况1：消费方未提交offset时异常，那重启后，这里一般会返回未提交的最后一个位点，以便能够继续拉取消息，情况2：消费方已经启动了，但是offset落后集群，但是此时来了一条新数据，这里一般会返回最新的offset，因为请求参数里，携带的是最早的offset）</span><br><span class="line">                                    completedFetches.add(new CompletedFetch(partition, fetchOffset, fetchData, metricAggregator,</span><br><span class="line">                                            resp.requestHeader().apiVersion()));</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            sensors.fetchLatency.record(resp.requestLatencyMs());</span><br><span class="line">                        &#125; finally &#123;</span><br><span class="line">                            nodesWithPendingFetchRequests.remove(fetchTarget.id());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                @Override</span><br><span class="line">                public void onFailure(RuntimeException e) &#123;</span><br><span class="line">                    &#x2F;&#x2F;省略失败处理</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        return fetchRequestMap.size();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    org.apache.kafka.clients.consumer.internals.Fetcher#fetchedRecords</span><br><span class="line">    public Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetchedRecords() &#123;</span><br><span class="line">        Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetched &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        int recordsRemaining &#x3D; maxPollRecords;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            while (recordsRemaining &gt; 0) &#123;</span><br><span class="line">                if (nextInLineRecords &#x3D;&#x3D; null || nextInLineRecords.isFetched) &#123;</span><br><span class="line">                    CompletedFetch completedFetch &#x3D; completedFetches.peek();</span><br><span class="line">                    if (completedFetch &#x3D;&#x3D; null) break;</span><br><span class="line"></span><br><span class="line">                    try &#123;</span><br><span class="line">                    		&#x2F;&#x2F; 2. 这里从已完成的拉取里面（completedFetch）获取构造获取下一次拉取的数据</span><br><span class="line">                        nextInLineRecords &#x3D; parseCompletedFetch(completedFetch);</span><br><span class="line">                    &#125; catch (Exception e) &#123;</span><br><span class="line">                        &#x2F;&#x2F; 省略异常处理</span><br><span class="line">                    &#125;</span><br><span class="line">                    &#x2F;&#x2F;3. 获取完就移除completedFetch队头元素</span><br><span class="line">                    completedFetches.poll();</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                  	&#x2F;&#x2F; 利用上一个if中构造的nextInLineRecords，解析nextInLineRecords，获取到这一批的数据</span><br><span class="line">                    List&lt;ConsumerRecord&lt;K, V&gt;&gt; records &#x3D; fetchRecords(nextInLineRecords, recordsRemaining);</span><br><span class="line">                    TopicPartition partition &#x3D; nextInLineRecords.partition;</span><br><span class="line">                    if (!records.isEmpty()) &#123;</span><br><span class="line">                        &#x2F;&#x2F; 省略获取到数据的处理</span><br><span class="line">                        </span><br><span class="line">                        &#x2F;&#x2F; 并继续尝试获取下一批</span><br><span class="line">                        recordsRemaining -&#x3D; records.size();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (KafkaException e) &#123;</span><br><span class="line">            if (fetched.isEmpty())</span><br><span class="line">                throw e;</span><br><span class="line">        &#125;</span><br><span class="line">        return fetched;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    org.apache.kafka.clients.consumer.internals.Fetcher#fetchRecords</span><br><span class="line">    private List&lt;ConsumerRecord&lt;K, V&gt;&gt; fetchRecords(PartitionRecords partitionRecords, int maxRecords) &#123;</span><br><span class="line">        if (!subscriptions.isAssigned(partitionRecords.partition)) &#123;</span><br><span class="line">             &#x2F;&#x2F; 省略</span><br><span class="line">        &#125; else if (!subscriptions.isFetchable(partitionRecords.partition)) &#123;</span><br><span class="line">            &#x2F;&#x2F; 省略</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            SubscriptionState.FetchPosition position &#x3D; subscriptions.position(partitionRecords.partition);</span><br><span class="line">            if (partitionRecords.nextFetchOffset &#x3D;&#x3D; position.offset) &#123;</span><br><span class="line">								&#x2F;&#x2F; 重点返回数据方法，该方法会更新partitionRecords的nextFetchOffset，不断拉取数据</span><br><span class="line">                List&lt;ConsumerRecord&lt;K, V&gt;&gt; partRecords &#x3D; partitionRecords.fetchRecords(maxRecords);</span><br><span class="line"></span><br><span class="line">                if (partitionRecords.nextFetchOffset &gt; position.offset) &#123;</span><br><span class="line">                		&#x2F;&#x2F; 如果新的下一段offset大于本地缓存的offset，则需要更新本地offset缓存</span><br><span class="line">                    SubscriptionState.FetchPosition nextPosition &#x3D; new SubscriptionState.FetchPosition(</span><br><span class="line">                            partitionRecords.nextFetchOffset,</span><br><span class="line">                            partitionRecords.lastEpoch,</span><br><span class="line">                            position.currentLeader);</span><br><span class="line">                    log.trace(&quot;Returning fetched records at offset &#123;&#125; for assigned partition &#123;&#125; and update &quot; +</span><br><span class="line">                            &quot;position to &#123;&#125;&quot;, position, partitionRecords.partition, nextPosition);</span><br><span class="line">                    subscriptions.position(partitionRecords.partition, nextPosition);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; 省略更新其他数据</span><br><span class="line">                </span><br><span class="line">                &#x2F;&#x2F; 返回拉取的数据对象</span><br><span class="line">                return partRecords;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                &#x2F;&#x2F; 省略</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        partitionRecords.drain();</span><br><span class="line">        return emptyList();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h1 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h1><blockquote>
<p>监控的指标有很多，这里以监控消费偏移量作为示例，其他指标类似</p>
</blockquote>
<h2 id="指标来源"><a href="#指标来源" class="headerlink" title="指标来源"></a>指标来源</h2><p>数据有多种来源</p>
<ol>
<li>Kafka自带的命令行，需要进去集群环境</li>
<li>Kafka集群和消费者应用暴露的jmx指标，无第三方，且指标丰富</li>
<li>Kafka_exporter收集指标，第三方托管，使用起来方便</li>
</ol>
<h3 id="命令行-1"><a href="#命令行-1" class="headerlink" title="命令行"></a>命令行</h3><p>查看消费的消息，需要指定到消费分组，可以看到当前提交偏移量为1，lag=2</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  bin .&#x2F;kafka-consumer-groups.sh --bootstrap-server localhost:9092  --describe --group myGroup</span><br><span class="line"></span><br><span class="line">TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID</span><br><span class="line">demo-topic      0          1               3               2               consumer-1-a86bbec5-c078-4f8e-864f-0a0b6b4717f6 &#x2F;127.0.0.1      consumer-1</span><br></pre></td></tr></table></figure>



<h3 id="Jmx指标"><a href="#Jmx指标" class="headerlink" title="Jmx指标"></a>Jmx指标</h3><p>查看对应kafka版本暴露的jmx指标，这里使用的是kafka的2.1.0版本，<a href="https://kafka.apache.org/21/documentation.html#monitoring" target="_blank" rel="noopener">https://kafka.apache.org/21/documentation.html#monitoring</a></p>
<blockquote>
<p>需要注意的是，server在kafka集群端暴露，producer和consumer是在具体的实例上暴露</p>
</blockquote>
<p>服务端启动时，是需要暴露jmx端口的，这里需要改一下启动参数，修改kafka-server-start.sh文件，在开头增加参数，启动即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JMX_PORT=9581</span><br></pre></td></tr></table></figure>

<p>此时，使用jdk自带的jconsoles可以查看到对应mbean</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./Library/Java/JavaVirtualMachines/jdk-1.8.jdk/Contents/Home/bin/jconsole</span><br></pre></td></tr></table></figure>

<p>页面如下</p>
<p><img src="/2022/11/13/3_Kafka/image1.png" alt="image-20230228221535616" loading="lazy"></p>
<p>这里是消费者实例的jmx，可以看到消费过2个消息，但并不是lag！（没找到只通过jmx如何判断lag的方式）</p>
<p><img src="/2022/11/13/3_Kafka/image2.png" alt="image-20230228221535616" loading="lazy"></p>
<p>另外还有一点，如果要暴露到prometheus，由于jmx的格式不适应prometheus，prometheus提供了kafka的转换agent，地址为：</p>
<p><a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">https://github.com/prometheus/jmx_exporter</a></p>
<p>放在kafka启动目录下，指定jmx暴露代理，修改kafka启动目录下的kafka-server-start.sh文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KAFKA_OPTS=<span class="string">"-javaagent:/Users/weiqian/Documents/1_apache/apache-kafka-2.12-2.1.0/bin/jmx_prometheus_javaagent-0.17.0.jar=9990:/Users/weiqian/Documents/1_apache/apache-kafka-2.12-2.1.0/bin/jmx-kafka.yml"</span></span><br></pre></td></tr></table></figure>

<p>其中jmx-kafka.yml是jmx_exporter提供的示例</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lowercaseOutputName: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">rules:</span><br><span class="line"><span class="comment"># Special cases and very specific rules</span></span><br><span class="line">- pattern : kafka.server&lt;<span class="built_in">type</span>=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_server_<span class="variable">$1_</span><span class="variable">$2</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    clientId: <span class="string">"<span class="variable">$3</span>"</span></span><br><span class="line">    topic: <span class="string">"<span class="variable">$4</span>"</span></span><br><span class="line">    partition: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">- pattern : kafka.server&lt;<span class="built_in">type</span>=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_server_<span class="variable">$1_</span><span class="variable">$2</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    clientId: <span class="string">"<span class="variable">$3</span>"</span></span><br><span class="line">    broker: <span class="string">"<span class="variable">$4</span>:<span class="variable">$5</span>"</span></span><br><span class="line">- pattern : kafka.coordinator.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_coordinator_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generic per-second counters with 0-2 key/value pairs</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)PerSec\w*, (.+)=(.+), (.+)=(.+)&gt;&lt;&gt;Count</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_total</span></span><br><span class="line">  <span class="built_in">type</span>: COUNTER</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">    <span class="string">"<span class="variable">$6</span>"</span>: <span class="string">"<span class="variable">$7</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)PerSec\w*, (.+)=(.+)&gt;&lt;&gt;Count</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_total</span></span><br><span class="line">  <span class="built_in">type</span>: COUNTER</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)PerSec\w*&gt;&lt;&gt;Count</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_total</span></span><br><span class="line">  <span class="built_in">type</span>: COUNTER</span><br><span class="line"></span><br><span class="line"><span class="comment"># Quota specific rules</span></span><br><span class="line">- pattern: kafka.server&lt;<span class="built_in">type</span>=(.+), user=(.+), client-id=(.+)&gt;&lt;&gt;([a-z-]+)</span><br><span class="line">  name: kafka_server_quota_<span class="variable">$4</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    resource: <span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">    user: <span class="string">"<span class="variable">$2</span>"</span></span><br><span class="line">    clientId: <span class="string">"<span class="variable">$3</span>"</span></span><br><span class="line">- pattern: kafka.server&lt;<span class="built_in">type</span>=(.+), client-id=(.+)&gt;&lt;&gt;([a-z-]+)</span><br><span class="line">  name: kafka_server_quota_<span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    resource: <span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">    clientId: <span class="string">"<span class="variable">$2</span>"</span></span><br><span class="line">- pattern: kafka.server&lt;<span class="built_in">type</span>=(.+), user=(.+)&gt;&lt;&gt;([a-z-]+)</span><br><span class="line">  name: kafka_server_quota_<span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    resource: <span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">    user: <span class="string">"<span class="variable">$2</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Generic gauges with 0-2 key/value pairs</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+), (.+)=(.+), (.+)=(.+)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">    <span class="string">"<span class="variable">$6</span>"</span>: <span class="string">"<span class="variable">$7</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+), (.+)=(.+)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line"></span><br><span class="line"><span class="comment"># Emulate Prometheus 'Summary' metrics for the exported 'Histogram's.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Note that these are missing the '_sum' metric!</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+), (.+)=(.+), (.+)=(.+)&gt;&lt;&gt;Count</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_count</span></span><br><span class="line">  <span class="built_in">type</span>: COUNTER</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">    <span class="string">"<span class="variable">$6</span>"</span>: <span class="string">"<span class="variable">$7</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+), (.+)=(.*), (.+)=(.+)&gt;&lt;&gt;(\d+)thPercentile</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">    <span class="string">"<span class="variable">$6</span>"</span>: <span class="string">"<span class="variable">$7</span>"</span></span><br><span class="line">    quantile: <span class="string">"0.<span class="variable">$8</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+), (.+)=(.+)&gt;&lt;&gt;Count</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_count</span></span><br><span class="line">  <span class="built_in">type</span>: COUNTER</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+), (.+)=(.*)&gt;&lt;&gt;(\d+)thPercentile</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br><span class="line">    quantile: <span class="string">"0.<span class="variable">$6</span>"</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)&gt;&lt;&gt;Count</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_count</span></span><br><span class="line">  <span class="built_in">type</span>: COUNTER</span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)&gt;&lt;&gt;(\d+)thPercentile</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    quantile: <span class="string">"0.<span class="variable">$4</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Generic gauges for MeanRate Percent</span></span><br><span class="line"><span class="comment"># Ex) kafka.server&lt;type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent&gt;&lt;&gt;MeanRate</span></span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)Percent\w*&gt;&lt;&gt;MeanRate</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_percent</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)Percent\w*&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_percent</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">- pattern: kafka.(\w+)&lt;<span class="built_in">type</span>=(.+), name=(.+)Percent\w*, (.+)=(.+)&gt;&lt;&gt;Value</span><br><span class="line">  name: kafka_<span class="variable">$1_</span><span class="variable">$2_</span><span class="variable">$3_percent</span></span><br><span class="line">  <span class="built_in">type</span>: GAUGE</span><br><span class="line">  labels:</span><br><span class="line">    <span class="string">"<span class="variable">$4</span>"</span>: <span class="string">"<span class="variable">$5</span>"</span></span><br></pre></td></tr></table></figure>





<h3 id="Kafka-Exporter"><a href="#Kafka-Exporter" class="headerlink" title="Kafka_Exporter"></a>Kafka_Exporter</h3><p>exporter的方式就比较简单了，直接启动kafka_exporter包，配置kafka的监听路径，地址：<a href="https://github.com/danielqsj/kafka_exporter" target="_blank" rel="noopener">https://github.com/danielqsj/kafka_exporter</a> 启动命令为</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./kafka_exporter --kafka.server=localhost:9092</span><br><span class="line"></span><br><span class="line">I1015 16:13:40.495902   12383 kafka_exporter.go:800] Starting kafka_exporter (version=1.7.0, branch=HEAD, revision=7e840e81a0170375214e2c1e1dc7ce94aeff8712)</span><br><span class="line">I1015 16:13:40.501380   12383 kafka_exporter.go:971] Listening on HTTP :9308</span><br></pre></td></tr></table></figure>

<p>访问<a href="http://127.0.0.1:9308/metrics" target="_blank" rel="noopener">http://127.0.0.1:9308/metrics</a> 可以看到监控信息</p>
<p><img src="/2022/11/13/3_Kafka/image3.png" alt="image-20230228221535616" loading="lazy"></p>
<h2 id="展示"><a href="#展示" class="headerlink" title="展示"></a>展示</h2><p>直接采用常用的Prometheus+grafana，</p>
<h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><p>下载Prometheus安装包，官网如下：<a href="https://prometheus.io/docs/introduction/first_steps/" target="_blank" rel="noopener">https://prometheus.io/docs/introduction/first_steps/</a></p>
<p>需要配置相关的exporter的端口，这里参考官方文档即可，prometheus.yml如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># my global config</span></span><br><span class="line">global:</span><br><span class="line">  scrape_interval: 15s <span class="comment"># Set the scrape interval to every 15 seconds. Default is every 1 minute.</span></span><br><span class="line">  evaluation_interval: 15s <span class="comment"># Evaluate rules every 15 seconds. The default is every 1 minute.</span></span><br><span class="line">  <span class="comment"># scrape_timeout is set to the global default (10s).</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># A scrape configuration containing exactly one endpoint to scrape:</span></span><br><span class="line"><span class="comment"># Here it's Prometheus itself.</span></span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: <span class="string">"elasticsearch_exporter"</span></span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [<span class="string">"localhost:9114"</span>]</span><br><span class="line"></span><br><span class="line">  - job_name: <span class="string">"kafka_jmx"</span></span><br><span class="line">    metrics_path: /metrics</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [<span class="string">'127.0.0.1:9990'</span>]</span><br><span class="line"></span><br><span class="line">  - job_name: <span class="string">"kafka_export"</span></span><br><span class="line">    metrics_path: /metrics</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [<span class="string">'127.0.0.1:9308'</span>]</span><br></pre></td></tr></table></figure>

<p>启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./prometheus --config.file=prometheus.yml</span><br></pre></td></tr></table></figure>

<p>默认访问：<a href="http://localhost:9090/" target="_blank" rel="noopener">http://localhost:9090/</a></p>
<p><img src="/2022/11/13/3_Kafka/image4.png" alt="image-20230228221535616" loading="lazy"></p>
<h3 id="Grafana"><a href="#Grafana" class="headerlink" title="Grafana"></a>Grafana</h3><p>下载Grafana安装包，官网如下：<a href="https://grafana.com/docs/grafana/latest/getting-started/get-started-grafana-prometheus/" target="_blank" rel="noopener">https://grafana.com/docs/grafana/latest/getting-started/get-started-grafana-prometheus/</a></p>
<p>启动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./grafana-server web</span><br></pre></td></tr></table></figure>

<p>访问：<a href="http://localhost:3000/" target="_blank" rel="noopener">http://localhost:3000/</a></p>
<p><img src="/2022/11/13/3_Kafka/image5.png" alt="image-20230228221535616" loading="lazy"></p>
<p>当然，这里的模板还是要借鉴一下神通广大的网友，自己配费劲，比如：<a href="https://grafana.com/grafana/dashboards/7589-kafka-exporter-overview/" target="_blank" rel="noopener">https://grafana.com/grafana/dashboards/7589-kafka-exporter-overview/</a></p>
<p><img src="/2022/11/13/3_Kafka/image6.png" alt="image-20230228221535616" loading="lazy"></p>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>组件</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis使用指南</title>
    <url>/2021/12/20/3_Redis/</url>
    <content><![CDATA[<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><p>主从（主读写，从读）</p>
<p>哨兵模式（故障自动转移）</p>
<p>集群模式（分片部署）</p>
<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><blockquote>
<p>较为常用的数据结构，Value最大范围可以达到512MB，但是工作中使用考虑到使用效率问题，一般参考阿里巴巴的开发手册要求，认为超过1M的数据可认为是大数据</p>
</blockquote>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>Set/get</p>
<p>设置/获取key中的值，不支持直接设置过期时间</p>
<p>etnx</p>
<p>是”<strong>SET</strong> if <strong>N</strong>ot e<strong>X</strong>ists”的简写，原子命令，如果存在则不会更新</p>
<p>Setex</p>
<p>设置值的同时设置过期时间，类似的有PsetEx</p>
<p>IncrBy/decrBy</p>
<p>增加/减少，要求value的值是可以转化为Integer类型，如果不能正确转化，则会报错</p>
<p>Mget/Mset/Msetnx</p>
<p>批量获取/批量设置</p>
<p>Getset/GetDel/GetEx</p>
<p>Get操作后附带的操作，其中，GetSet是1.0版本就有的，而GetDel/GetEx需要到6.2之后</p>
<p>其他命令参考文档：<a href="https://redis.io/commands/append" target="_blank" rel="noopener">https://redis.io/commands/append</a></p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>作为最常用的Redis命令，可以原子设置过期时间，避免缓存-数据库一致性这个问题，常用于验证码缓存等短期缓存场景。</p>
<h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><h3 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h3><p>Lpush/Lpush，Lpop/Lpop</p>
<p>从左侧/从右侧插入，相对的是从左侧/从右侧弹出</p>
<p>Lrange</p>
<p>检索在一定范围内的元素</p>
<p>Ltrim</p>
<p>截取一定范围内的元素</p>
<p>其他命令参考：<a href="https://redis.io/commands/blmove" target="_blank" rel="noopener">https://redis.io/commands/blmove</a></p>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><p>底层是链表结构，消费者模型可用于队列，可方便的获取最新一次的数据。</p>
<h2 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h2><h3 id="常用命令-2"><a href="#常用命令-2" class="headerlink" title="常用命令"></a>常用命令</h3><p>Hset/Hget，Hmset/Hmget</p>
<p>设置/获取，批量设置/批量获取。</p>
<p>Hincrby/Hdecrby</p>
<p>增加/减少某个key的值</p>
<p>Hsetnx</p>
<p>类似煜setnx</p>
<p>其他命令参考：<a href="https://redis.io/commands/hdel" target="_blank" rel="noopener">https://redis.io/commands/hdel</a></p>
<h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><p>哈希结构，可以比较方便的表示对象内的字段关系，hash里面的key没有独立的过期时间，过期时间跟着大的Key而定。</p>
<h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><h3 id="常用命令-3"><a href="#常用命令-3" class="headerlink" title="常用命令"></a>常用命令</h3><p>Sadd</p>
<p>添加某个元素</p>
<p>Sismember</p>
<p>判断某个元素是否存在，1表示存在</p>
<p>Smembers</p>
<p>返回元素长度</p>
<p>Sunionstore/Sinter/Sdiff</p>
<p>取并集/交集/差集</p>
<p>其他命令参考：<a href="https://redis.io/commands/sadd" target="_blank" rel="noopener">https://redis.io/commands/sadd</a></p>
<h3 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h3><p>集合，无排序，可排除重复项。利用并交差，可以快速检索出两个列表的关系，例如关注了同一个人的用户。</p>
<h2 id="sort-set"><a href="#sort-set" class="headerlink" title="sort set"></a>sort set</h2><h3 id="常用命令-4"><a href="#常用命令-4" class="headerlink" title="常用命令"></a>常用命令</h3><p>Zadd</p>
<p>增加元素</p>
<p>Zrange</p>
<p>检索指定评分的元素，可以降序</p>
<p>Zrank</p>
<p>查看某个元素属于什么索引（不是评分）</p>
<p>Zinter/Zunion/Zdiff</p>
<p>于set的命令相似</p>
<p>其他命令参考：<a href="https://redis.io/commands/bzmpop" target="_blank" rel="noopener">https://redis.io/commands/bzmpop</a></p>
<h3 id="特点-4"><a href="#特点-4" class="headerlink" title="特点"></a>特点</h3><p>set升级版，增加了score，可以根据评分进行排序，底层利用skiplist。常用于排行榜。</p>
<h2 id="bitmap"><a href="#bitmap" class="headerlink" title="bitmap"></a>bitmap</h2><h3 id="常用命令-5"><a href="#常用命令-5" class="headerlink" title="常用命令"></a>常用命令</h3><p>Setbit/Getbit</p>
<p>设置/获取。设置的偏移量必须是Integer类型。</p>
<p>Bitcount</p>
<p>查看位数为1的个数</p>
<p>Bitop</p>
<p>对string进行位运算</p>
<p>Bitpos</p>
<p>查找指定0/1的第一位</p>
<p>其他命令参考：<a href="https://redis.io/commands/setbit" target="_blank" rel="noopener">https://redis.io/commands/setbit</a></p>
<h3 id="特点-5"><a href="#特点-5" class="headerlink" title="特点"></a>特点</h3><p>位图，是一种特殊的String，可以标识2^32个bi位，可以通过高效的存储结构，利用少量的空间存储大量的数据。例如，布隆过滤器，可以基于bitmap来实现，使用时通过某种hash函数，将数据转化为位表示。也可以用于记录签到，打卡等一次性开关活动。</p>
<h2 id="hyperLogLogs"><a href="#hyperLogLogs" class="headerlink" title="hyperLogLogs"></a>hyperLogLogs</h2><h3 id="常用命令-6"><a href="#常用命令-6" class="headerlink" title="常用命令"></a>常用命令</h3><p>Pfadd</p>
<p>增加元素</p>
<p>Pfcount</p>
<p>返回有多少基数</p>
<p>其他命令参考：<a href="https://redis.io/commands/pfadd" target="_blank" rel="noopener">https://redis.io/commands/pfadd</a></p>
<h3 id="特点-6"><a href="#特点-6" class="headerlink" title="特点"></a>特点</h3><p>也是一种特殊的String，在允许误差的情况下，快速计算基数（也就是不重复的元素<strong>个</strong>数），常用的数据结构有（set，bitmap）</p>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>组件</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive初识</title>
    <url>/2023/04/30/3_Hive/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>引自官网介绍，<a href="https://hive.apache.org/" target="_blank" rel="noopener">https://hive.apache.org/</a></p>
<p>The Apache Hive ™ is a distributed, fault-tolerant data warehouse system that enables analytics at a massive scale and facilitates reading, writing, and managing petabytes of data residing in distributed storage using SQL.</p>
<blockquote>
<p>Hive是一个分布式，具有容错性的数据仓库系统，允许分析人员使用Sql管理大规模读写，PB级别数据的分布式存储。</p>
</blockquote>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h2><p>下载release包，这里下载的是hadoop-3.3.1</p>
<p>Mac允许SSH</p>
<p><img src="/2023/04/30/3_Hive/1.png" alt="image-20230228221535616" loading="lazy"></p>
<p><img src="/2023/04/30/3_Hive/2.png" alt="image-20230228221535616" loading="lazy"></p>
<h3 id="伪分布式"><a href="#伪分布式" class="headerlink" title="伪分布式"></a>伪分布式</h3><ol>
<li>修改etc/hadoop/hdfs-site.xml文件</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="comment">&lt;!-- 去掉权限（不知道有没有用） --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/Users/xxx/Documents/1_apache/hadoop-3.3.1/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/Users/xxx/Documents/1_apache/hadoop-3.3.1/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改etc/hadoop/core-site.xml</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>格式化文件系统（Format the filesystem）</li>
</ol>
<blockquote>
<p>mac上有个未解决的问题，执行hdfs相关命令时，会警告：</p>
<p>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果启动时，datanode出现如下报错：</p>
<p>2023-05-01 17:19:49,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000<br>2023-05-01 17:19:49,630 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)<br>2023-05-01 17:19:49,636 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-weiqian/dfs/data/in_use.lock acquired by nodename <a href="mailto:44940@weiqiandeMacBook-Pro.local">44940@weiqiandeMacBook-Pro.local</a><br>2023-05-01 17:19:49,640 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/tmp/hadoop-weiqian/dfs/data<br>java.io.IOException: Incompatible clusterIDs in /private/tmp/hadoop-weiqian/dfs/data: namenode clusterID = CID-f94bf14f-588b-4b3a-9211-0ed559ed8428; datanode clusterID = CID-1b3b1006-e635-4285-b45a-5ef8d75b58a1<br>   at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:746)<br>   at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:296)<br>   at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)<br>   at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:389)<br>   at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:561)<br>   at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1753)<br>   at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1689)<br>   at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:394)<br>   at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:295)<br>   at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:854)<br>   at java.base/java.lang.Thread.run(Thread.java:833)</registering></p>
</blockquote>
<p>说明clusterID已经创建过，简单暴力的方式（不适合生产），就是直接删除datanode下的文件，然后重新</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#rm -rf /tmp/hadoop-&#123;username&#125;/*</span></span><br><span class="line"><span class="comment">#rm -rf /tmp/hadoop-root/*</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>启动NameNode daemon 和DataNode daemon，NameNode的web界面url：<a href="http://localhost:9870/" target="_blank" rel="noopener">http://localhost:9870/</a></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>创建HDFS目录执行MapReduce任务：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hdfs dfs -mkdir -p /user/&lt;username&gt;</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>执行一个例子，复制文件到hdfs里</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hdfs dfs -mkdir input</span><br><span class="line">bin/hdfs dfs -put etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>执行一个例子，执行一个mapReduce任务</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar grep input output <span class="string">'dfs[a-z.]+'</span></span><br></pre></td></tr></table></figure>

<ol start="8">
<li>查看结果</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure>

<ol start="9">
<li>关闭集群</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>



<h3 id="Yarn部署"><a href="#Yarn部署" class="headerlink" title="Yarn部署"></a>Yarn部署</h3><ol>
<li>修改配置文件yarn-site.xml</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>    </span><br><span class="line">		<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改mapred-site.xml</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>由于hadoop需要运行在java8或11环境下，为了避免java环境异常，手动指定一下，修改hadoop-env.sh文件，使用jdk8的版本</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>启动，webui：<a href="http://localhost:8088/cluster/apps" target="_blank" rel="noopener">http://localhost:8088/cluster/apps</a></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>提交一个job任务</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar grep input output <span class="string">'dfs[a-z.]+'</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>在nodemanager出现过报错，导致job的任务无法运行，此时可以检查下hadoop-env.sh的java_home</p>
<p>/bin/bash: /bin/java: No such file or directory</p>
</blockquote>
<ol start="6">
<li>查看结果</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>关闭集群</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>



<h2 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h2><p>下载release包，这里下载的是hive-3.1.2</p>
<ol>
<li>启动hadoop（参见上面）</li>
<li>在hadoop文件目录下，创建相关的路径</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hadoop fs -mkdir       /tmp</span><br><span class="line">bin/hadoop fs -mkdir       /user/hive/warehouse</span><br><span class="line">bin/hadoop fs -chmod g+w   /tmp</span><br><span class="line">bin/hadoop fs -chmod g+w   /user/hive/warehouse</span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<p><img src="/2023/04/30/3_Hive/3.png" alt="image-20230228221535616" loading="lazy"></p>
<ol start="3">
<li>更改元数据，采用mysql，在conf目录下创建hive-site.xml</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://127.0.0.1:3306/hive_local?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      JDBC connect string for a JDBC metastore.</span><br><span class="line">      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.</span><br><span class="line">      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.cj.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>linlin<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>采用的是mysql8的驱动（mysql-connector-java-8.0.11.jar），放到lib目录下</p>
<ol start="4">
<li>进入Hive文件目录，启动Hive</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>初始化</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure>



<h2 id="使用TPC-DS压测"><a href="#使用TPC-DS压测" class="headerlink" title="使用TPC-DS压测"></a>使用TPC-DS压测</h2><ol>
<li>由于TPC-DS测试数据生成脚本是基于linux环境，这里在mac上创建一个虚拟机，解压tpc-ds的文件，官网路径：<a href="https://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request5.asp?bm_type=TPC-DS&amp;bm_vers=3.2.0&amp;mode=CURRENT-ONLY，解压后文件目录如下" target="_blank" rel="noopener">https://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request5.asp?bm_type=TPC-DS&amp;bm_vers=3.2.0&amp;mode=CURRENT-ONLY，解压后文件目录如下</a></li>
</ol>
<p><img src="/2023/04/30/3_Hive/4.png" alt="image-20230228221535616" loading="lazy"></p>
<ol start="2">
<li>进入tools目录，执行make命令编译，（这里如果是mac的话，value.h文件会报错）</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>tools目录下，可以看到建表语句，tpcds.sql</li>
</ol>
<p><img src="/2023/04/30/3_Hive/5.png" alt="image-20230228221535616" loading="lazy"></p>
<ol start="4">
<li>hive需要修改几个地方，完整的建表和数据导入语句如下</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">create table dbgen_version</span><br><span class="line">(</span><br><span class="line">    dv_version                varchar(16)                   ,</span><br><span class="line">    dv_create_date            date                          ,</span><br><span class="line">    dv_create_time            varchar(16)                          ,</span><br><span class="line">    dv_cmdline_args           varchar(200)                  </span><br><span class="line">)</span><br><span class="line">row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">create table customer_address</span><br><span class="line">(</span><br><span class="line">    ca_address_sk             <span class="built_in">integer</span>               not null,</span><br><span class="line">    ca_address_id             char(16)              not null,</span><br><span class="line">    ca_street_number          char(10)                      ,</span><br><span class="line">    ca_street_name            varchar(60)                   ,</span><br><span class="line">    ca_street_type            char(15)                      ,</span><br><span class="line">    ca_suite_number           char(10)                      ,</span><br><span class="line">    ca_city                   varchar(60)                   ,</span><br><span class="line">    ca_county                 varchar(30)                   ,</span><br><span class="line">    ca_state                  char(2)                       ,</span><br><span class="line">    ca_zip                    char(10)                      ,</span><br><span class="line">    ca_country                varchar(20)                   ,</span><br><span class="line">    ca_gmt_offset             decimal(5,2)                  ,</span><br><span class="line">    ca_location_type          char(20)                      ,</span><br><span class="line">    primary key (ca_address_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table customer_demographics</span><br><span class="line">(</span><br><span class="line">    cd_demo_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    cd_gender                 char(1)                       ,</span><br><span class="line">    cd_marital_status         char(1)                       ,</span><br><span class="line">    cd_education_status       char(20)                      ,</span><br><span class="line">    cd_purchase_estimate      <span class="built_in">integer</span>                       ,</span><br><span class="line">    cd_credit_rating          char(10)                      ,</span><br><span class="line">    cd_dep_count              <span class="built_in">integer</span>                       ,</span><br><span class="line">    cd_dep_employed_count     <span class="built_in">integer</span>                       ,</span><br><span class="line">    cd_dep_college_count      <span class="built_in">integer</span>                       ,</span><br><span class="line">    primary key (cd_demo_sk)  DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table date_dim</span><br><span class="line">(</span><br><span class="line">    d_date_sk                 <span class="built_in">integer</span>               not null,</span><br><span class="line">    d_date_id                 char(16)              not null,</span><br><span class="line">    d_date                    date                          ,</span><br><span class="line">    d_month_seq               <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_week_seq                <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_quarter_seq             <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_year                    <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_dow                     <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_moy                     <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_dom                     <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_qoy                     <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_fy_year                 <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_fy_quarter_seq          <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_fy_week_seq             <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_day_name                char(9)                       ,</span><br><span class="line">    d_quarter_name            char(6)                       ,</span><br><span class="line">    d_holiday                 char(1)                       ,</span><br><span class="line">    d_weekend                 char(1)                       ,</span><br><span class="line">    d_following_holiday       char(1)                       ,</span><br><span class="line">    d_first_dom               <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_last_dom                <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_same_day_ly             <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_same_day_lq             <span class="built_in">integer</span>                       ,</span><br><span class="line">    d_current_day             char(1)                       ,</span><br><span class="line">    d_current_week            char(1)                       ,</span><br><span class="line">    d_current_month           char(1)                       ,</span><br><span class="line">    d_current_quarter         char(1)                       ,</span><br><span class="line">    d_current_year            char(1)                       ,</span><br><span class="line">    primary key (d_date_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table warehouse</span><br><span class="line">(</span><br><span class="line">    w_warehouse_sk            <span class="built_in">integer</span>               not null,</span><br><span class="line">    w_warehouse_id            char(16)              not null,</span><br><span class="line">    w_warehouse_name          varchar(20)                   ,</span><br><span class="line">    w_warehouse_sq_ft         <span class="built_in">integer</span>                       ,</span><br><span class="line">    w_street_number           char(10)                      ,</span><br><span class="line">    w_street_name             varchar(60)                   ,</span><br><span class="line">    w_street_type             char(15)                      ,</span><br><span class="line">    w_suite_number            char(10)                      ,</span><br><span class="line">    w_city                    varchar(60)                   ,</span><br><span class="line">    w_county                  varchar(30)                   ,</span><br><span class="line">    w_state                   char(2)                       ,</span><br><span class="line">    w_zip                     char(10)                      ,</span><br><span class="line">    w_country                 varchar(20)                   ,</span><br><span class="line">    w_gmt_offset              decimal(5,2)                  ,</span><br><span class="line">    primary key (w_warehouse_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table ship_mode</span><br><span class="line">(</span><br><span class="line">    sm_ship_mode_sk           <span class="built_in">integer</span>               not null,</span><br><span class="line">    sm_ship_mode_id           char(16)              not null,</span><br><span class="line">    sm_type                   char(30)                      ,</span><br><span class="line">    sm_code                   char(10)                      ,</span><br><span class="line">    sm_carrier                char(20)                      ,</span><br><span class="line">    sm_contract               char(20)                      ,</span><br><span class="line">    primary key (sm_ship_mode_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table time_dim</span><br><span class="line">(</span><br><span class="line">    t_time_sk                 <span class="built_in">integer</span>               not null,</span><br><span class="line">    t_time_id                 char(16)              not null,</span><br><span class="line">    t_time                    <span class="built_in">integer</span>                       ,</span><br><span class="line">    t_hour                    <span class="built_in">integer</span>                       ,</span><br><span class="line">    t_minute                  <span class="built_in">integer</span>                       ,</span><br><span class="line">    t_second                  <span class="built_in">integer</span>                       ,</span><br><span class="line">    t_am_pm                   char(2)                       ,</span><br><span class="line">    t_shift                   char(20)                      ,</span><br><span class="line">    t_sub_shift               char(20)                      ,</span><br><span class="line">    t_meal_time               char(20)                      ,</span><br><span class="line">    primary key (t_time_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table reason</span><br><span class="line">(</span><br><span class="line">    r_reason_sk               <span class="built_in">integer</span>               not null,</span><br><span class="line">    r_reason_id               char(16)              not null,</span><br><span class="line">    r_reason_desc             char(100)                     ,</span><br><span class="line">    primary key (r_reason_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table income_band</span><br><span class="line">(</span><br><span class="line">    ib_income_band_sk         <span class="built_in">integer</span>               not null,</span><br><span class="line">    ib_lower_bound            <span class="built_in">integer</span>                       ,</span><br><span class="line">    ib_upper_bound            <span class="built_in">integer</span>                       ,</span><br><span class="line">    primary key (ib_income_band_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table item</span><br><span class="line">(</span><br><span class="line">    i_item_sk                 <span class="built_in">integer</span>               not null,</span><br><span class="line">    i_item_id                 char(16)              not null,</span><br><span class="line">    i_rec_start_date          date                          ,</span><br><span class="line">    i_rec_end_date            date                          ,</span><br><span class="line">    i_item_desc               varchar(200)                  ,</span><br><span class="line">    i_current_price           decimal(7,2)                  ,</span><br><span class="line">    i_wholesale_cost          decimal(7,2)                  ,</span><br><span class="line">    i_brand_id                <span class="built_in">integer</span>                       ,</span><br><span class="line">    i_brand                   char(50)                      ,</span><br><span class="line">    i_class_id                <span class="built_in">integer</span>                       ,</span><br><span class="line">    i_class                   char(50)                      ,</span><br><span class="line">    i_category_id             <span class="built_in">integer</span>                       ,</span><br><span class="line">    i_category                char(50)                      ,</span><br><span class="line">    i_manufact_id             <span class="built_in">integer</span>                       ,</span><br><span class="line">    i_manufact                char(50)                      ,</span><br><span class="line">    i_size                    char(20)                      ,</span><br><span class="line">    i_formulation             char(20)                      ,</span><br><span class="line">    i_color                   char(20)                      ,</span><br><span class="line">    i_units                   char(10)                      ,</span><br><span class="line">    i_container               char(10)                      ,</span><br><span class="line">    i_manager_id              <span class="built_in">integer</span>                       ,</span><br><span class="line">    i_product_name            char(50)                      ,</span><br><span class="line">    primary key (i_item_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table store</span><br><span class="line">(</span><br><span class="line">    s_store_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    s_store_id                char(16)              not null,</span><br><span class="line">    s_rec_start_date          date                          ,</span><br><span class="line">    s_rec_end_date            date                          ,</span><br><span class="line">    s_closed_date_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    s_store_name              varchar(50)                   ,</span><br><span class="line">    s_number_employees        <span class="built_in">integer</span>                       ,</span><br><span class="line">    s_floor_space             <span class="built_in">integer</span>                       ,</span><br><span class="line">    s_hours                   char(20)                      ,</span><br><span class="line">    s_manager                 varchar(40)                   ,</span><br><span class="line">    s_market_id               <span class="built_in">integer</span>                       ,</span><br><span class="line">    s_geography_class         varchar(100)                  ,</span><br><span class="line">    s_market_desc             varchar(100)                  ,</span><br><span class="line">    s_market_manager          varchar(40)                   ,</span><br><span class="line">    s_division_id             <span class="built_in">integer</span>                       ,</span><br><span class="line">    s_division_name           varchar(50)                   ,</span><br><span class="line">    s_company_id              <span class="built_in">integer</span>                       ,</span><br><span class="line">    s_company_name            varchar(50)                   ,</span><br><span class="line">    s_street_number           varchar(10)                   ,</span><br><span class="line">    s_street_name             varchar(60)                   ,</span><br><span class="line">    s_street_type             char(15)                      ,</span><br><span class="line">    s_suite_number            char(10)                      ,</span><br><span class="line">    s_city                    varchar(60)                   ,</span><br><span class="line">    s_county                  varchar(30)                   ,</span><br><span class="line">    s_state                   char(2)                       ,</span><br><span class="line">    s_zip                     char(10)                      ,</span><br><span class="line">    s_country                 varchar(20)                   ,</span><br><span class="line">    s_gmt_offset              decimal(5,2)                  ,</span><br><span class="line">    s_tax_precentage          decimal(5,2)                  ,</span><br><span class="line">    primary key (s_store_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table call_center</span><br><span class="line">(</span><br><span class="line">    cc_call_center_sk         <span class="built_in">integer</span>               not null,</span><br><span class="line">    cc_call_center_id         char(16)              not null,</span><br><span class="line">    cc_rec_start_date         date                          ,</span><br><span class="line">    cc_rec_end_date           date                          ,</span><br><span class="line">    cc_closed_date_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_open_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_name                   varchar(50)                   ,</span><br><span class="line">    cc_class                  varchar(50)                   ,</span><br><span class="line">    cc_employees              <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_sq_ft                  <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_hours                  char(20)                      ,</span><br><span class="line">    cc_manager                varchar(40)                   ,</span><br><span class="line">    cc_mkt_id                 <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_mkt_class              char(50)                      ,</span><br><span class="line">    cc_mkt_desc               varchar(100)                  ,</span><br><span class="line">    cc_market_manager         varchar(40)                   ,</span><br><span class="line">    cc_division               <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_division_name          varchar(50)                   ,</span><br><span class="line">    cc_company                <span class="built_in">integer</span>                       ,</span><br><span class="line">    cc_company_name           char(50)                      ,</span><br><span class="line">    cc_street_number          char(10)                      ,</span><br><span class="line">    cc_street_name            varchar(60)                   ,</span><br><span class="line">    cc_street_type            char(15)                      ,</span><br><span class="line">    cc_suite_number           char(10)                      ,</span><br><span class="line">    cc_city                   varchar(60)                   ,</span><br><span class="line">    cc_county                 varchar(30)                   ,</span><br><span class="line">    cc_state                  char(2)                       ,</span><br><span class="line">    cc_zip                    char(10)                      ,</span><br><span class="line">    cc_country                varchar(20)                   ,</span><br><span class="line">    cc_gmt_offset             decimal(5,2)                  ,</span><br><span class="line">    cc_tax_percentage         decimal(5,2)                  ,</span><br><span class="line">    primary key (cc_call_center_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table customer</span><br><span class="line">(</span><br><span class="line">    c_customer_sk             <span class="built_in">integer</span>               not null,</span><br><span class="line">    c_customer_id             char(16)              not null,</span><br><span class="line">    c_current_cdemo_sk        <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_current_hdemo_sk        <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_current_addr_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_first_shipto_date_sk    <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_first_sales_date_sk     <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_salutation              char(10)                      ,</span><br><span class="line">    c_first_name              char(20)                      ,</span><br><span class="line">    c_last_name               char(30)                      ,</span><br><span class="line">    c_preferred_cust_flag     char(1)                       ,</span><br><span class="line">    c_birth_day               <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_birth_month             <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_birth_year              <span class="built_in">integer</span>                       ,</span><br><span class="line">    c_birth_country           varchar(20)                   ,</span><br><span class="line">    c_login                   char(13)                      ,</span><br><span class="line">    c_email_address           char(50)                      ,</span><br><span class="line">    c_last_review_date        char(10)                      ,</span><br><span class="line">    primary key (c_customer_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table web_site</span><br><span class="line">(</span><br><span class="line">    web_site_sk               <span class="built_in">integer</span>               not null,</span><br><span class="line">    web_site_id               char(16)              not null,</span><br><span class="line">    web_rec_start_date        date                          ,</span><br><span class="line">    web_rec_end_date          date                          ,</span><br><span class="line">    web_name                  varchar(50)                   ,</span><br><span class="line">    web_open_date_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    web_close_date_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    web_class                 varchar(50)                   ,</span><br><span class="line">    web_manager               varchar(40)                   ,</span><br><span class="line">    web_mkt_id                <span class="built_in">integer</span>                       ,</span><br><span class="line">    web_mkt_class             varchar(50)                   ,</span><br><span class="line">    web_mkt_desc              varchar(100)                  ,</span><br><span class="line">    web_market_manager        varchar(40)                   ,</span><br><span class="line">    web_company_id            <span class="built_in">integer</span>                       ,</span><br><span class="line">    web_company_name          char(50)                      ,</span><br><span class="line">    web_street_number         char(10)                      ,</span><br><span class="line">    web_street_name           varchar(60)                   ,</span><br><span class="line">    web_street_type           char(15)                      ,</span><br><span class="line">    web_suite_number          char(10)                      ,</span><br><span class="line">    web_city                  varchar(60)                   ,</span><br><span class="line">    web_county                varchar(30)                   ,</span><br><span class="line">    web_state                 char(2)                       ,</span><br><span class="line">    web_zip                   char(10)                      ,</span><br><span class="line">    web_country               varchar(20)                   ,</span><br><span class="line">    web_gmt_offset            decimal(5,2)                  ,</span><br><span class="line">    web_tax_percentage        decimal(5,2)                  ,</span><br><span class="line">    primary key (web_site_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table store_returns</span><br><span class="line">(</span><br><span class="line">    sr_returned_date_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_return_time_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_item_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    sr_customer_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_cdemo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_hdemo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_addr_sk                <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_store_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_reason_sk              <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_ticket_number          <span class="built_in">integer</span>               not null,</span><br><span class="line">    sr_return_quantity        <span class="built_in">integer</span>                       ,</span><br><span class="line">    sr_return_amt             decimal(7,2)                  ,</span><br><span class="line">    sr_return_tax             decimal(7,2)                  ,</span><br><span class="line">    sr_return_amt_inc_tax     decimal(7,2)                  ,</span><br><span class="line">    sr_fee                    decimal(7,2)                  ,</span><br><span class="line">    sr_return_ship_cost       decimal(7,2)                  ,</span><br><span class="line">    sr_refunded_cash          decimal(7,2)                  ,</span><br><span class="line">    sr_reversed_charge        decimal(7,2)                  ,</span><br><span class="line">    sr_store_credit           decimal(7,2)                  ,</span><br><span class="line">    sr_net_loss               decimal(7,2)                  ,</span><br><span class="line">    primary key (sr_item_sk, sr_ticket_number) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table household_demographics</span><br><span class="line">(</span><br><span class="line">    hd_demo_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    hd_income_band_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    hd_buy_potential          char(15)                      ,</span><br><span class="line">    hd_dep_count              <span class="built_in">integer</span>                       ,</span><br><span class="line">    hd_vehicle_count          <span class="built_in">integer</span>                       ,</span><br><span class="line">    primary key (hd_demo_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table web_page</span><br><span class="line">(</span><br><span class="line">    wp_web_page_sk            <span class="built_in">integer</span>               not null,</span><br><span class="line">    wp_web_page_id            char(16)              not null,</span><br><span class="line">    wp_rec_start_date         date                          ,</span><br><span class="line">    wp_rec_end_date           date                          ,</span><br><span class="line">    wp_creation_date_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    wp_access_date_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    wp_autogen_flag           char(1)                       ,</span><br><span class="line">    wp_customer_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    wp_url                    varchar(100)                  ,</span><br><span class="line">    wp_type                   char(50)                      ,</span><br><span class="line">    wp_char_count             <span class="built_in">integer</span>                       ,</span><br><span class="line">    wp_link_count             <span class="built_in">integer</span>                       ,</span><br><span class="line">    wp_image_count            <span class="built_in">integer</span>                       ,</span><br><span class="line">    wp_max_ad_count           <span class="built_in">integer</span>                       ,</span><br><span class="line">    primary key (wp_web_page_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table promotion</span><br><span class="line">(</span><br><span class="line">    p_promo_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    p_promo_id                char(16)              not null,</span><br><span class="line">    p_start_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    p_end_date_sk             <span class="built_in">integer</span>                       ,</span><br><span class="line">    p_item_sk                 <span class="built_in">integer</span>                       ,</span><br><span class="line">    p_cost                    decimal(15,2)                 ,</span><br><span class="line">    p_response_target         <span class="built_in">integer</span>                       ,</span><br><span class="line">    p_promo_name              char(50)                      ,</span><br><span class="line">    p_channel_dmail           char(1)                       ,</span><br><span class="line">    p_channel_email           char(1)                       ,</span><br><span class="line">    p_channel_catalog         char(1)                       ,</span><br><span class="line">    p_channel_tv              char(1)                       ,</span><br><span class="line">    p_channel_radio           char(1)                       ,</span><br><span class="line">    p_channel_press           char(1)                       ,</span><br><span class="line">    p_channel_event           char(1)                       ,</span><br><span class="line">    p_channel_demo            char(1)                       ,</span><br><span class="line">    p_channel_details         varchar(100)                  ,</span><br><span class="line">    p_purpose                 char(15)                      ,</span><br><span class="line">    p_discount_active         char(1)                       ,</span><br><span class="line">    primary key (p_promo_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table catalog_page</span><br><span class="line">(</span><br><span class="line">    cp_catalog_page_sk        <span class="built_in">integer</span>               not null,</span><br><span class="line">    cp_catalog_page_id        char(16)              not null,</span><br><span class="line">    cp_start_date_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    cp_end_date_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    cp_department             varchar(50)                   ,</span><br><span class="line">    cp_catalog_number         <span class="built_in">integer</span>                       ,</span><br><span class="line">    cp_catalog_page_number    <span class="built_in">integer</span>                       ,</span><br><span class="line">    cp_description            varchar(100)                  ,</span><br><span class="line">    cp_type                   varchar(100)                  ,</span><br><span class="line">    primary key (cp_catalog_page_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table inventory</span><br><span class="line">(</span><br><span class="line">    inv_date_sk               <span class="built_in">integer</span>               not null,</span><br><span class="line">    inv_item_sk               <span class="built_in">integer</span>               not null,</span><br><span class="line">    inv_warehouse_sk          <span class="built_in">integer</span>               not null,</span><br><span class="line">    inv_quantity_on_hand      <span class="built_in">integer</span>                       ,</span><br><span class="line">    primary key (inv_date_sk, inv_item_sk, inv_warehouse_sk) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table catalog_returns</span><br><span class="line">(</span><br><span class="line">    cr_returned_date_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_returned_time_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_item_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    cr_refunded_customer_sk   <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_refunded_cdemo_sk      <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_refunded_hdemo_sk      <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_refunded_addr_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_returning_customer_sk  <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_returning_cdemo_sk     <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_returning_hdemo_sk     <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_returning_addr_sk      <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_call_center_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_catalog_page_sk        <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_ship_mode_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_warehouse_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_reason_sk              <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_order_number           <span class="built_in">integer</span>               not null,</span><br><span class="line">    cr_return_quantity        <span class="built_in">integer</span>                       ,</span><br><span class="line">    cr_return_amount          decimal(7,2)                  ,</span><br><span class="line">    cr_return_tax             decimal(7,2)                  ,</span><br><span class="line">    cr_return_amt_inc_tax     decimal(7,2)                  ,</span><br><span class="line">    cr_fee                    decimal(7,2)                  ,</span><br><span class="line">    cr_return_ship_cost       decimal(7,2)                  ,</span><br><span class="line">    cr_refunded_cash          decimal(7,2)                  ,</span><br><span class="line">    cr_reversed_charge        decimal(7,2)                  ,</span><br><span class="line">    cr_store_credit           decimal(7,2)                  ,</span><br><span class="line">    cr_net_loss               decimal(7,2)                  ,</span><br><span class="line">    primary key (cr_item_sk, cr_order_number) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table web_returns</span><br><span class="line">(</span><br><span class="line">    wr_returned_date_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_returned_time_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_item_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    wr_refunded_customer_sk   <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_refunded_cdemo_sk      <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_refunded_hdemo_sk      <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_refunded_addr_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_returning_customer_sk  <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_returning_cdemo_sk     <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_returning_hdemo_sk     <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_returning_addr_sk      <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_web_page_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_reason_sk              <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_order_number           <span class="built_in">integer</span>               not null,</span><br><span class="line">    wr_return_quantity        <span class="built_in">integer</span>                       ,</span><br><span class="line">    wr_return_amt             decimal(7,2)                  ,</span><br><span class="line">    wr_return_tax             decimal(7,2)                  ,</span><br><span class="line">    wr_return_amt_inc_tax     decimal(7,2)                  ,</span><br><span class="line">    wr_fee                    decimal(7,2)                  ,</span><br><span class="line">    wr_return_ship_cost       decimal(7,2)                  ,</span><br><span class="line">    wr_refunded_cash          decimal(7,2)                  ,</span><br><span class="line">    wr_reversed_charge        decimal(7,2)                  ,</span><br><span class="line">    wr_account_credit         decimal(7,2)                  ,</span><br><span class="line">    wr_net_loss               decimal(7,2)                  ,</span><br><span class="line">    primary key (wr_item_sk, wr_order_number) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table web_sales</span><br><span class="line">(</span><br><span class="line">    ws_sold_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_sold_time_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_ship_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_item_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    ws_bill_customer_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_bill_cdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_bill_hdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_bill_addr_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_ship_customer_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_ship_cdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_ship_hdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_ship_addr_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_web_page_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_web_site_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_ship_mode_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_warehouse_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_promo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_order_number           <span class="built_in">integer</span>               not null,</span><br><span class="line">    ws_quantity               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ws_wholesale_cost         decimal(7,2)                  ,</span><br><span class="line">    ws_list_price             decimal(7,2)                  ,</span><br><span class="line">    ws_sales_price            decimal(7,2)                  ,</span><br><span class="line">    ws_ext_discount_amt       decimal(7,2)                  ,</span><br><span class="line">    ws_ext_sales_price        decimal(7,2)                  ,</span><br><span class="line">    ws_ext_wholesale_cost     decimal(7,2)                  ,</span><br><span class="line">    ws_ext_list_price         decimal(7,2)                  ,</span><br><span class="line">    ws_ext_tax                decimal(7,2)                  ,</span><br><span class="line">    ws_coupon_amt             decimal(7,2)                  ,</span><br><span class="line">    ws_ext_ship_cost          decimal(7,2)                  ,</span><br><span class="line">    ws_net_paid               decimal(7,2)                  ,</span><br><span class="line">    ws_net_paid_inc_tax       decimal(7,2)                  ,</span><br><span class="line">    ws_net_paid_inc_ship      decimal(7,2)                  ,</span><br><span class="line">    ws_net_paid_inc_ship_tax  decimal(7,2)                  ,</span><br><span class="line">    ws_net_profit             decimal(7,2)                  ,</span><br><span class="line">    primary key (ws_item_sk, ws_order_number) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table catalog_sales</span><br><span class="line">(</span><br><span class="line">    cs_sold_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_sold_time_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_ship_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_bill_customer_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_bill_cdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_bill_hdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_bill_addr_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_ship_customer_sk       <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_ship_cdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_ship_hdemo_sk          <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_ship_addr_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_call_center_sk         <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_catalog_page_sk        <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_ship_mode_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_warehouse_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_item_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    cs_promo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_order_number           <span class="built_in">integer</span>               not null,</span><br><span class="line">    cs_quantity               <span class="built_in">integer</span>                       ,</span><br><span class="line">    cs_wholesale_cost         decimal(7,2)                  ,</span><br><span class="line">    cs_list_price             decimal(7,2)                  ,</span><br><span class="line">    cs_sales_price            decimal(7,2)                  ,</span><br><span class="line">    cs_ext_discount_amt       decimal(7,2)                  ,</span><br><span class="line">    cs_ext_sales_price        decimal(7,2)                  ,</span><br><span class="line">    cs_ext_wholesale_cost     decimal(7,2)                  ,</span><br><span class="line">    cs_ext_list_price         decimal(7,2)                  ,</span><br><span class="line">    cs_ext_tax                decimal(7,2)                  ,</span><br><span class="line">    cs_coupon_amt             decimal(7,2)                  ,</span><br><span class="line">    cs_ext_ship_cost          decimal(7,2)                  ,</span><br><span class="line">    cs_net_paid               decimal(7,2)                  ,</span><br><span class="line">    cs_net_paid_inc_tax       decimal(7,2)                  ,</span><br><span class="line">    cs_net_paid_inc_ship      decimal(7,2)                  ,</span><br><span class="line">    cs_net_paid_inc_ship_tax  decimal(7,2)                  ,</span><br><span class="line">    cs_net_profit             decimal(7,2)                  ,</span><br><span class="line">    primary key (cs_item_sk, cs_order_number) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">create table store_sales</span><br><span class="line">(</span><br><span class="line">    ss_sold_date_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_sold_time_sk           <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_item_sk                <span class="built_in">integer</span>               not null,</span><br><span class="line">    ss_customer_sk            <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_cdemo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_hdemo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_addr_sk                <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_store_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_promo_sk               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_ticket_number          <span class="built_in">integer</span>               not null,</span><br><span class="line">    ss_quantity               <span class="built_in">integer</span>                       ,</span><br><span class="line">    ss_wholesale_cost         decimal(7,2)                  ,</span><br><span class="line">    ss_list_price             decimal(7,2)                  ,</span><br><span class="line">    ss_sales_price            decimal(7,2)                  ,</span><br><span class="line">    ss_ext_discount_amt       decimal(7,2)                  ,</span><br><span class="line">    ss_ext_sales_price        decimal(7,2)                  ,</span><br><span class="line">    ss_ext_wholesale_cost     decimal(7,2)                  ,</span><br><span class="line">    ss_ext_list_price         decimal(7,2)                  ,</span><br><span class="line">    ss_ext_tax                decimal(7,2)                  ,</span><br><span class="line">    ss_coupon_amt             decimal(7,2)                  ,</span><br><span class="line">    ss_net_paid               decimal(7,2)                  ,</span><br><span class="line">    ss_net_paid_inc_tax       decimal(7,2)                  ,</span><br><span class="line">    ss_net_profit             decimal(7,2)                  ,</span><br><span class="line">    primary key (ss_item_sk, ss_ticket_number) DISABLE NOVALIDATE RELY</span><br><span class="line">)row format delimited</span><br><span class="line">fields terminated by <span class="string">'|'</span></span><br><span class="line">stored as TEXTFILE;</span><br><span class="line"></span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/dbgen_version.dat'</span> into table dbgen_version;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/call_center.dat'</span> into table call_center;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/catalog_page.dat'</span> into table catalog_page;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/catalog_returns.dat'</span> into table catalog_returns;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/catalog_sales.dat'</span> into table catalog_sales;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/customer_address.dat'</span> into table customer_address;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/customer_demographics.dat'</span> into table customer_demographics;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/weiqian/Documents/1_apache/apache-hive-3.1.2/outData/customer.dat'</span> into table customer;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/weiqian/Documents/1_apache/apache-hive-3.1.2/outData/date_dim.dat'</span> into table date_dim;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/weiqian/Documents/1_apache/apache-hive-3.1.2/outData/household_demographics.dat'</span> into table household_demographics;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/income_band.dat'</span> into table income_band;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/inventory.dat'</span> into table inventory;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/item.dat'</span> into table item;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/promotion.dat'</span> into table promotion;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/reason.dat'</span> into table reason;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/ship_mode.dat'</span> into table ship_mode;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/store_returns.dat'</span> into table store_returns;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/store_sales.dat'</span> into table store_sales;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/store.dat'</span> into table store;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/time_dim.dat'</span> into table time_dim;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/warehouse.dat'</span> into table warehouse;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/web_page.dat'</span> into table web_page;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/web_returns.dat'</span> into table web_returns;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/web_sales.dat'</span> into table web_sales;</span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/Users/xxx/Documents/1_apache/apache-hive-3.1.2/outData/web_site.dat'</span> into table web_site;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>生成查询语句，进入tools目录，由于template有点问题，直接执行代码生成时会出现问题，报错如下</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ERROR: Substitution<span class="string">'_END'</span> is used before being initialized at line 63 <span class="keyword">in</span> ../query_templates/query1.tpl</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>先执行shell脚本，把每个template文件都追加后缀</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i in &#96;ls query*tpl&#96;</span><br><span class="line">do </span><br><span class="line">    echo $i;  </span><br><span class="line">    echo &quot;define _END &#x3D; \&quot;\&quot;;&quot; &gt;&gt; $i</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>执行shell脚本，生成ansi模板的查询sql文件</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for id in &#96;seq 1 99&#96;; do .&#x2F;dsqgen -DIRECTORY ..&#x2F;query_templates -TEMPLATE &quot;query$id.tpl&quot; -DIALECT ansi -FILTER Y &gt; .&#x2F;sql&#x2F;&quot;query$id.sql&quot;; done</span><br></pre></td></tr></table></figure>









<h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1>]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
  </entry>
  <entry>
    <title>Quarkus</title>
    <url>/2022/05/09/3_Quarkus/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<h1 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h1><p><img src="/2022/05/09/3_Quarkus/image-20220509222033634.png" alt loading="lazy"></p>
<p>标榜为<strong>Supersonic Subatomic Java</strong>（亚原子超音速Java）</p>
<blockquote>
<p>A Kubernetes Native Java stack tailored for OpenJDK HotSpot and GraalVM, crafted from the best of breed Java libraries and standards.</p>
</blockquote>
<p>专门为OpenjdkHotSopt和GraalVm定制的，一款Kubernetes的，由优秀的软件类库及标准精心制作而来的，<strong>原生Java开发栈</strong>。2018年12月19号，Quarkus 0.2.0第一次正式发布，截至2022年5月6号，Quarkus发布了2.8.3.Final版本，目前9.9K的Star。</p>
<blockquote>
<p>Traditional Java stacks were engineered for monolithic applications with long startup times and large memory requirements in a world where the cloud, containers, and Kubernetes did not exist. Java frameworks needed to evolve to meet the needs of this new world.</p>
<p>Quarkus was created to enable Java developers to create applications for a modern, cloud-native world. Quarkus is a Kubernetes-native Java framework tailored for GraalVM and HotSpot, crafted from best-of-breed Java libraries and standards. The goal is to make Java the leading platform in Kubernetes and serverless environments while offering developers a framework to address a wider range of distributed application architectures.</p>
</blockquote>
<p>在云、容器和Kubernetes不存在的时代，传统的Java开发栈是设计应用于”巨石”应用，有着较长的启动时间和较大的内存需求。在新的时代，Java框架需要发展。</p>
<p>为了让Java开发者能够创建面向现代，云原生时代的应用，Quarkus由此而生。Quarkus是一个Kubernetes-原生的Java框架，专门为GraalVm和Hotspot而定制，具有云原生特性的软件类库及标准。目标是使Java成为Kubernetes和无服务环境的领先平台，给开发者提供一个解决广泛的分布式应用架构。</p>
<ul>
<li>开发者的玩具</li>
</ul>
<p>开发者是每个组织成功的关键，他们需要快速高效的构建云远程应用。Quarkus通过配套的工具、类库和扩展等手段提供丝滑的开发体验。Quarkus让开发者在开发模式下高效得改变内部开发循环。</p>
<ul>
<li>云原生</li>
</ul>
<p>Quarkus从头开始构建于Kubernetes，致力于不需要了解复杂的平台，轻易构建应用。Quarkus允许开发者自动生成包含构建和部署的Kubernetes容器，该容器无需手动创建Yaml文件。</p>
<ul>
<li>类库和标准的绝佳组合</li>
</ul>
<p>Quarkus提供有结合的，易于使用的，一站式框架，通过使用你喜欢的类库来更大程度发挥作用。</p>
<ul>
<li>命令式与反应式编程</li>
</ul>
<p>Quarkus被设计用无缝结合命令式编程风格和非阻塞式反应式编程风格这两种应用程序。</p>
<h1 id="初体验"><a href="#初体验" class="headerlink" title="初体验"></a>初体验</h1><p>先安装一下Quarkus Cli，Mac下安装十分方便，使用Homebrew安装即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew install quarkusio/tap/quarkus</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">quarkus --version</span><br><span class="line">2.8.3.Final</span><br></pre></td></tr></table></figure>

<p>可以直接使用Quaukus Cli创建一个空项目，指定一个目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">quarkus create</span><br><span class="line">-----------</span><br><span class="line"></span><br><span class="line">applying codestarts...</span><br><span class="line">📚  java</span><br><span class="line">🔨  maven</span><br><span class="line">📦  quarkus</span><br><span class="line">📝  config-properties</span><br><span class="line">🔧  dockerfiles</span><br><span class="line">🔧  maven-wrapper</span><br><span class="line">🚀  resteasy-codestart</span><br><span class="line"></span><br><span class="line">-----------</span><br><span class="line">[SUCCESS] ✅ quarkus project has been successfully generated <span class="keyword">in</span>:</span><br><span class="line">--&gt; /&lt;output-dir&gt;/code-with-quarkus</span><br></pre></td></tr></table></figure>

<p>当然也可以创建时指定groupId，artifartifactId，version</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a project with groupId=org.acme, artifactId=bar, and version=1.0.0-SNAPSHOT</span></span><br><span class="line">quarkus create app bar</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a project with groupId=com.foo, artifactId=bar, and version=1.0.0-SNAPSHOT</span></span><br><span class="line">quarkus create app com.foo:bar</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a project with groupId=com.foo, artifactId=bar, and version=1.0</span></span><br><span class="line">quarkus create app com.foo:bar:1.0</span><br></pre></td></tr></table></figure>

<p>接着就可以得到类似这样的项目</p>
<p><img src="/2022/05/09/3_Quarkus/image-20220511165008252.png" alt="image-20220511165008252" loading="lazy"></p>
<p>启动有两种方法，方法1，安装Quarkus Run Configs插件（不安装好像也可以），通过Run/Debug的模式启动</p>
<p><img src="/2022/05/09/3_Quarkus/image-20220511165119708.png" alt="image-20220511165119708" loading="lazy"></p>
<p><img src="/2022/05/09/3_Quarkus/image-20220511165204348.png" alt="image-20220511165204348" loading="lazy"></p>
<p>启动后</p>
<p><img src="/2022/05/09/3_Quarkus/image-20220511211025445.png" alt="image-20220511211025445" loading="lazy"></p>
<p>访问后</p>
<p><img src="/2022/05/09/3_Quarkus/image-20220511211104601.png" alt="image-20220511211104601" loading="lazy"></p>
<h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><p>Github地址</p>
<p><a href="https://github.com/quarkusio/quarkus" target="_blank" rel="noopener">https://github.com/quarkusio/quarkus</a></p>
<p>官网地址</p>
<p><a href="https://quarkus.io/" target="_blank" rel="noopener">https://quarkus.io/</a></p>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>分布式框架</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper</title>
    <url>/2021/12/24/3_Zookeeper/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>官网地址：<a href="https://zookeeper.apache.org/doc/current/zookeeperProgrammers.html#ch_zkWatches" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/current/zookeeperProgrammers.html#ch_zkWatches</a></p>
<blockquote>
<p> ZooKeeper is a high-performance coordination service for distributed applications. It exposes common services - such as naming, configuration management, synchronization, and group services - in a simple interface so you don’t have to write them from scratch. You can use it off-the-shelf to implement consensus, group management, leader election, and presence protocols. And you can build on it for your own, specific needs.</p>
</blockquote>
<p>是一个高性能的分布式协调服务，常用于注册中心服务发现，它被设计为易于编程，使用类似于文件系统的树状结构数据模型，使用java运行。</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><ol>
<li><p>简单</p>
<p>允许多个分布式进程通过共享的分层命名空间协调，由znode组成（数据注册器），类似文件和目录，但是不是文件存储，zookeeper的数据保存在内存里，所以zookeeper才有高吞吐量和低延迟。</p>
</li>
<li><p>可复制</p>
<p>Server之间必须知道其他Server，它们在内存中维持状态快照，事务日志和持久化节点快照，只要大部分节点（至少一半）可用，zookeeper就能正常服务。</p>
<p>Client使用Tcp连接某一个Server，可以进行发送请求，获得响应，获得watch事件，发送心跳信息，如果Tcp连接断开，Client会连接到另一个不同的Server。</p>
</li>
<li><p>有序</p>
<p>Zookeeper每一次更新会标记一个反应顺序的数字，在此之上，可以做一些高层级的操作，比如同步原语。</p>
</li>
<li><p>快速</p>
<p>在以读取为主的场景中特别快速。通过上百台机器，可以达到10：1的读写比，读优于写。</p>
</li>
</ol>
<h2 id="层次结构"><a href="#层次结构" class="headerlink" title="层次结构"></a>层次结构</h2><p><img src="https://zookeeper.apache.org/doc/current/images/zknamespace.jpg" alt="贴一张官网的图" loading="lazy"></p>
<p>贴一张官网的图。每一个节点均包含数据，子节点，数据比较小，通常在b-&gt;kb这个数量级，简称znode。znode维护了一个状态结构，包括数据变更、acl的变更、时间戳的版本号。每次数据变更时版本号会递增。</p>
<p>节点的读写是原子的，由ACL控制权限范围。</p>
<p>临时节点随着session创建而创建，关闭而删除。</p>
<h2 id="Watch"><a href="#Watch" class="headerlink" title="Watch"></a>Watch</h2><p>Client可以在znode上添加Watch，当znode变更时会被触发和删除。当watch被触发时，客户端会收到znode被触发的消息。如果Client和Server连接断开，Client会收到本地通知（没懂）</p>
<blockquote>
<p>Tip：3.6.0版本后，客户端可以添加永久递归监听，触发通知后不会删除，并且会在触发后再次注册和递归注册子节点。</p>
</blockquote>
<h2 id="保证"><a href="#保证" class="headerlink" title="保证"></a>保证</h2><ol>
<li>顺序一致，按照Client的发送顺序更新</li>
<li>原子</li>
<li>单一的系统视图。Client不管连接的哪个Server，看到的都是相同的视图</li>
<li>可靠，更新会立刻持久化</li>
<li>及时，在一定的时间窗口内，系统视图时最新的</li>
</ol>
<h2 id="简单的Api"><a href="#简单的Api" class="headerlink" title="简单的Api"></a>简单的Api</h2><ul>
<li>create</li>
<li>delete</li>
<li>exists</li>
<li>get</li>
<li>set</li>
<li>get child</li>
<li>sync</li>
</ul>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>每一个Server都有一个内存数据库，复制所有的树状数据，更新会持久化在硬盘上，用于恢复，写入内存数据库之前先写入硬盘。每一个Server使用本地数据响应Client的读取。</p>
<p>写入会交给leader节点集中处理，剩余的节点为follower。消息层处理leader失败，并同步所有flollower和leader</p>
<p>后续引入Observers，提高写入性能。参考：<a href="https://zookeeper.apache.org/doc/current/zookeeperObservers.html" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/current/zookeeperObservers.html</a></p>
<h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="单机版"><a href="#单机版" class="headerlink" title="单机版"></a>单机版</h2><p>jdk至少1.8，双核，2G内存，80G硬盘以上。</p>
<ol>
<li>安装jdk</li>
<li>下载Zookeeper</li>
<li>创建配置zoo.cfg，每一台机器必须互联</li>
</ol>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">/var/lib/zookeeper</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p> tickTime：基本时间，心跳时间是这个的2倍</p>
<p>dataDir：事务日志的存储位置，内存快照</p>
<p>clientPort：客户端连接端口</p>
</blockquote>
<ol start="4">
<li>启动</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/zkServer.sh start</span><br></pre></td></tr></table></figure>



<h2 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h2><p><a href="https://zookeeper.apache.org/doc/current/zookeeperStarted.html#sc_InstallingSingleMode" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/current/zookeeperStarted.html#sc_InstallingSingleMode</a></p>
<p>副本集部署方式下，至少需要3个节点，推荐奇数节点，配置文件不同的节点大部分相同，类似于</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">/var/lib/zookeeper</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">5</span></span><br><span class="line"><span class="meta">syncLimit</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">server.1</span>=<span class="string">zoo1:2888:3888</span></span><br><span class="line"><span class="meta">server.2</span>=<span class="string">zoo2:2888:3888</span></span><br><span class="line"><span class="meta">server.3</span>=<span class="string">zoo3:2888:3888</span></span><br></pre></td></tr></table></figure>

<p>其中initLimit表示跟随者连接和同步到领导者的时间量（单位为tickTime），syncLimit表示跟随者同步到领导者的时间量（单位为tickTime），如果失败过多，则会下线。</p>
<p>注：如果本地想模拟多个节点，则需要保证</p>
<ol>
<li><p>dataDir有多个</p>
</li>
<li><p>在【指定的dataDir目录/zookeeper】下面创建myid，内容为1-255的数，表示当前节点的id</p>
</li>
<li><p>保证端口开放。</p>
</li>
</ol>
<h1 id="食谱"><a href="#食谱" class="headerlink" title="食谱"></a>食谱</h1><blockquote>
<p>以下实例均来自3.4.10版本官方Recipes</p>
</blockquote>
<h2 id="服务发现-注册中心"><a href="#服务发现-注册中心" class="headerlink" title="服务发现/注册中心"></a>服务发现/注册中心</h2><blockquote>
<p>在网络通信中，通信双方往往需要指定对方的地址，但在分布式场景下，服务提供者与服务发现者通常都是多节点，而且随着动态扩容，节点地址和数量都会随之改变，所以，急需一个可以动态变更的注册表，用于存储各节点的地址信息。zookeeper就是比较好的例子之一，相似的组件有Eruke，Apollo，Nacos。zookeeper本身支持集群部署，降低单点故障的风险，且提供较好的读取性能（相对的，写入性能较差）</p>
</blockquote>
<ul>
<li>使用方式</li>
</ul>
<p>提供者注册时，向注册中心创建临时节点，并保存当前服务的ip端口等信息。消费者调用时，从zookeeper中拉取配置信息，并监听根节点，这样当新提供者上线时，可以获取到最新的服务列表；提供者启动时向zookeeper注册临时节点，当提供者下线时，zookeeper会自动移除临时节点。</p>
<ul>
<li>考量</li>
</ul>
<p>本质上利用节点的临时性和存储能力。</p>
<p>一般而言，服务信息随着部署而变化，变更不频繁，且数据稳定，数据量小，比较适合存储，但由于zookeeper写入时由leader承担了写入的职责，会将等待一半以上跟随者的投票，保持强一致性，所以写入性能相对较低。</p>
<p>在leader挂掉的时候，zookeeper系统会处于暂时不可用阶段，等待跟随者重新选举leader。所以说zookeeper仅保证CP，作为基础注册中心，在部分分区follower无法与leader通信时，会导致部分分区无法提供能力。</p>
<h2 id="栅栏（Barriers）"><a href="#栅栏（Barriers）" class="headerlink" title="栅栏（Barriers）"></a>栅栏（Barriers）</h2><blockquote>
<p>利用zookeeper的写一致性，将某个节点是否存在作为锁的标志</p>
</blockquote>
<ul>
<li>使用方式</li>
</ul>
<ol>
<li>客户端调用 <strong>exists()</strong>方法，并在这个节点设置watch</li>
<li>如果<strong>exists()</strong>方法返回false，说明栅栏消失，允许通过</li>
<li>如果返回true，客户端等待当前节点的watch事件触发</li>
<li>当watch事件触发后，客户端重新触发<strong>exists()</strong>，直到这个节点被移除</li>
</ol>
<ul>
<li>考量</li>
</ul>
<p>本质上利用watch和节点的原子性，每一个执行线程都是<strong>临时顺序节点</strong>。</p>
<p>当执行线程开始执行时，调用<strong>entry()</strong>方法进入栅栏，进入栅栏时创建子临时节点，调用getChildren()，判断栅栏中是否有足够的执行线程，如不足，则继续阻塞并继续监听栅栏节点，每一个执行线程进入时，由于调用了create，会触发watch监听，使之前阻塞的执行线程有机会判断。当执行线程均执行完成（即均调用退出栅栏方法）后，调用getChildren方法，判断是否还有未执行完的执行线程（子节点有值），如果均执行完成，则自己也退出。</p>
<p>阻塞操作利用Integer对象作为synchronized的监视器锁，调用Integer变量上的wait()和notify()实现线程阻塞。</p>
<p>对比jdk中的CyclicBarrier</p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><blockquote>
<p>利用zookeeper的写一致性，将某个节点是否存在作为锁的标志</p>
</blockquote>
<ul>
<li>官网使用方式</li>
</ul>
<ol>
<li>客户端调用 <strong>create()</strong>方法创建来自根节点（/locknode）下的<strong>顺序临时节点</strong>，表示准备申请锁</li>
<li>客户端不添加监听地调用<strong>getChildren()</strong>，查看所有待申请的锁</li>
<li>如果，通过path比对，判断当前的path的顺序是最小的，则获取到锁</li>
<li>否则，则调用<strong>exists()</strong>，添加监听，监听排在自己前面一个path，防止惊群效应。</li>
<li>如果调用<strong>exists()</strong>也返回null，说明，那个锁已经释放了，只能重新从第2步开始下一轮尝试获取锁。</li>
</ol>
<ul>
<li>考量</li>
</ul>
<p>本质上利用的节点的顺序性，公平锁。每一个待获取锁的对象都会在根节点下排队，当自己是根节点下最小，则获取到锁，并监听排序最大的那个节点变更，减少惊群现象。释放锁时，会删除当前节点，删除当前节点会触发之前监听的对象，获取到锁。按照这个顺序，待获取锁的对象以此获取锁。由于锁节点是临时节点，所以锁必然会释放，不会死锁。</p>
<p>属于互斥锁的实现原理。</p>
<p>读写锁的话，需要借用两个锁节点，读节点为xxx/read-，写节点为xxx/write-。获取读锁时，在第3步，需要结合write锁一同判断，获取写锁是，第3步只需要判断写锁是否存在即可。</p>
<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><blockquote>
<p>利用节点的顺序性，可以实现单对单的消息队列</p>
</blockquote>
<ul>
<li>使用方式</li>
</ul>
<ol>
<li>创建一个持久化节点，作为队列节点</li>
<li>客户端创建一个以’queue-‘开头的<strong>临时顺序节点</strong>，顺序节点保证消息的顺序性</li>
<li>当客户端需要消费时，会循环获取队列节点下的节点，并获取到最小序号（最早的消息），并调用<strong>getData()</strong>获取内容，然后删除这个消息节点，接着就可以处理这个消息了。这里也利用监视器锁，当队列节点下没有消息节点是，调用wait等待，当触发watch后，调用notify触发。</li>
</ol>
<ul>
<li>考量</li>
</ul>
<p>利用的是节点的顺序性和原子性，每一次消息的获取可以理解为从zookeeper中摘取节点，且每一次摘取的只是顺序最小的，每一次摘取完都会删除消息，如果删除消息失败，说明另外一个消费者已经消费了此消息，此时循环再次尝试获取。以此保证消息仅一次消费。</p>
<p>使用队列时需要注意，1.消息不能过大，znode存储有限，2.消息总数有一个限制，当然顺序自增的数量比较大，3.消息堆积时，对于消费者消费压力较大，因为要获取所有子节点，然后判断，存在内存溢出的风险。</p>
<ul>
<li>优先级队列</li>
</ul>
<p>如果想实现优先级队列，只需要修改获取消息的逻辑，把获取<strong>最小顺序</strong>替换为获取<strong>优先级最高</strong>的子节点。</p>
<h1 id="常用使用场景"><a href="#常用使用场景" class="headerlink" title="常用使用场景"></a>常用使用场景</h1><blockquote>
<p>主要是高可用做动态发现</p>
</blockquote>
<p>Kafka</p>
<p>Dubbo</p>
<p>Hadoop</p>
]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
      <tags>
        <tag>组件</tag>
        <tag>小结</tag>
      </tags>
  </entry>
  <entry>
    <title>Kudu源码阅读</title>
    <url>/2024/02/24/3_Kudu%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<p>Kudu读取过程</p>
<ol>
<li>Tablet的rowset结构</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct TabletComponents : public RefCountedThreadSafe&lt;TabletComponents&gt; &#123;</span><br><span class="line">  TabletComponents(std::shared_ptr&lt;MemRowSet&gt; mrs,</span><br><span class="line">                   std::vector&lt;std::shared_ptr&lt;MemRowSet&gt;&gt; txn_mrss,</span><br><span class="line">                   std::shared_ptr&lt;RowSetTree&gt; rs_tree);</span><br><span class="line">  &#x2F;&#x2F; The &quot;main&quot; MemRowSet that catches inserts to the tablet that are not a</span><br><span class="line">  &#x2F;&#x2F; part of any transaction.</span><br><span class="line">  const std::shared_ptr&lt;MemRowSet&gt; memrowset;</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; MemRowSets whose insertion heads were inserted as a part of a transaction.</span><br><span class="line">  const std::vector&lt;std::shared_ptr&lt;MemRowSet&gt;&gt; txn_memrowsets;</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; The persisted RowSets that comprise the rows of a tablet.</span><br><span class="line">  const std::shared_ptr&lt;RowSetTree&gt; rowsets;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>主要类结构图</li>
</ol>
<p><img src="/2024/02/24/3_Kudu%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/1.png" alt="image-202306" loading="lazy"></p>
<ol start="3">
<li>代码流程</li>
</ol>
<p>C++暴露的Scan接口，由JavaClient的org.apache.kudu.client.AsyncKuduClient#sendRpcToTablet发出RPC请求，扫描数据，kudu服务器接受请求的是kudu.tserver.TabletServerService的Scan（中间经过RPC层中转）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.kudu.client.AsyncKuduScanner#nextRows</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Deferred&lt;RowResultIterator&gt; <span class="title">nextRows</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (closed) &#123;  <span class="comment">// We're already done scanning.</span></span><br><span class="line">      <span class="keyword">if</span> (prefetching &amp;&amp; cachedPrefetcherDeferred.get() != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// return the cached result and reset the cache.</span></span><br><span class="line">        <span class="keyword">return</span> cachedPrefetcherDeferred.getAndUpdate((v) -&gt; <span class="keyword">null</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> Deferred.fromResult(<span class="keyword">null</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tablet == <span class="keyword">null</span>) &#123;</span><br><span class="line">      Callback&lt;Deferred&lt;RowResultIterator&gt;, AsyncKuduScanner.Response&gt; cb =</span><br><span class="line">          <span class="keyword">new</span> Callback&lt;Deferred&lt;RowResultIterator&gt;, Response&gt;() &#123;</span><br><span class="line">         ...</span><br><span class="line">      &#125;;</span><br><span class="line"></span><br><span class="line">      Callback&lt;Deferred&lt;RowResultIterator&gt;, Exception&gt; eb =</span><br><span class="line">          <span class="keyword">new</span> Callback&lt;Deferred&lt;RowResultIterator&gt;, Exception&gt;() &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 发起请求</span></span><br><span class="line">      <span class="keyword">return</span> client.sendRpcToTablet(getOpenRequest()).addCallbackDeferring(cb).addErrback(eb);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (prefetching &amp;&amp; cachedPrefetcherDeferred.get() != <span class="keyword">null</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> Deferred&lt;RowResultIterator&gt; d =</span><br><span class="line">        client.scanNextRows(<span class="keyword">this</span>).addCallbacks(gotNextRow, nextRowErrback());</span><br><span class="line">    <span class="keyword">if</span> (prefetching) &#123;</span><br><span class="line">      d.chain(<span class="keyword">new</span> Deferred&lt;RowResultIterator&gt;().addCallback(prefetch));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> d;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>KuduServer（C++），1.17版本</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TabletServiceImpl::Scan</span><span class="params">(<span class="keyword">const</span> ScanRequestPB* req,</span></span></span><br><span class="line"><span class="function"><span class="params">                             ScanResponsePB* resp,</span></span></span><br><span class="line"><span class="function"><span class="params">                             RpcContext* context)</span> </span>&#123;</span><br><span class="line">  TRACE_EVENT0(<span class="string">"tserver"</span>, <span class="string">"TabletServiceImpl::Scan"</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// check 第一次读取数据，或者第二次读取</span></span><br><span class="line">  <span class="keyword">if</span> (PREDICT_FALSE(req-&gt;has_scanner_id() &amp;&amp;</span><br><span class="line">                    req-&gt;has_new_scan_request())) &#123;</span><br><span class="line">    context-&gt;RespondFailure(Status::InvalidArgument(</span><br><span class="line">                            <span class="string">"Must not pass both a scanner_id and new_scan_request"</span>));</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 验证是否有权限</span></span><br><span class="line">  TokenPB token;</span><br><span class="line">  <span class="keyword">if</span> (FLAGS_tserver_enforce_access_control &amp;&amp; req-&gt;has_new_scan_request()) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span>&amp; scan_pb = req-&gt;new_scan_request();</span><br><span class="line">    <span class="keyword">if</span> (!VerifyAuthzTokenOrRespond(server_-&gt;token_verifier(),</span><br><span class="line">                                   req-&gt;new_scan_request(), context, &amp;token)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    scoped_refptr&lt;TabletReplica&gt; replica;</span><br><span class="line">    <span class="keyword">if</span> (!LookupRunningTabletReplicaOrRespond(server_-&gt;tablet_manager(),</span><br><span class="line">        req-&gt;new_scan_request().tablet_id(), resp, context, &amp;replica)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span>&amp; privilege = token.authz().table_privilege();</span><br><span class="line">    <span class="keyword">if</span> (!CheckMatchingTableIdOrRespond(privilege, replica-&gt;tablet_metadata()-&gt;table_id(),</span><br><span class="line">                                       <span class="string">"Scan"</span>, context)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">unordered_set</span>&lt;ColumnId&gt; authorized_column_ids;</span><br><span class="line">    <span class="keyword">if</span> (!CheckMayHaveScanPrivilegesOrRespond(privilege, <span class="string">"Scan"</span>, &amp;authorized_column_ids, context)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// If the token doesn't have full scan privileges for the table, check</span></span><br><span class="line">    <span class="comment">// for required privileges based on the scan request.</span></span><br><span class="line">    <span class="keyword">if</span> (!privilege.scan_privilege()) &#123;</span><br><span class="line">      <span class="keyword">const</span> SchemaPtr schema_ptr = replica-&gt;tablet_metadata()-&gt;schema();</span><br><span class="line">      <span class="keyword">if</span> (!CheckScanPrivilegesOrRespond(scan_pb, *schema_ptr, authorized_column_ids,</span><br><span class="line">                                        <span class="string">"Scan"</span>, context)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//开始读数据</span></span><br><span class="line">  <span class="function">ScanResultCopier <span class="title">collector</span><span class="params">(GetMaxBatchSizeBytesHint(req))</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">bool</span> has_more_results = <span class="literal">false</span>;</span><br><span class="line">  TabletServerErrorPB::Code error_code = TabletServerErrorPB::UNKNOWN_ERROR;</span><br><span class="line">  <span class="keyword">if</span> (req-&gt;has_new_scan_request()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!CheckTabletServerNotQuiescingOrRespond(server_, resp, context)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> NewScanRequestPB&amp; scan_pb = req-&gt;new_scan_request();</span><br><span class="line">    scoped_refptr&lt;TabletReplica&gt; replica;</span><br><span class="line">    <span class="keyword">if</span> (!LookupRunningTabletReplicaOrRespond(server_-&gt;tablet_manager(), scan_pb.tablet_id(), resp,</span><br><span class="line">                                             context, &amp;replica)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">string</span> scanner_id;</span><br><span class="line">    Timestamp scan_timestamp;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//开始读取数据，并记录scanner_id</span></span><br><span class="line">    Status s = HandleNewScanRequest(replica.<span class="built_in">get</span>(), req, context,</span><br><span class="line">                                    &amp;collector, &amp;scanner_id, &amp;scan_timestamp, &amp;has_more_results,</span><br><span class="line">                                    &amp;error_code);</span><br><span class="line">    <span class="keyword">if</span> (PREDICT_FALSE(!s.ok())) &#123;</span><br><span class="line">      SetupErrorAndRespond(resp-&gt;mutable_error(), s, error_code, context);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Only set the scanner id if we have more results.</span></span><br><span class="line">    <span class="keyword">if</span> (has_more_results) &#123;</span><br><span class="line">      resp-&gt;set_scanner_id(scanner_id);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (scan_timestamp != Timestamp::kInvalidTimestamp) &#123;</span><br><span class="line">      resp-&gt;set_snap_timestamp(scan_timestamp.ToUint64());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (req-&gt;has_scanner_id()) &#123;</span><br><span class="line">    <span class="comment">//继续读取数据</span></span><br><span class="line">    Status s = HandleContinueScanRequest(req, context, &amp;collector, &amp;has_more_results, &amp;error_code);</span><br><span class="line">    <span class="keyword">if</span> (PREDICT_FALSE(!s.ok())) &#123;</span><br><span class="line">      SetupErrorAndRespond(resp-&gt;mutable_error(), s, error_code, context);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    context-&gt;RespondFailure(Status::InvalidArgument(</span><br><span class="line">                              <span class="string">"Must pass either a scanner_id or new_scan_request"</span>));</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  collector.SetupResponse(context, resp);</span><br><span class="line">  resp-&gt;set_has_more_results(has_more_results);</span><br><span class="line">  resp-&gt;set_propagated_timestamp(server_-&gt;clock()-&gt;Now().ToUint64());</span><br><span class="line"></span><br><span class="line">  SetResourceMetrics(context, collector.cpu_times(), resp-&gt;mutable_resource_metrics());</span><br><span class="line">  context-&gt;RespondSuccess();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>第一次读取</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">TabletServiceImpl::HandleNewScanRequest</span><span class="params">(TabletReplica* replica,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               <span class="keyword">const</span> ScanRequestPB* req,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               <span class="keyword">const</span> RpcContext* rpc_context,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               ScanResultCollector* result_collector,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               <span class="built_in">string</span>* scanner_id,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               Timestamp* snap_timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               <span class="keyword">bool</span>* has_more_results,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               TabletServerErrorPB::Code* error_code)</span> </span>&#123;</span><br><span class="line">  ... 省略了一波操作</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//初始化RowwiseIterator迭代器</span></span><br><span class="line">  <span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt; iter;</span><br><span class="line">  optional&lt;Timestamp&gt; snap_start_timestamp;</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">    TRACE(<span class="string">"Creating iterator"</span>);</span><br><span class="line">    TRACE_EVENT0(<span class="string">"tserver"</span>, <span class="string">"Create iterator"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">switch</span> (scan_pb.read_mode()) &#123;</span><br><span class="line">      <span class="keyword">case</span> UNKNOWN_READ_MODE: &#123;</span><br><span class="line">        *error_code = TabletServerErrorPB::INVALID_SCAN_SPEC;</span><br><span class="line">        <span class="keyword">return</span> Status::NotSupported(<span class="string">"Unknown read mode."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> READ_LATEST: &#123;</span><br><span class="line">        <span class="keyword">if</span> (scan_pb.has_snap_start_timestamp()) &#123;</span><br><span class="line">          *error_code = TabletServerErrorPB::INVALID_SCAN_SPEC;</span><br><span class="line">          <span class="keyword">return</span> Status::InvalidArgument(<span class="string">"scan start timestamp is only supported "</span></span><br><span class="line">                                         <span class="string">"in READ_AT_SNAPSHOT read mode"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//通过tablet初始化RowIterator器</span></span><br><span class="line">        s = tablet-&gt;NewRowIterator(projection, &amp;iter);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> READ_YOUR_WRITES: <span class="comment">// Fallthrough intended</span></span><br><span class="line">      <span class="keyword">case</span> READ_AT_SNAPSHOT: &#123;</span><br><span class="line">        s = HandleScanAtSnapshot(</span><br><span class="line">            scan_pb, rpc_context, projection, tablet.<span class="built_in">get</span>(), replica-&gt;time_manager(),</span><br><span class="line">            &amp;iter, &amp;snap_start_timestamp, snap_timestamp, error_code);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    TRACE(<span class="string">"Iterator created"</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">	 <span class="comment">//省略一堆</span></span><br><span class="line">	 </span><br><span class="line">  scanner-&gt;Init(<span class="built_in">std</span>::<span class="built_in">move</span>(iter), <span class="built_in">std</span>::<span class="built_in">move</span>(orig_spec), <span class="built_in">std</span>::<span class="built_in">move</span>(client_projection));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Stop the scanner timer because ContinueScanRequest starts its own timer.</span></span><br><span class="line">  scanner_timer.Stop();</span><br><span class="line">  unreg_scanner.Cancel();</span><br><span class="line">  *scanner_id = scanner-&gt;id();</span><br><span class="line"></span><br><span class="line">  VLOG(<span class="number">1</span>) &lt;&lt; <span class="string">"Started scanner "</span> &lt;&lt; scanner-&gt;id() &lt;&lt; <span class="string">": "</span> &lt;&lt; scanner-&gt;iter()-&gt;ToString();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (GetMaxBatchSizeBytesHint(req) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    TRACE(<span class="string">"Continuing scan request"</span>);</span><br><span class="line">    <span class="comment">// TODO(wdberkeley): Instead of copying the pb, instead split</span></span><br><span class="line">    <span class="comment">// HandleContinueScanRequest and call the second half directly. Once that's</span></span><br><span class="line">    <span class="comment">// done, remove the call to ScopedAddScannerTiming::Stop() above (and the</span></span><br><span class="line">    <span class="comment">// method as it won't be used) and start the timing for continue requests</span></span><br><span class="line">    <span class="comment">// from the first half that is no longer executed in this codepath.</span></span><br><span class="line">    <span class="function">ScanRequestPB <span class="title">continue_req</span><span class="params">(*req)</span></span>;</span><br><span class="line">    continue_req.set_scanner_id(scanner-&gt;id());</span><br><span class="line">    scanner_lock.Unlock();</span><br><span class="line">    <span class="comment">//初始化好了scanRequest，开始扫描</span></span><br><span class="line">    <span class="keyword">return</span> HandleContinueScanRequest(</span><br><span class="line">        &amp;continue_req, rpc_context, result_collector, has_more_results, error_code);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Increment the scanner call sequence ID. HandleContinueScanRequest handles</span></span><br><span class="line">  <span class="comment">// this in the non-empty scan case.</span></span><br><span class="line">  scanner-&gt;IncrementCallSeqId();</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里是读取历史的，和上面代码类似</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">TabletServiceImpl::HandleContinueScanRequest</span><span class="params">(<span class="keyword">const</span> ScanRequestPB* req,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    <span class="keyword">const</span> RpcContext* rpc_context,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    ScanResultCollector* result_collector,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    <span class="keyword">bool</span>* has_more_results,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    TabletServerErrorPB::Code* error_code)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//省略</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">//获取scan</span></span><br><span class="line">  <span class="keyword">size_t</span> batch_size_bytes = GetMaxBatchSizeBytesHint(req);</span><br><span class="line"></span><br><span class="line">  SharedScanner scanner;</span><br><span class="line">  TabletServerErrorPB::Code code = TabletServerErrorPB::UNKNOWN_ERROR;</span><br><span class="line">  Status s = server_-&gt;scanner_manager()-&gt;LookupScanner(req-&gt;scanner_id(),</span><br><span class="line">                                                       rpc_context-&gt;remote_user().username(),</span><br><span class="line">                                                       &amp;code,</span><br><span class="line">                                                       &amp;scanner);</span><br><span class="line">  <span class="comment">//省略</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">//获取迭代读取器</span></span><br><span class="line">  RowwiseIterator* iter = scanner-&gt;iter();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Set the row format flags on the ScanResultCollector.</span></span><br><span class="line">  s = result_collector-&gt;InitSerializer(scanner-&gt;row_format_flags(),</span><br><span class="line">                                       iter-&gt;schema(),</span><br><span class="line">                                       *scanner-&gt;client_projection_schema());</span><br><span class="line">  <span class="keyword">if</span> (!s.ok()) &#123;</span><br><span class="line">    *error_code = TabletServerErrorPB::INVALID_SCAN_SPEC;</span><br><span class="line">    <span class="keyword">return</span> s;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO(todd): could size the RowBlock based on the user's requested batch size?</span></span><br><span class="line">  <span class="comment">// If people had really large indirect objects, we would currently overshoot</span></span><br><span class="line">  <span class="comment">// their requested batch size by a lot.</span></span><br><span class="line">  <span class="function">RowBlockMemory <span class="title">mem</span><span class="params">(<span class="number">32</span> * <span class="number">1024</span>)</span></span>;</span><br><span class="line">  <span class="function">RowBlock <span class="title">block</span><span class="params">(&amp;iter-&gt;schema(), FLAGS_scanner_batch_size_rows, &amp;mem)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO(todd): in the future, use the client timeout to set a budget. For now,</span></span><br><span class="line">  <span class="comment">// just use a half second, which should be plenty to amortize call overhead.</span></span><br><span class="line">  <span class="keyword">int</span> budget_ms = <span class="number">500</span>;</span><br><span class="line">  MonoTime deadline = MonoTime::Now() + MonoDelta::FromMilliseconds(budget_ms);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int64_t</span> rows_scanned = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (iter-&gt;HasNext() &amp;&amp; !scanner-&gt;has_fulfilled_limit()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (PREDICT_FALSE(FLAGS_scanner_inject_latency_on_each_batch_ms &gt; <span class="number">0</span>)) &#123;</span><br><span class="line">      SleepFor(MonoDelta::FromMilliseconds(FLAGS_scanner_inject_latency_on_each_batch_ms));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照block块读取</span></span><br><span class="line">    Status s = iter-&gt;NextBlock(&amp;block);</span><br><span class="line">    <span class="keyword">if</span> (PREDICT_FALSE(!s.ok())) &#123;</span><br><span class="line">      LOG(WARNING) &lt;&lt; <span class="string">"Copying rows from internal iterator for request "</span></span><br><span class="line">                   &lt;&lt; SecureShortDebugString(*req);</span><br><span class="line">      *error_code = TabletServerErrorPB::UNKNOWN_ERROR;</span><br><span class="line">      <span class="keyword">return</span> s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (PREDICT_TRUE(block.nrows() &gt; <span class="number">0</span>)) &#123;</span><br><span class="line">      <span class="comment">// Count the number of rows scanned, regardless of predicates or deletions.</span></span><br><span class="line">      <span class="comment">// The collector will separately count the number of rows actually returned to</span></span><br><span class="line">      <span class="comment">// the client.</span></span><br><span class="line">      rows_scanned += block.nrows();</span><br><span class="line">      <span class="keyword">if</span> (scanner-&gt;spec().has_limit()) &#123;</span><br><span class="line">        <span class="keyword">int64_t</span> rows_left = scanner-&gt;spec().limit() - scanner-&gt;num_rows_returned();</span><br><span class="line">        DCHECK_GT(rows_left, <span class="number">0</span>);  <span class="comment">// Guaranteed by has_fulfilled_limit()</span></span><br><span class="line">        block.selection_vector()-&gt;ClearToSelectAtMost(<span class="keyword">static_cast</span>&lt;<span class="keyword">size_t</span>&gt;(rows_left));</span><br><span class="line">      &#125;</span><br><span class="line">      result_collector-&gt;HandleRowBlock(scanner.<span class="built_in">get</span>(), block);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//省略</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (response_size &gt;= batch_size_bytes) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//省略返回数据</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>经过Scan的读取（第一次和第二次），开始初始化RowIterator</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Status Tablet::NewRowIterator(const Schema&amp; projection,</span><br><span class="line">                              unique_ptr&lt;RowwiseIterator&gt;* iter) const &#123;</span><br><span class="line">  RowIteratorOptions opts;</span><br><span class="line">  &#x2F;&#x2F; Yield current rows.</span><br><span class="line">  opts.snap_to_include &#x3D; MvccSnapshot(mvcc_);</span><br><span class="line">  opts.projection &#x3D; &amp;projection;</span><br><span class="line">  return NewRowIterator(std::move(opts), iter);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Status Tablet::NewRowIterator(RowIteratorOptions opts,</span><br><span class="line">                              unique_ptr&lt;RowwiseIterator&gt;* iter) const &#123;</span><br><span class="line">  RETURN_IF_STOPPED_OR_CHECK_STATE(kOpen);</span><br><span class="line">  if (metrics_) &#123;</span><br><span class="line">    metrics_-&gt;scans_started-&gt;Increment();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  VLOG_WITH_PREFIX(2) &lt;&lt; &quot;Created new Iterator for snapshot range: (&quot;</span><br><span class="line">                      &lt;&lt; (opts.snap_to_exclude ? opts.snap_to_exclude-&gt;ToString() : &quot;-Inf&quot;)</span><br><span class="line">                      &lt;&lt; &quot;, &quot; &lt;&lt; opts.snap_to_include.ToString() &lt;&lt; &quot;)&quot;;</span><br><span class="line">	&#x2F;&#x2F;开始初始化迭代器</span><br><span class="line">  iter-&gt;reset(new Iterator(this, std::move(opts)));</span><br><span class="line">  ret</span><br></pre></td></tr></table></figure>

<p>迭代器主要包括，继承自RowwiseIterator的有MergeIterator，UnionIterator，MaterializingIterator，PredicateEvaluatingIterator，集成自ColumnwiseIterator的有DeltaApplier，CFileSet负责读取</p>
<p>这里初始化第一部分：核心Iterator来自NewRowIteratorWithBounds或NewRowIterator方法，Iterator的初始化函数如下，初始化了MergeIterator或UnionIterator。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Status Tablet::Iterator::Init(ScanSpec *spec) &#123;</span><br><span class="line">  RETURN_NOT_OK(tablet_-&gt;CheckHasNotBeenStopped());</span><br><span class="line">  DCHECK(iter_.<span class="built_in">get</span>() == <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">  RETURN_NOT_OK(tablet_-&gt;GetMappedReadProjection(projection_, &amp;projection_));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">vector</span>&lt;IterWithBounds&gt; iters;</span><br><span class="line">  <span class="comment">//第一步初始化，memRowSet和diskRowSet的Iterator</span></span><br><span class="line">  RETURN_NOT_OK(tablet_-&gt;CaptureConsistentIterators(opts_, spec, &amp;iters));</span><br><span class="line">  TRACE_COUNTER_INCREMENT(<span class="string">"rowset_iterators"</span>, iters.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">//第二步初始化</span></span><br><span class="line">  <span class="keyword">switch</span> (opts_.order) &#123;</span><br><span class="line">    <span class="keyword">case</span> ORDERED:</span><br><span class="line">      iter_ = NewMergeIterator(MergeIteratorOptions(opts_.include_deleted_rows), <span class="built_in">std</span>::<span class="built_in">move</span>(iters));</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> UNORDERED:</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      iter_ = NewUnionIterator(<span class="built_in">std</span>::<span class="built_in">move</span>(iters));</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">//根据规格进行初始化</span></span><br><span class="line">  RETURN_NOT_OK(iter_-&gt;Init(spec));</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在MergeIterator和UnionIterator的InitSubIterators方法中，都会调用nitAndMaybeWrap初始化内部迭代器。其中初始化的是PredicateEvaluatingIterator，多个迭代器都只是RowwiseIterator的封装，执行了谓词下推，合并等逻辑。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">MergeIterator::InitSubIterators</span><span class="params">(ScanSpec *spec)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Initialize all the sub iterators.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; i : orig_iters_) &#123;</span><br><span class="line">    ScanSpec *spec_copy = spec != <span class="literal">nullptr</span> ? scan_spec_copies_.Construct(*spec) : <span class="literal">nullptr</span>;</span><br><span class="line">    RETURN_NOT_OK(InitAndMaybeWrap(&amp;i.iter, spec_copy));</span><br><span class="line">    <span class="function"><span class="built_in">unique_ptr</span>&lt;MergeIterState&gt; <span class="title">state</span><span class="params">(<span class="keyword">new</span> MergeIterState(<span class="built_in">std</span>::<span class="built_in">move</span>(i)))</span></span>;</span><br><span class="line">    RETURN_NOT_OK(state-&gt;Init(&amp;decoded_bounds_memory_));</span><br><span class="line">    states_.push_back(*state.<span class="built_in">release</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  orig_iters_.<span class="built_in">clear</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Since we handle predicates in all the wrapped iterators, we can clear</span></span><br><span class="line">  <span class="comment">// them here.</span></span><br><span class="line">  <span class="keyword">if</span> (spec != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    spec-&gt;RemovePredicates();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>PredicateEvaluatingIterator内部包含底层的Iterator，只是一个包装，有自己的谓词下推逻辑，数据读取还是靠底层Iterator</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">UnionIterator::InitSubIterators</span><span class="params">(ScanSpec *spec)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; i : iters_) &#123;</span><br><span class="line">    ScanSpec *spec_copy = spec != <span class="literal">nullptr</span> ? scan_spec_copies_.Construct(*spec) : <span class="literal">nullptr</span>;</span><br><span class="line">    RETURN_NOT_OK(InitAndMaybeWrap(&amp;i.iter, spec_copy));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The union iterator doesn't care about these, so let's drop them now to</span></span><br><span class="line">    <span class="comment">// free some memory.</span></span><br><span class="line">    i.encoded_bounds.reset();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Since we handle predicates in all the wrapped iterators, we can clear</span></span><br><span class="line">  <span class="comment">// them here.</span></span><br><span class="line">  <span class="keyword">if</span> (spec != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    spec-&gt;RemovePredicates();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">InitAndMaybeWrap</span><span class="params">(<span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt;* base_iter,</span></span></span><br><span class="line"><span class="function"><span class="params">                        ScanSpec *spec)</span> </span>&#123;</span><br><span class="line">  RETURN_NOT_OK((*base_iter)-&gt;Init(spec));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (spec != <span class="literal">nullptr</span> &amp;&amp; !spec-&gt;predicates().empty()) &#123;</span><br><span class="line">    <span class="comment">// Underlying iterator did not accept all predicates. Wrap it.</span></span><br><span class="line">    <span class="function"><span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt; <span class="title">wrapper</span><span class="params">(<span class="keyword">new</span> PredicateEvaluatingIterator(<span class="built_in">std</span>::<span class="built_in">move</span>(*base_iter)))</span></span>;</span><br><span class="line">    RETURN_NOT_OK(wrapper-&gt;Init(spec));</span><br><span class="line">    *base_iter = <span class="built_in">std</span>::<span class="built_in">move</span>(wrapper);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>CaptureConsistentIterators会尝试读取memRowSet和diskRowSet的iterator</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Tablet::CaptureConsistentIterators</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> RowIteratorOptions&amp; opts,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> ScanSpec* spec,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="built_in">vector</span>&lt;IterWithBounds&gt;* iters)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function">shared_lock&lt;rw_spinlock&gt; <span class="title">l</span><span class="params">(component_lock_)</span></span>;</span><br><span class="line">  RETURN_IF_STOPPED_OR_CHECK_STATE(kOpen);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Construct all the iterators locally first, so that if we fail</span></span><br><span class="line">  <span class="comment">// in the middle, we don't modify the output arguments.</span></span><br><span class="line">  <span class="built_in">vector</span>&lt;IterWithBounds&gt; ret;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取MemRowSet</span></span><br><span class="line">  <span class="comment">// Grab the memrowset iterator.</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt; ms_iter;</span><br><span class="line">    RETURN_NOT_OK(components_-&gt;memrowset-&gt;NewRowIterator(opts, &amp;ms_iter));</span><br><span class="line">    IterWithBounds mrs_iwb;</span><br><span class="line">    mrs_iwb.iter = <span class="built_in">std</span>::<span class="built_in">move</span>(ms_iter);</span><br><span class="line">    ret.emplace_back(<span class="built_in">std</span>::<span class="built_in">move</span>(mrs_iwb));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取在已提交事务中的MemRowSet</span></span><br><span class="line">  <span class="comment">// Capture any iterators for memrowsets whose inserts were added as a part of</span></span><br><span class="line">  <span class="comment">// committed transactions.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; txn_mrs : components_-&gt;txn_memrowsets) &#123;</span><br><span class="line">    <span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt; txn_ms_iter;</span><br><span class="line">    RETURN_NOT_OK(txn_mrs-&gt;NewRowIterator(opts, &amp;txn_ms_iter));</span><br><span class="line">    IterWithBounds txn_mrs_iwb;</span><br><span class="line">    txn_mrs_iwb.iter = <span class="built_in">std</span>::<span class="built_in">move</span>(txn_ms_iter);</span><br><span class="line">    ret.emplace_back(<span class="built_in">std</span>::<span class="built_in">move</span>(txn_mrs_iwb));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据Key范围找到RowSet</span></span><br><span class="line">  <span class="comment">// Cull row-sets in the case of key-range queries.</span></span><br><span class="line">  <span class="keyword">if</span> (spec != <span class="literal">nullptr</span> &amp;&amp; (spec-&gt;lower_bound_key() || spec-&gt;exclusive_upper_bound_key())) &#123;</span><br><span class="line">    optional&lt;Slice&gt; lower_bound = spec-&gt;lower_bound_key() ?</span><br><span class="line">        optional&lt;Slice&gt;(spec-&gt;lower_bound_key()-&gt;encoded_key()) : nullopt;</span><br><span class="line">    optional&lt;Slice&gt; upper_bound = spec-&gt;exclusive_upper_bound_key() ?</span><br><span class="line">        optional&lt;Slice&gt;(spec-&gt;exclusive_upper_bound_key()-&gt;encoded_key()) : nullopt;</span><br><span class="line">    <span class="built_in">vector</span>&lt;RowSet*&gt; interval_sets;</span><br><span class="line">    components_-&gt;rowsets-&gt;FindRowSetsIntersectingInterval(lower_bound, upper_bound, &amp;interval_sets);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>* rs : interval_sets) &#123;</span><br><span class="line">      IterWithBounds iwb;</span><br><span class="line">      RETURN_NOT_OK_PREPEND(rs-&gt;NewRowIteratorWithBounds(opts, &amp;iwb),</span><br><span class="line">                            Substitute(<span class="string">"Could not create iterator for rowset $0"</span>,</span><br><span class="line">                                       rs-&gt;ToString()));</span><br><span class="line">      ret.emplace_back(<span class="built_in">std</span>::<span class="built_in">move</span>(iwb));</span><br><span class="line">    &#125;</span><br><span class="line">    *iters = <span class="built_in">std</span>::<span class="built_in">move</span>(ret);</span><br><span class="line">    <span class="keyword">return</span> Status::OK();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//如果没有Key范围，那就查询所有RowSet</span></span><br><span class="line">  <span class="comment">// If there are no encoded predicates of the primary keys, then</span></span><br><span class="line">  <span class="comment">// fall back to grabbing all rowset iterators.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;RowSet&gt;&amp; rs : components_-&gt;rowsets-&gt;all_rowsets()) &#123;</span><br><span class="line">    IterWithBounds iwb;</span><br><span class="line">    RETURN_NOT_OK_PREPEND(rs-&gt;NewRowIteratorWithBounds(opts, &amp;iwb),</span><br><span class="line">                          Substitute(<span class="string">"Could not create iterator for rowset $0"</span>,</span><br><span class="line">                                     rs-&gt;ToString()));</span><br><span class="line">    ret.emplace_back(<span class="built_in">std</span>::<span class="built_in">move</span>(iwb));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Swap results into the parameters.</span></span><br><span class="line">  *iters = <span class="built_in">std</span>::<span class="built_in">move</span>(ret);</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当MemRowSet初始化Iterator时，会直接通过SeekToStart完成数据检索</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">MemRowSet::Iterator* <span class="title">MemRowSet::NewIterator</span><span class="params">(<span class="keyword">const</span> RowIteratorOptions&amp; opts)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> MemRowSet::Iterator(shared_from_this(), tree_.NewIterator(), opts);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">MemRowSet::Iterator* <span class="title">MemRowSet::NewIterator</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// TODO(todd): can we kill this function? should be only used by tests?</span></span><br><span class="line">  RowIteratorOptions opts;</span><br><span class="line">  opts.projection = &amp;schema();</span><br><span class="line">  <span class="keyword">return</span> NewIterator(opts);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">MemRowSet::NewRowIterator</span><span class="params">(<span class="keyword">const</span> RowIteratorOptions&amp; opts,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt;* out)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  out-&gt;reset(NewIterator(opts));</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br><span class="line">MemRowSet::Iterator::Iterator(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;<span class="keyword">const</span> MemRowSet&gt;&amp; mrs,</span><br><span class="line">                              MemRowSet::MSBTIter* iter,</span><br><span class="line">                              RowIteratorOptions opts)</span><br><span class="line">    : memrowset_(mrs),</span><br><span class="line">      iter_(iter),</span><br><span class="line">      opts_(<span class="built_in">std</span>::<span class="built_in">move</span>(opts)),</span><br><span class="line">      projector_(</span><br><span class="line">          GenerateAppropriateProjector(&amp;mrs-&gt;schema_nonvirtual(), opts_.projection)),</span><br><span class="line">      delta_projector_(&amp;mrs-&gt;schema_nonvirtual(), opts_.projection),</span><br><span class="line">      projection_vc_is_deleted_idx_(opts_.projection-&gt;first_is_deleted_virtual_column_idx()),</span><br><span class="line">      state_(kUninitialized) &#123;</span><br><span class="line">  <span class="comment">// TODO(todd): various code assumes that a newly constructed iterator</span></span><br><span class="line">  <span class="comment">// is pointed at the beginning of the dataset. This causes a redundant</span></span><br><span class="line">  <span class="comment">// seek. Could make this lazy instead, or change the semantics so that</span></span><br><span class="line">  <span class="comment">// a seek is required (probably the latter)</span></span><br><span class="line">  iter_-&gt;SeekToStart();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当diskRowSet初始化Iterator时，会初始化MaterializingIterator，而MaterializingIterator包含ColumnwiseIterator</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DiskRowSet::NewRowIterator</span><span class="params">(<span class="keyword">const</span> RowIteratorOptions&amp; opts,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="built_in">unique_ptr</span>&lt;RowwiseIterator&gt;* out)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  DCHECK(open_);</span><br><span class="line">  <span class="function">shared_lock&lt;rw_spinlock&gt; <span class="title">l</span><span class="params">(component_lock_)</span></span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//可以看出base Iter是通过CFileSet::Iterator检索</span></span><br><span class="line">  <span class="function"><span class="built_in">shared_ptr</span>&lt;CFileSet::Iterator&gt; <span class="title">base_iter</span><span class="params">(base_data_-&gt;NewIterator(opts.projection,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                                   opts.io_context))</span></span>;</span><br><span class="line">                                                                   </span><br><span class="line">  <span class="comment">//delta是由ColumnwiseIterator包裹的DeltaIterator检索</span></span><br><span class="line">  <span class="built_in">unique_ptr</span>&lt;ColumnwiseIterator&gt; col_iter;</span><br><span class="line">  RETURN_NOT_OK(delta_tracker_-&gt;WrapIterator(base_iter, opts, &amp;col_iter));</span><br><span class="line"></span><br><span class="line">  *out = NewMaterializingIterator(<span class="built_in">std</span>::<span class="built_in">move</span>(col_iter));</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>delta data由DeltaTracker检索，合并undo，redo和delta memberstore</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DeltaTracker::WrapIterator</span><span class="params">(<span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;CFileSet::Iterator&gt; &amp;base,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="keyword">const</span> RowIteratorOptions&amp; opts,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="built_in">unique_ptr</span>&lt;ColumnwiseIterator&gt;* out)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="built_in">unique_ptr</span>&lt;DeltaIterator&gt; iter;</span><br><span class="line">  RETURN_NOT_OK(NewDeltaIterator(opts, &amp;iter));</span><br><span class="line"></span><br><span class="line">  out-&gt;reset(<span class="keyword">new</span> DeltaApplier(opts, base, <span class="built_in">std</span>::<span class="built_in">move</span>(iter)));</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">DeltaTracker::NewDeltaIterator</span><span class="params">(<span class="keyword">const</span> RowIteratorOptions&amp; opts,</span></span></span><br><span class="line"><span class="function"><span class="params">                                      WhichStores which,</span></span></span><br><span class="line"><span class="function"><span class="params">                                      <span class="built_in">unique_ptr</span>&lt;DeltaIterator&gt;* out)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;DeltaStore&gt;&gt; stores;</span><br><span class="line">  <span class="comment">//收集数据undo redo deltastore的数据</span></span><br><span class="line">  CollectStores(&amp;stores, which);</span><br><span class="line">  <span class="comment">//调用DeltaIteratorMerger初始化</span></span><br><span class="line">  <span class="keyword">return</span> DeltaIteratorMerger::Create(stores, opts, out);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DeltaTracker::CollectStores</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;DeltaStore&gt;&gt;* deltas,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 WhichStores which)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="built_in">std</span>::lock_guard&lt;rw_spinlock&gt; <span class="title">lock</span><span class="params">(component_lock_)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (which != REDOS_ONLY) &#123;</span><br><span class="line">    <span class="comment">//合并undo</span></span><br><span class="line">    deltas-&gt;assign(undo_delta_stores_.<span class="built_in">begin</span>(), undo_delta_stores_.<span class="built_in">end</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (which != UNDOS_ONLY) &#123;</span><br><span class="line">  	<span class="comment">//合并redo和delta</span></span><br><span class="line">    deltas-&gt;insert(deltas-&gt;<span class="built_in">end</span>(), redo_delta_stores_.<span class="built_in">begin</span>(), redo_delta_stores_.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">if</span> (dms_exists_ &amp;&amp; !dms_-&gt;Empty()) &#123;</span><br><span class="line">      deltas-&gt;push_back(dms_);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>base data由CFileSet检索，是ColumnwiseIterator的实现类</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CFileSet</span>:</span>:Iterator : <span class="keyword">public</span> ColumnwiseIterator &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Init</span><span class="params">(ScanSpec *spec)</span> OVERRIDE</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">PrepareBatch</span><span class="params">(<span class="keyword">size_t</span> *nrows)</span> OVERRIDE</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">InitializeSelectionVector</span><span class="params">(SelectionVector *sel_vec)</span> OVERRIDE</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">MaterializeColumn</span><span class="params">(ColumnMaterializationContext *ctx)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="comment">//省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>读取完base data和delta data后，由DeltaApplier合并并返回结果，DeltaApplier是ColumnwiseIterator的实现</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A DeltaApplier takes in a base ColumnwiseIterator along with a</span></span><br><span class="line"><span class="comment">// DeltaIterator. It is responsible for applying the updates coming</span></span><br><span class="line"><span class="comment">// from the delta iterator to the results of the base iterator.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeltaApplier</span> <span class="title">final</span> :</span> <span class="keyword">public</span> ColumnwiseIterator &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function">Status <span class="title">Init</span><span class="params">(ScanSpec* spec)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">PrepareBatch</span><span class="params">(<span class="keyword">size_t</span>* nrows)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="comment">//省略其他</span></span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function">Status <span class="title">DeltaApplier::Init</span><span class="params">(ScanSpec* spec)</span> </span>&#123;</span><br><span class="line">  RETURN_NOT_OK(base_iter_-&gt;Init(spec));</span><br><span class="line">  RETURN_NOT_OK(delta_iter_-&gt;Init(spec));</span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">DeltaApplier::MaterializeColumn</span><span class="params">(ColumnMaterializationContext* ctx)</span> </span>&#123;</span><br><span class="line">  DCHECK(!first_prepare_) &lt;&lt; <span class="string">"PrepareBatch() must be called at least once"</span>;</span><br><span class="line">  <span class="comment">// Data with updates cannot be evaluated at the decoder-level.</span></span><br><span class="line">  <span class="keyword">if</span> (delta_iter_-&gt;MayHaveDeltas()) &#123;</span><br><span class="line">    ctx-&gt;SetDecoderEvalNotSupported();</span><br><span class="line">    RETURN_NOT_OK(base_iter_-&gt;MaterializeColumn(ctx));</span><br><span class="line">    <span class="comment">//应用delta的数据更新</span></span><br><span class="line">    RETURN_NOT_OK(delta_iter_-&gt;ApplyUpdates(ctx-&gt;col_idx(), ctx-&gt;block(), *ctx-&gt;sel()));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    RETURN_NOT_OK(base_iter_-&gt;MaterializeColumn(ctx));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Status::OK();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>













]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
  </entry>
  <entry>
    <title>Presto</title>
    <url>/2023/05/11/3_Presto/</url>
    <content><![CDATA[<blockquote>
<p>Presto是一款开源的高效的查询引擎。目前市面上有两款Presto，一个是Prestodb，由Facebook开源维护。一个是Trino（又名Prestosql），由Starburst公司开源维护。其中Presto的核心创始人之前在Facebook研发，19年后离开Facebook，重新fork分支后开发了trino，所以两款Presto的基础思想都类似，为避免歧义，本文分析的是trino，以下Presto均代表Trino，源码版本为458</p>
</blockquote>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Presto是一个大规模并行处理MPP（Massively parallel processing）的分布式SQL查询引擎。主要使用场景有：联邦查询，即席查询，通过分配处理任务来实现横向扩展提高强大的处理能力，同时也能适应较大数据量的ETL查询。</p>
<p>在BI业务中，如果业务方想要在PB级别数据库中快速提取数据，形成报表，往往有以下几种方式。1. 通过Hive实现数据提取，2. 开发对应的取数程序，按照固定报表格式，形成BI报表，供业务方查询。3. 依赖关系型数据库（如Oracle，PostgreSQL）连表查询。但上述方式，hive取数耗时较久，取数程序报表格式固定不灵活，连表查询分库分表无法实现。这种场景业界也有许多组件选型，例如Impala，kylin，druid，starRocks等。相比之下，我们选择了Presto，能够低延时的满足灵活分析的场景，而且存算分离后，也可以通过横向扩展来应对峰值查询。</p>
<p>本文以查询计划生成为切入点，分享实践中对慢Sql的定位与优化，以此加深对Presto的了解。</p>
<h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><p>Presto架构图如下：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image2.png"
                        alt="image-202206251715403"
                 ></p>
<h2 id="查询计划是什么"><a href="#查询计划是什么" class="headerlink" title="查询计划是什么"></a>查询计划是什么</h2><p>查询计划是一个过程，是由 LogicalPlanner根据Sql语句分析后的结果，生成逻辑执行计划，逻辑执行计划经过各种优化器处理后，最终输出的查询执行计划分段，并交由调度执行器分配到不同的worker执行。</p>
<p>查询计划的直观体现：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fragment 1 [HASH]</span><br><span class="line">    CPU: 2.65ms, Scheduled: 2.81ms, Input: 0 rows (0B); per task: avg.: 0.00 std.dev.: 0.00, Output: 0 rows (0B)</span><br><span class="line">    Output layout: [u_key]</span><br><span class="line">    Output partitioning: SINGLE []</span><br><span class="line">    Stage Execution Strategy: UNGROUPED_EXECUTION</span><br><span class="line">    Project[]</span><br><span class="line">    │   Layout: [u_key:varchar]</span><br><span class="line">    │   Estimates: &#123;rows: ? (?), cpu: ?, memory: ?, network: ?&#125;</span><br><span class="line">    │   CPU: 0.00ns (?%), Scheduled: 0.00ns (0.00%), Output: 0 rows (0B)</span><br><span class="line">    │   Input avg.: 0.00 rows, Input std.dev.: ?%</span><br><span class="line">    └─ Aggregate(FINAL)[u_key][$hashvalue]</span><br><span class="line">       │   Layout: [u_key:varchar, $hashvalue:bigint]</span><br><span class="line">       │   Estimates: &#123;rows: ? (?), cpu: ?, memory: ?, network: ?&#125;</span><br><span class="line">       │   CPU: 0.00ns (?%), Scheduled: 0.00ns (0.00%), Output: 0 rows (0B)</span><br><span class="line">       │   Input avg.: 0.00 rows, Input std.dev.: ?%</span><br><span class="line">       │   Collisions avg.: ? (?% est.), Collisions std.dev.: ?%</span><br><span class="line">       └─ LocalExchange[HASH][$hashvalue] (&quot;u_key&quot;)</span><br><span class="line">          │   Layout: [u_key:varchar, $hashvalue:bigint]</span><br><span class="line">          │   Estimates: &#123;rows: ? (?), cpu: ?, memory: ?, network: ?&#125;</span><br><span class="line">          │   CPU: 0.00ns (?%), Scheduled: 0.00ns (0.00%), Output: 0 rows (0B)</span><br><span class="line">          │   Input avg.: 0.00 rows, Input std.dev.: ?%</span><br><span class="line">          └─ RemoteSource[2]</span><br><span class="line">                 Layout: [u_key:varchar, $hashvalue_4:bigint]</span><br><span class="line">                 CPU: 0.00ns (?%), Scheduled: 0.00ns (0.00%), Output: 0 rows (0B)</span><br><span class="line">                 Input avg.: 0.00 rows, Input std.dev.: ?%</span><br></pre></td></tr></table></figure>



<h2 id="查询计划的生成过程"><a href="#查询计划的生成过程" class="headerlink" title="查询计划的生成过程"></a>查询计划的生成过程</h2><p>查询过程中的核心类图交互关系如下，其中，查询计划生成后，会由SqlQueryExecution进行调度执行</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image4.png"
                        alt="image-2022062517"
                 ></p>
<h3 id="Client端"><a href="#Client端" class="headerlink" title="Client端"></a>Client端</h3><p>jdbc驱动首先通过TrinoDriver初始化一个TrinoConnection连接，该连接通过注册TrinoStatement来实现具体的sql执行，这个操作和常见的数据库连接类似，在TrinoStatemen最终会将查询委托给internalExecute方法。</p>
<p>该方法通过TrinoConnection的startQuery方法（io.trino.jdbc.TrinoConnection#startQuery）创建StatementClientV1对象，这里设置好角色权限，请求uri，超时时间等。同时通过静态方法TrinoResultSet.create，获取返回结果（currentResult字段）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.jdbc.TrinoStatement#internalExecute</span><br><span class="line">final boolean internalExecute(String sql)</span><br><span class="line">            throws SQLException</span><br><span class="line">    &#123;</span><br><span class="line">        ...前置检查...</span><br><span class="line">        </span><br><span class="line">        StatementClient client = null;</span><br><span class="line">        TrinoResultSet resultSet = null;</span><br><span class="line">        try &#123;</span><br><span class="line">        		//执行查询请求</span><br><span class="line">            client = connection().startQuery(sql, getStatementSessionProperties());</span><br><span class="line">            if (client.isFinished()) &#123;</span><br><span class="line">                QueryStatusInfo finalStatusInfo = client.finalStatusInfo();</span><br><span class="line">                if (finalStatusInfo.getError() != null) &#123;</span><br><span class="line">                    throw resultsException(finalStatusInfo);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            executingClient.set(client);</span><br><span class="line">            WarningsManager warningsManager = new WarningsManager();</span><br><span class="line">            currentWarningsManager.set(Optional.of(warningsManager));</span><br><span class="line">            //获取查询结果</span><br><span class="line">            resultSet = TrinoResultSet.create(this, client, maxRows.get(), progressConsumer, warningsManager);</span><br><span class="line"></span><br><span class="line">						...拿到返回的数据，如果是更新，则需处理事务相关变量</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        ...各种catch，清理变量，关闭连接</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>StatementClientV1是一个线程安全的对象，维护着本次查询的任务状态，以及后续查询的交互，当StatementClientV1初始化时方法中执行http请求（&#x2F;v1&#x2F;statement），同时维护了当前查询结果（currentResults），当前查询状态（state）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.client.StatementClientV1#StatementClientV1</span><br><span class="line">public StatementClientV1(OkHttpClient httpClient, ClientSession session, String query, Optional&lt;Set&lt;String&gt;&gt; clientCapabilities)</span><br><span class="line">    &#123;</span><br><span class="line">        ... 前置check，字段赋值</span><br><span class="line"></span><br><span class="line">				//生成请求对象</span><br><span class="line">        Request request = buildQueryRequest(session, query);</span><br><span class="line"></span><br><span class="line">        //执行请求</span><br><span class="line">        JsonResponse&lt;QueryResults&gt; response = JsonResponse.execute(QUERY_RESULTS_CODEC, httpClient, request, OptionalLong.empty());</span><br><span class="line">        if ((response.getStatusCode() != HTTP_OK) || !response.hasValue()) &#123;</span><br><span class="line">            state.compareAndSet(State.RUNNING, State.CLIENT_ERROR);</span><br><span class="line">            throw requestFailedException(&quot;starting query&quot;, request, response);</span><br><span class="line">        &#125;</span><br><span class="line">        //返回结果</span><br><span class="line">        processResponse(response.getHeaders(), response.getValue());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>由StatementClientV1发起第一次请求后，会返回TrinoResultSet，这是ResultSet的子类，内部包含了ResultsPageIterator迭代器（继承自Iterator，迭代器重写了computeNext方法，而该方法会被迭代器（Iterator）的next触发，当从ResultSet获取下一行数据时，会触发该方法获取下一条数据（注意这里为了提高传输效率，并不是一条一条数据返回，而是每一批数据返回，每一批数据大小默认1M），获取数据代码如下如所示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">prestoTemplate.query(query, new ResultSetExtractor&lt;Object&gt;() &#123;</span><br><span class="line"> @Override</span><br><span class="line"> public Object extractData(ResultSet resultSet) throws SQLException, DataAccessException &#123;</span><br><span class="line"> 	// 发起远程请求</span><br><span class="line">   while (resultSet.next()) &#123;</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当resultSet.next调用时，最终会执行到advance方法，该方法使用类似游标的做法，会不断获取下一个游标，如果有，则继续查询（url：&#x2F;v1&#x2F;statement&#x2F;executing），如果没有nextUri，则说明查询结束。这里有一个重试机制，当远程查询失败时，会尝试重试，每次重试会休眠100ms，当超过请求时间时会报错退出重试。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.client.StatementClientV1#advance</span><br><span class="line">public boolean advance()</span><br><span class="line">    &#123;</span><br><span class="line">        if (!isRunning()) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">				//获取下一个游标</span><br><span class="line">        URI nextUri = currentStatusInfo().getNextUri();</span><br><span class="line">        if (nextUri == null) &#123;</span><br><span class="line">        		//查询结束的标识：没有数据了</span><br><span class="line">            state.compareAndSet(State.RUNNING, State.FINISHED);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Request request = prepareRequest(HttpUrl.get(nextUri)).build();</span><br><span class="line">				..参数初始化</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            if (isClientAborted()) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (attempts &gt; 0) &#123;</span><br><span class="line">                ..尝试获取</span><br><span class="line">            &#125;</span><br><span class="line">            attempts++;</span><br><span class="line"></span><br><span class="line">            JsonResponse&lt;QueryResults&gt; response;</span><br><span class="line">            try &#123;</span><br><span class="line">            		//执行下一个游标的查询</span><br><span class="line">                response = JsonResponse.execute(QUERY_RESULTS_CODEC, httpClient, request, OptionalLong.of(MAX_MATERIALIZED_JSON_RESPONSE_SIZE));</span><br><span class="line">            &#125;</span><br><span class="line">            catch (RuntimeException e) &#123;</span><br><span class="line">                cause = e;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if ((response.getStatusCode() == HTTP_OK) &amp;&amp; response.hasValue()) &#123;</span><br><span class="line">             		//查询结束的标识：查到数据了</span><br><span class="line">                processResponse(response.getHeaders(), response.getValue());</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (!shouldRetry(response.getStatusCode())) &#123;</span><br><span class="line">                state.compareAndSet(State.RUNNING, State.CLIENT_ERROR);</span><br><span class="line">                throw requestFailedException(&quot;fetching next&quot;, request, response);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h3 id="Server端"><a href="#Server端" class="headerlink" title="Server端"></a>Server端</h3><h4 id="与客户端数据交互"><a href="#与客户端数据交互" class="headerlink" title="与客户端数据交互"></a>与客户端数据交互</h4><p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image10.png"
                        alt="image-2022062517"
                 ></p>
<ul>
<li>主要逻辑</li>
</ul>
<ol>
<li>通过&#x2F;v1&#x2F;statement接口，注册查询请求。由io.trino.dispatcher.QueuedStatementResource#postStatement具体实现。主要生成queryId。</li>
<li>通过&#x2F;v1&#x2F;statement&#x2F;queued&#x2F;{queryId}&#x2F;{slug}&#x2F;{token}。发起查询请求，由io.trino.dispatcher.DispatchManager具体实现。主要调用createQuery，生成查询执行计划，并执行。</li>
<li>通过&#x2F;v1&#x2F;statement&#x2F;executing&#x2F;{queryId}&#x2F;{slug}&#x2F;{token}。获取查询结果，由io.trino.server.protocol.Query具体实现。主要从ExchangeDataSource获取结果，ExchangeDataSource内部会由QueryStateMachine将执行结果通过钩子方法addInput写入缓冲区，多次循环获取到所需结果。</li>
</ol>
<ul>
<li>主要类</li>
</ul>
<p>QueuedStatementResource</p>
<p>Web接口的控制类，负责接收jdbc客户端发起查询请求，并触发DispatchManager创建查询。</p>
<p>ExecutingStatementResource</p>
<p>Web接口的控制类，负责接收jdbc客户端获取查询结果，接收QueryStateMachine填充的查询结果，返回客户端。</p>
<h4 id="语法解析及发起查询"><a href="#语法解析及发起查询" class="headerlink" title="语法解析及发起查询"></a>语法解析及发起查询</h4><p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image11.png"
                        alt="image-2022062517"
                 ></p>
<ul>
<li>主要逻辑</li>
</ul>
<ol>
<li>核心方法是DispatchManager的createQueryInternal</li>
</ol>
<p>堆栈路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.QueuedStatementResource#getStatus(io.trino.dispatcher.QueuedStatementResource.Query, long, io.airlift.units.Duration, javax.ws.rs.core.UriInfo)</span><br><span class="line">io.trino.dispatcher.QueuedStatementResource.Query#waitForDispatched</span><br><span class="line">io.trino.dispatcher.QueuedStatementResource.Query#submitIfNeeded</span><br><span class="line">io.trino.dispatcher.DispatchManager#createQuery</span><br><span class="line">io.trino.dispatcher.DispatchManager#createQueryInternal</span><br></pre></td></tr></table></figure>

<p>核心方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.DispatchManager#createQueryInternal</span><br><span class="line">private &lt;C&gt; void createQueryInternal(QueryId queryId, Slug slug, SessionContext sessionContext, String query, ResourceGroupManager&lt;C&gt; resourceGroupManager)</span><br><span class="line">    &#123;</span><br><span class="line">        Session session = null;</span><br><span class="line">        PreparedQuery preparedQuery = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (query.length() &gt; maxQueryLength) &#123;</span><br><span class="line">                int queryLength = query.length();</span><br><span class="line">                query = query.substring(0, maxQueryLength);</span><br><span class="line">                throw new TrinoException(QUERY_TEXT_TOO_LARGE, format(&quot;Query text length (%s) exceeds the maximum length (%s)&quot;, queryLength, maxQueryLength));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            //通过安全认证的方式获取session</span><br><span class="line">            // decode session</span><br><span class="line">            session = sessionSupplier.createSession(queryId, sessionContext);</span><br><span class="line"></span><br><span class="line">            //校验一下配置，是否有执行权限</span><br><span class="line">            // check query execute permissions</span><br><span class="line">            accessControl.checkCanExecuteQuery(sessionContext.getIdentity());</span><br><span class="line"></span><br><span class="line">            //sql解析</span><br><span class="line">            // prepare query</span><br><span class="line">            preparedQuery = queryPreparer.prepareQuery(session, query);</span><br><span class="line"></span><br><span class="line">						//选择资源组</span><br><span class="line">            // select resource group</span><br><span class="line">            Optional&lt;String&gt; queryType = getQueryType(preparedQuery.getStatement()).map(Enum::name);</span><br><span class="line">            SelectionContext&lt;C&gt; selectionContext = resourceGroupManager.selectGroup(new SelectionCriteria(</span><br><span class="line">                    sessionContext.getIdentity().getPrincipal().isPresent(),</span><br><span class="line">                    sessionContext.getIdentity().getUser(),</span><br><span class="line">                    sessionContext.getIdentity().getGroups(),</span><br><span class="line">                    sessionContext.getSource(),</span><br><span class="line">                    sessionContext.getClientTags(),</span><br><span class="line">                    sessionContext.getResourceEstimates(),</span><br><span class="line">                    queryType));</span><br><span class="line"></span><br><span class="line">            // apply system default session properties (does not override user set properties)</span><br><span class="line">            session = sessionPropertyDefaults.newSessionWithDefaultProperties(session, queryType, selectionContext.getResourceGroupId());</span><br><span class="line"></span><br><span class="line">						//分配查询</span><br><span class="line">            DispatchQuery dispatchQuery = dispatchQueryFactory.createDispatchQuery(</span><br><span class="line">                    session,</span><br><span class="line">                    sessionContext.getTransactionId(),</span><br><span class="line">                    query,</span><br><span class="line">                    preparedQuery,</span><br><span class="line">                    slug,</span><br><span class="line">                    selectionContext.getResourceGroupId());</span><br><span class="line"></span><br><span class="line">            boolean queryAdded = queryCreated(dispatchQuery);</span><br><span class="line">            if (queryAdded &amp;&amp; !dispatchQuery.isDone()) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    resourceGroupManager.submit(dispatchQuery, selectionContext, dispatchExecutor);</span><br><span class="line">                &#125;</span><br><span class="line">                catch (Throwable e) &#123;</span><br><span class="line">                    // dispatch query has already been registered, so just fail it directly</span><br><span class="line">                    dispatchQuery.fail(e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        catch (Throwable throwable) &#123;</span><br><span class="line">            // creation must never fail, so register a failed query in this case</span><br><span class="line">            if (session == null) &#123;</span><br><span class="line">                session = Session.builder(sessionPropertyManager)</span><br><span class="line">                        .setQueryId(queryId)</span><br><span class="line">                        .setIdentity(sessionContext.getIdentity())</span><br><span class="line">                        .setSource(sessionContext.getSource().orElse(null))</span><br><span class="line">                        .build();</span><br><span class="line">            &#125;</span><br><span class="line">            Optional&lt;String&gt; preparedSql = Optional.ofNullable(preparedQuery).flatMap(PreparedQuery::getPrepareSql);</span><br><span class="line">            DispatchQuery failedDispatchQuery = failedDispatchQueryFactory.createFailedDispatchQuery(session, query, preparedSql, Optional.empty(), throwable);</span><br><span class="line">            queryCreated(failedDispatchQuery);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>QueryPreparer委托SqlParser（createQueryInternal核心逻辑之一），进入到invokeParser，该方法对sql进行语法解析，通过visit模式，构建Ast语法树，Ast根据Sql解析出Query对象，封装为PreparedQuery。</li>
</ol>
<p>堆栈路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.DispatchManager#createQueryInternal</span><br><span class="line">io.trino.execution.QueryPreparer#prepareQuery (io.trino.Session, java.lang.String)</span><br><span class="line">io.trino.sql.parser.SqlParser#createStatement</span><br><span class="line">io.trino.sql.parser.SqlParser#invokeParser</span><br></pre></td></tr></table></figure>

<p>核心方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private Node invokeParser(String name, String sql, Function&lt;SqlBaseParser, ParserRuleContext&gt; parseFunction, ParsingOptions parsingOptions)</span><br><span class="line">    &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">        		//通过antlr生成的词法解析</span><br><span class="line">            SqlBaseLexer lexer = new SqlBaseLexer(new CaseInsensitiveStream(CharStreams.fromString(sql)));</span><br><span class="line">            CommonTokenStream tokenStream = new CommonTokenStream(lexer);</span><br><span class="line">            SqlBaseParser parser = new SqlBaseParser(tokenStream);</span><br><span class="line">            initializer.accept(lexer, parser);</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line">            ...省略词法解析的异常监听</span><br><span class="line"></span><br><span class="line">            ParserRuleContext tree;</span><br><span class="line">            try &#123;</span><br><span class="line">                // first, try parsing with potentially faster SLL mode</span><br><span class="line">                parser.getInterpreter().setPredictionMode(PredictionMode.SLL);</span><br><span class="line">                tree = parseFunction.apply(parser);</span><br><span class="line">            &#125;</span><br><span class="line">            catch (ParseCancellationException ex) &#123;</span><br><span class="line">                // if we fail, parse with LL mode</span><br><span class="line">                tokenStream.seek(0); // rewind input stream</span><br><span class="line">                parser.reset();</span><br><span class="line"></span><br><span class="line">                parser.getInterpreter().setPredictionMode(PredictionMode.LL);</span><br><span class="line">                tree = parseFunction.apply(parser);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">						//解析生成Node</span><br><span class="line">            return new AstBuilder(parsingOptions).visit(tree);</span><br><span class="line">        &#125;</span><br><span class="line">        catch (StackOverflowError e) &#123;</span><br><span class="line">            throw new ParsingException(name + &quot; is too large (stack overflow while parsing)&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>DispatchQueryFactory分配查询（createQueryInternal核心逻辑之一），主要有2个核心逻辑，a) 注册SqlQueryExecution构造方法，b) 构造LocalDispatchQuery，并注册钩子方法SqlQueryManager::createQuery。</li>
</ol>
<p>堆栈路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.DispatchManager#createQueryInternal</span><br><span class="line">io.trino.dispatcher.DispatchQueryFactory#createDispatchQuery</span><br><span class="line">io.trino.dispatcher.LocalDispatchQuery</span><br></pre></td></tr></table></figure>

<p>核心方法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.LocalDispatchQueryFactory#createDispatchQuery</span><br><span class="line">public DispatchQuery createDispatchQuery(</span><br><span class="line">            Session session,</span><br><span class="line">            Optional&lt;TransactionId&gt; existingTransactionId,</span><br><span class="line">            String query,</span><br><span class="line">            PreparedQuery preparedQuery,</span><br><span class="line">            Slug slug,</span><br><span class="line">            ResourceGroupId resourceGroup)</span><br><span class="line">    &#123;</span><br><span class="line">        // 启动 查询状态机</span><br><span class="line">        WarningCollector warningCollector = warningCollectorFactory.create();</span><br><span class="line">        PlanOptimizersStatsCollector planOptimizersStatsCollector = new PlanOptimizersStatsCollector(queryReportedRuleStatsLimit);</span><br><span class="line">        QueryStateMachine stateMachine = QueryStateMachine.begin(</span><br><span class="line">                existingTransactionId,</span><br><span class="line">                query,</span><br><span class="line">                preparedQuery.getPrepareSql(),</span><br><span class="line">                session,</span><br><span class="line">                locationFactory.createQueryLocation(session.getQueryId()),</span><br><span class="line">                resourceGroup,</span><br><span class="line">                isTransactionControlStatement(preparedQuery.getStatement()),</span><br><span class="line">                transactionManager,</span><br><span class="line">                accessControl,</span><br><span class="line">                // limit the number of state change listener callback threads for each query</span><br><span class="line">                new BoundedExecutor(executor, maxStateMachineThreadsPerQuery),</span><br><span class="line">                metadata,</span><br><span class="line">                warningCollector,</span><br><span class="line">                planOptimizersStatsCollector,</span><br><span class="line">                getQueryType(preparedQuery.getStatement()),</span><br><span class="line">                faultTolerantExecutionExchangeEncryptionEnabled,</span><br><span class="line">                version);</span><br><span class="line"></span><br><span class="line">				// 监控</span><br><span class="line">        queryMonitor.queryCreatedEvent(stateMachine.getBasicQueryInfo(Optional.empty()));</span><br><span class="line"></span><br><span class="line">				// 注册SqlQueryExecution工厂类</span><br><span class="line">        ListenableFuture&lt;QueryExecution&gt; queryExecutionFuture = executor.submit(() -&gt; &#123;</span><br><span class="line">            // 省略</span><br><span class="line"></span><br><span class="line">            try &#123;</span><br><span class="line">                return queryExecutionFactory.createQueryExecution(preparedQuery, stateMachine, slug, warningCollector, planOptimizersStatsCollector);</span><br><span class="line">            &#125;</span><br><span class="line">            catch (Throwable e) &#123; </span><br><span class="line">            	// 省略异常处理</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">				// 注册 createQuery钩子方法</span><br><span class="line">        return new LocalDispatchQuery(</span><br><span class="line">                stateMachine,</span><br><span class="line">                queryExecutionFuture,</span><br><span class="line">                queryMonitor,</span><br><span class="line">                clusterSizeMonitor,</span><br><span class="line">                executor,</span><br><span class="line">                queryManager::createQuery);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>DispatchQueryFactory分配查询（createQueryInternal核心逻辑之一），经过一系列回调，触发钩子函数SqlQueryManager::createQuery，最终由SqlQueryExecute.start()开启调度执行。</li>
</ol>
<p>堆栈路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.DispatchManager#createQueryInternal</span><br><span class="line">io.trino.execution.resourcegroups.ResourceGroupManager#submit</span><br><span class="line">io.trino.execution.resourcegroups.InternalResourceGroup#run</span><br><span class="line">io.trino.execution.resourcegroups.InternalResourceGroup#startInBackground</span><br><span class="line">io.trino.dispatcher.LocalDispatchQuery#startWaitingForResources</span><br><span class="line">io.trino.dispatcher.LocalDispatchQuery#waitForMinimumWorkers</span><br><span class="line">io.trino.dispatcher.LocalDispatchQuery#startExecution</span><br></pre></td></tr></table></figure>

<p>核心方法 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.dispatcher.LocalDispatchQuery#startExecution</span><br><span class="line">private void startExecution(QueryExecution queryExecution)</span><br><span class="line">    &#123;</span><br><span class="line">        if (stateMachine.transitionToDispatching()) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">            		// 调用前面注册的钩子函数</span><br><span class="line">                querySubmitter.accept(queryExecution);</span><br><span class="line">                if (notificationSentOrGuaranteed.compareAndSet(false, true)) &#123;</span><br><span class="line">                    queryExecution.addFinalQueryInfoListener(queryMonitor::queryCompletedEvent);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            catch (Throwable t) &#123;</span><br><span class="line">            		//省略异常处理</span><br><span class="line">            &#125;</span><br><span class="line">            finally &#123;</span><br><span class="line">                submitted.set(null);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>钩子函数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.execution.SqlQueryManager#createQuery</span><br><span class="line">public void createQuery(QueryExecution queryExecution)</span><br><span class="line">    &#123;</span><br><span class="line">        // 省略校验，以及queryTracker执行日志的过期处理</span><br><span class="line"></span><br><span class="line">        try (SetThreadName _ = new SetThreadName(&quot;Query-%s&quot;, queryExecution.getQueryId())) &#123;</span><br><span class="line">            try (var ignoredStartScope = scopedSpan(tracer.spanBuilder(&quot;query-start&quot;)</span><br><span class="line">                    .setParent(Context.current().with(queryExecution.getSession().getQuerySpan()))</span><br><span class="line">                    .startSpan())) &#123;</span><br><span class="line">                // 执行查询</span><br><span class="line">                queryExecution.start();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>开始调度</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.execution.SqlQueryExecution#start</span><br><span class="line">public void start()</span><br><span class="line">    &#123; </span><br><span class="line">    	//省略具体执行</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>主要类</li>
</ul>
<p>DispatchManager</p>
<h4 id="生成逻辑执行计划"><a href="#生成逻辑执行计划" class="headerlink" title="生成逻辑执行计划"></a>生成逻辑执行计划</h4><p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image12.png"
                        alt="image-2022062517"
                 ></p>
<ul>
<li>主要逻辑</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.execution.SqlQueryExecution#start</span><br><span class="line">public void start()</span><br><span class="line">    &#123;</span><br><span class="line">        try (SetThreadName _ = new SetThreadName(&quot;Query-%s&quot;, stateMachine.getQueryId())) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">            		// 执行状态变更：  -&gt; planning</span><br><span class="line">                if (!stateMachine.transitionToPlanning()) &#123;</span><br><span class="line">                    // query already started or finished</span><br><span class="line">                    return;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">								// 省略注册执行引擎状态变更监听</span><br><span class="line"></span><br><span class="line">                try &#123;</span><br><span class="line">                    // 1 构造逻辑执行计划</span><br><span class="line">                    CachingTableStatsProvider tableStatsProvider = new CachingTableStatsProvider(plannerContext.getMetadata(), getSession());</span><br><span class="line">                    PlanRoot plan = planQuery(tableStatsProvider);</span><br><span class="line">                    </span><br><span class="line">                    // 省略加速特性-动态过滤</span><br><span class="line">                    </span><br><span class="line">                    // 2 执行计划分配</span><br><span class="line">                    planDistribution(plan, tableStatsProvider);</span><br><span class="line">                &#125;</span><br><span class="line">                finally &#123;</span><br><span class="line">                    synchronized (planningThread) &#123;</span><br><span class="line">                        planningThread.set(null);</span><br><span class="line">                        // Clear the interrupted flag in case there was a race condition where</span><br><span class="line">                        // the planning thread was interrupted right after planning completes above</span><br><span class="line">                        Thread.interrupted();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                tableExecuteContextManager.registerTableExecuteContextForQuery(getQueryId());</span><br><span class="line"></span><br><span class="line">								// 执行状态变更： ? -&gt; planning ，?大概率是planning</span><br><span class="line">                if (!stateMachine.transitionToStarting()) &#123;</span><br><span class="line">                    // query already started or finished</span><br><span class="line">                    return;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                // if query is not finished, start the scheduler, otherwise cancel it</span><br><span class="line">                QueryScheduler scheduler = queryScheduler.get();</span><br><span class="line"></span><br><span class="line">								// 执行状态判断：finished or faild</span><br><span class="line">                if (!stateMachine.isDone()) &#123;</span><br><span class="line">                    // 3. 开始执行</span><br><span class="line">                    scheduler.start();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            catch (Throwable e) &#123;</span><br><span class="line">                fail(e);</span><br><span class="line">                throwIfInstanceOf(e, Error.class);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>构造逻辑执行计划：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.execution.SqlQueryExecution#doPlanQuery</span><br><span class="line">private PlanRoot doPlanQuery(CachingTableStatsProvider tableStatsProvider)</span><br><span class="line">    &#123;</span><br><span class="line">        // 省略logicalPlanner构造函数</span><br><span class="line">        </span><br><span class="line">        // 1 逻辑执行计划解析，验证，收集cost和表信息</span><br><span class="line">        Plan plan = logicalPlanner.plan(analysis);</span><br><span class="line">        queryPlan.set(plan);</span><br><span class="line">	</span><br><span class="line">        // 2. 逻辑查询计划分片</span><br><span class="line">        SubPlan fragmentedPlan;</span><br><span class="line">        try (var _ = scopedSpan(tracer, &quot;fragment-plan&quot;)) &#123;</span><br><span class="line">            fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, stateMachine.getWarningCollector());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 3. 提取input和output，包装执行计划树PlanRoot</span><br><span class="line">        try (var _ = scopedSpan(tracer, &quot;extract-inputs&quot;)) &#123;</span><br><span class="line">            stateMachine.setInputs(new InputExtractor(plannerContext.getMetadata(), stateMachine.getSession()).extractInputs(fragmentedPlan));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        stateMachine.setOutput(analysis.getTarget());</span><br><span class="line"></span><br><span class="line">        boolean explainAnalyze = analysis.getStatement() instanceof ExplainAnalyze;</span><br><span class="line">        return new PlanRoot(fragmentedPlan, !explainAnalyze);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>执行计划分配：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.execution.SqlQueryExecution#planDistribution</span><br><span class="line">private void planDistribution(PlanRoot plan, CachingTableStatsProvider tableStatsProvider)</span><br><span class="line">    &#123;</span><br><span class="line">        // if query was canceled, skip creating scheduler</span><br><span class="line">        if (stateMachine.isDone()) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // 获取逻辑查询计划分片</span><br><span class="line">        PlanFragment rootFragment = plan.getRoot().getFragment();</span><br><span class="line">        stateMachine.setColumns(</span><br><span class="line">                ((OutputNode) rootFragment.getRoot()).getColumnNames(),</span><br><span class="line">                rootFragment.getTypes());</span><br><span class="line"></span><br><span class="line">				// 构造查询调度，存入queryScheduler</span><br><span class="line">        RetryPolicy retryPolicy = getRetryPolicy(getSession());</span><br><span class="line">        QueryScheduler scheduler = switch (retryPolicy) &#123;</span><br><span class="line">            case QUERY, NONE -&gt; new PipelinedQueryScheduler(</span><br><span class="line">                    stateMachine,</span><br><span class="line">                    plan.getRoot(),</span><br><span class="line">                    nodePartitioningManager,</span><br><span class="line">                    nodeScheduler,</span><br><span class="line">                    remoteTaskFactory,</span><br><span class="line">                    plan.isSummarizeTaskInfos(),</span><br><span class="line">                    scheduleSplitBatchSize,</span><br><span class="line">                    queryExecutor,</span><br><span class="line">                    schedulerExecutor,</span><br><span class="line">                    failureDetector,</span><br><span class="line">                    nodeTaskMap,</span><br><span class="line">                    executionPolicy,</span><br><span class="line">                    tracer,</span><br><span class="line">                    schedulerStats,</span><br><span class="line">                    dynamicFilterService,</span><br><span class="line">                    tableExecuteContextManager,</span><br><span class="line">                    plannerContext.getMetadata(),</span><br><span class="line">                    splitSourceFactory,</span><br><span class="line">                    coordinatorTaskManager);</span><br><span class="line">            case TASK -&gt; new EventDrivenFaultTolerantQueryScheduler(</span><br><span class="line">                    stateMachine,</span><br><span class="line">                    plannerContext.getMetadata(),</span><br><span class="line">                    remoteTaskFactory,</span><br><span class="line">                    taskDescriptorStorage,</span><br><span class="line">                    eventDrivenTaskSourceFactory,</span><br><span class="line">                    plan.isSummarizeTaskInfos(),</span><br><span class="line">                    nodeTaskMap,</span><br><span class="line">                    queryExecutor,</span><br><span class="line">                    schedulerExecutor,</span><br><span class="line">                    tracer,</span><br><span class="line">                    schedulerStats,</span><br><span class="line">                    partitionMemoryEstimatorFactory,</span><br><span class="line">                    outputStatsEstimatorFactory,</span><br><span class="line">                    nodePartitioningManager,</span><br><span class="line">                    exchangeManagerRegistry.getExchangeManager(),</span><br><span class="line">                    nodeAllocatorService,</span><br><span class="line">                    failureDetector,</span><br><span class="line">                    dynamicFilterService,</span><br><span class="line">                    taskExecutionStats,</span><br><span class="line">                    new AdaptivePlanner(</span><br><span class="line">                            stateMachine.getSession(),</span><br><span class="line">                            plannerContext,</span><br><span class="line">                            adaptivePlanOptimizers,</span><br><span class="line">                            planFragmenter,</span><br><span class="line">                            DISTRIBUTED_PLAN_SANITY_CHECKER,</span><br><span class="line">                            stateMachine.getWarningCollector(),</span><br><span class="line">                            planOptimizersStatsCollector,</span><br><span class="line">                            tableStatsProvider),</span><br><span class="line">                    stageExecutionStats,</span><br><span class="line">                    plan.getRoot());</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        queryScheduler.set(scheduler);</span><br><span class="line">        stateMachine.addQueryInfoStateChangeListener(queryInfo -&gt; &#123;</span><br><span class="line">            if (queryInfo.isFinalQueryInfo()) &#123;</span><br><span class="line">                queryScheduler.set(null);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>Sql解析成PlanNode</p>
<p>主要通过RelationPlanner继承AstVisitor，使用Visit模式，通过RelationPlanner的visitQuery，visitQuerySpecification等构造RelationPlan。</p>
<p>抽象元素：Node</p>
<p>具体元素是主要有：Query，QuerySpecification</p>
<p>抽象访问者：AstVisitor</p>
<p>具体访问者：RelationPlanner</p>
<p>存储元素结构：RelationPlan</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.sql.planner.QueryPlanner#plan(io.trino.sql.tree.Query)</span><br><span class="line">io.trino.sql.planner.QueryPlanner#plan(io.trino.sql.tree.QuerySpecification)</span><br><span class="line">public RelationPlan plan(QuerySpecification node)</span><br><span class="line">    &#123;</span><br><span class="line">        PlanBuilder builder = planFrom(node);</span><br><span class="line"></span><br><span class="line">        builder = filter(builder, analysis.getWhere(node), node);</span><br><span class="line">        builder = aggregate(builder, node);</span><br><span class="line">        builder = filter(builder, analysis.getHaving(node), node);</span><br><span class="line">        builder = planWindowFunctions(node, builder, ImmutableList.copyOf(analysis.getWindowFunctions(node)));</span><br><span class="line">        builder = planWindowMeasures(node, builder, ImmutableList.copyOf(analysis.getWindowMeasures(node)));</span><br><span class="line">        </span><br><span class="line">        ..省略</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>通过PlanOptimizer优化PlanNode，使用Visit模式，优化PlanNode</p>
<p>抽象元素：PlanNode</p>
<p>具体元素是主要有：ProjectNode，JoinNode等</p>
<p>抽象访问者：PlanVisitor</p>
<p>具体访问者：IterativeOptimizer，PredicatePushDown等内部类Rewriter</p>
<p>存储元素结构：LogicalPlanner</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.sql.planner.LogicalPlanner#runOptimizer</span><br><span class="line">private PlanNode runOptimizer(PlanNode root, TableStatsProvider tableStatsProvider, PlanOptimizer optimizer)</span><br><span class="line">    &#123;</span><br><span class="line">        PlanNode result;</span><br><span class="line">        try (var _ = optimizerSpan(optimizer)) &#123;</span><br><span class="line">            //具体优化</span><br><span class="line">            result = optimizer.optimize(root, new PlanOptimizer.Context(session, symbolAllocator, idAllocator, warningCollector, planOptimizersStatsCollector, tableStatsProvider, RuntimeInfoProvider.noImplementation()));</span><br><span class="line">        &#125;</span><br><span class="line">        //打印日志</span><br><span class="line"></span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>相对重要的优化策略</p>
<p>AddExchanges</p>
<p>委托在StatsRecordingPlanOptimizer优化器中进行优化。优化的策略如下：</p>
<p>对于AggregationNode，将其拆分成局部聚合和最终聚合(Final、partial、single)，在两个聚合之间增加ExchangeNode</p>
<p>对于三种类型的Join，根据数据表特性会出现（有group by字段时增加一个ExchangeNode，无左右分别增加ExchangeNode）</p>
<p>对于窗口函数下增加ExchangeNode</p>
<p>对于count-distinct对增加ExchangeNode</p>
<p>分片逻辑执行计划</p>
<p>SubPlan，单个分片的执行计划。</p>
<p>Fragment：维护单个分片的相关信息，如分区描述信息，分居数据表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public SubPlan createSubPlans(</span><br><span class="line">            Session session,</span><br><span class="line">            Plan plan,</span><br><span class="line">            boolean forceSingleNode,</span><br><span class="line">            WarningCollector warningCollector,</span><br><span class="line">            PlanFragmentIdAllocator idAllocator,</span><br><span class="line">            PartitioningScheme outputPartitioningScheme,</span><br><span class="line">            Map&lt;ExchangeSourceId, SubPlan&gt; unchangedSubPlans)</span><br><span class="line">    &#123;</span><br><span class="line">        // 准备分片器</span><br><span class="line">        Fragmenter fragmenter = new Fragmenter(</span><br><span class="line">                session,</span><br><span class="line">                metadata,</span><br><span class="line">                functionManager,</span><br><span class="line">                plan.getStatsAndCosts(),</span><br><span class="line">                activeCatalogs,</span><br><span class="line">                languageScalarFunctions,</span><br><span class="line">                idAllocator,</span><br><span class="line">                unchangedSubPlans);</span><br><span class="line">        FragmentProperties properties = new FragmentProperties(outputPartitioningScheme);</span><br><span class="line">        if (forceSingleNode || isForceSingleNodeOutput(session)) &#123;</span><br><span class="line">            properties = properties.setSingleNodeDistribution();</span><br><span class="line">        &#125;</span><br><span class="line">        PlanNode root = SimplePlanRewriter.rewriteWith(fragmenter, plan.getRoot(), properties);</span><br><span class="line"></span><br><span class="line">        // 构造子执行计划</span><br><span class="line">        SubPlan subPlan = fragmenter.buildRootFragment(root, properties);</span><br><span class="line">        subPlan = reassignPartitioningHandleIfNecessary(session, subPlan);</span><br><span class="line"></span><br><span class="line">        // 省略后置校验</span><br><span class="line">        </span><br><span class="line">        return subPlan;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<ul>
<li>主要类</li>
</ul>
<h4 id="分布式执行"><a href="#分布式执行" class="headerlink" title="分布式执行"></a>分布式执行</h4><blockquote>
<p>以Query，None重试策略为例，默认为None</p>
</blockquote>
<p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image13.png"
                        alt="image-2022062517"
                 ></p>
<ul>
<li>核心逻辑</li>
</ul>
<p>将SubPlan执行计划，构造成不同的阶段调度，异步执行调度并返回调度结果。</p>
<ul>
<li>核心类</li>
</ul>
<p>QueryStateMachine，查询状态引擎，主要维护回调事件，查询进度状态。</p>
<p>SqlQueryExecution，构造Pipelined查询调度器，串联构造相应的Scheduler，StageExecution，并异步执行调度。</p>
<p>PipelinedQueryScheduler（实现QueryScheduler），具体的调度实现，内部构造StageManager，CoordinatorStagesScheduler（协调者调度），接收SqlQueryExecution的start指令后，协调者schedule调度开始，同时分布式调度委托给DistributedStagesScheduler，负责schedule调度。当DistributedStagesScheduler构造完成后，调用StageScheduler的start开始调度，schedule尝试执行调度并返回ScheduleResult（有的调度在start已经异步执行，schedule阶段可能能返回结果），循环schedule阶段，直到所有阶段均获取到数据。</p>
<p>StageManager，阶段管理，由PipelinedQueryScheduler构建。将SubPlan转换成SqlStage，便于后续执行。</p>
<p>DistributedStagesScheduler，PipelinedQueryScheduler的内部类，具体完成分阶段的分布式查询。在构造期间，1） 会根据SqlStage构造StageExecution（如PipelinedStageExecution，实现StageExecution接口）；2）紧接着构造StageScheduler，根据split切割情况，参数配置等，初始化FixedSourcePartitionedScheduler、MultiSourcePartitionedScheduler（实现StageScheduler接口）；3）进行初始化initialize，注册回调。</p>
<h4 id="调度及结果回写"><a href="#调度及结果回写" class="headerlink" title="调度及结果回写"></a>调度及结果回写</h4><ul>
<li>主要逻辑</li>
</ul>
<p>拉取数据方</p>
<ol>
<li>在Query类的create方法中，给SqlQueryManager注册OutputInfoListener，把ExchangeDataSource.addInput方法传入，作为数据写入的回调方法</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.server.protocol.Query#create</span><br><span class="line">result.queryManager.setOutputInfoListener(result.getQueryId(), result::setQueryOutputInfo)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>ExecutingStatementResource接收到http查询数据请求后，异步调用protocol.Query的waitForResults方法，等待数据填充；</p>
</li>
<li><p>protocol.query::waitForResults中，注册stateChange事件，并等待一定时间；stateChange事件内部是等待exchangeDataSource状态完成；</p>
</li>
<li><p>当stateChange触发时，调用钩子函数getNextResult，在getNextResult中，SqlQueryManager的getResultQueryInfo方法获取查询结。1) 如果ResultQueryInfo状态为Start时，会尝试调用exchangeDataSource.pollPage获取数据。2）如果ResultQueryInfo状态没有完成或构造完成，且状态正常，返回数据不为空，则构造nextUri及token、http返回数据，等待下次请求尝试获取后续数据。</p>
</li>
</ol>
<p>提供数据方</p>
<ol>
<li>QueryStateMachine调用begin后，经过分布式执行，这里分为2类TaskLifecycleListener，分阶段构造，先初始化CoordinatorStagesScheduler，1）CoordinatorStagesScheduler构造的QueryOutputTaskLifecycleListener，2）PipelinedStageStateMachine的匿名内部类。</li>
<li>PipelinedStageExecution陆续调用scheduleTask调度方法，在scheduleTask方法中，会调用RemoteTask的start方法，开启请求后，会注册线程池，异步等待结果。等待上游数据提供好后，将请求uri通过http写入状态，并更新exchangeDataSource。主要调度方法参考下列注释</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.trino.execution.scheduler.PipelinedStageExecution#scheduleTask</span><br><span class="line">public synchronized Optional&lt;RemoteTask&gt; scheduleTask(</span><br><span class="line">            InternalNode node,</span><br><span class="line">            int partition,</span><br><span class="line">            Multimap&lt;PlanNodeId, Split&gt; initialSplits)</span><br><span class="line">    &#123;</span><br><span class="line">    		// 省略前置校验</span><br><span class="line">    		</span><br><span class="line">				// 准备缓冲区数据</span><br><span class="line">        OutputBuffers outputBuffers = outputBufferManagers.get(stage.getFragment().getId()).getOutputBuffers();</span><br><span class="line"></span><br><span class="line">        Optional&lt;RemoteTask&gt; optionalTask = stage.createTask(</span><br><span class="line">                node,</span><br><span class="line">                partition,</span><br><span class="line">                attempt,</span><br><span class="line">                bucketToPartition,</span><br><span class="line">                outputBuffers,</span><br><span class="line">                initialSplits,</span><br><span class="line">                ImmutableSet.of(),</span><br><span class="line">                Optional.empty(),</span><br><span class="line">                false);</span><br><span class="line"></span><br><span class="line">        if (optionalTask.isEmpty()) &#123;</span><br><span class="line">            return Optional.empty();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        RemoteTask task = optionalTask.get();</span><br><span class="line"> 				</span><br><span class="line"> 				//省略一些准备工作</span><br><span class="line"></span><br><span class="line">				// 分配下游分片，这里会尝试触发更新协调者协调者缓冲区数据</span><br><span class="line">        task.addSplits(exchangeSplits.build());</span><br><span class="line">        completeSources.forEach(task::noMoreSplits);</span><br><span class="line"></span><br><span class="line">				// 注册一些钩子函数</span><br><span class="line">        task.addStateChangeListener(this::updateTaskStatus);</span><br><span class="line"></span><br><span class="line">				// 正式开始调度，包括写入协调者缓冲区数据，获取任务状态</span><br><span class="line">        task.start();</span><br><span class="line"></span><br><span class="line">				// 调用exchangeDataSource.pollPage钩子函数，将请求地址push到队列，拉取数据方获取到请求地址后，调用Get请求/v1/task/&#123;taskId&#125;/result，获取缓冲区数据</span><br><span class="line">        taskLifecycleListener.taskCreated(stage.getFragment().getId(), task);</span><br><span class="line"></span><br><span class="line">        // 更新上游缓冲区（提供数据的为上游，典型的上游为TableScan）</span><br><span class="line">        OutputBufferId outputBufferId = new OutputBufferId(task.getTaskId().getPartitionId());</span><br><span class="line">        updateSourceTasksOutputBuffers(outputBufferManager -&gt; outputBufferManager.addOutputBuffer(outputBufferId));</span><br><span class="line"></span><br><span class="line">        return Optional.of(task);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>主要类</li>
</ul>
<p>io.trino.dispatcher.LocalDispatchQueryFactory#createDispatchQuery<br>io.trino.execution.SqlQueryExecution.SqlQueryExecutionFactory#createQueryExecution<br>io.trino.execution.SqlQueryManager#createQuery<br>io.trino.execution.SqlQueryExecution#start</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><h3 id="Visit模式"><a href="#Visit模式" class="headerlink" title="Visit模式"></a>Visit模式</h3><h3 id="异步回调"><a href="#异步回调" class="headerlink" title="异步回调"></a>异步回调</h3><h1 id="工作实践"><a href="#工作实践" class="headerlink" title="工作实践"></a>工作实践</h1><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>通过对查询计划的分析，我们了解到以下几点信息</p>
<ol>
<li>执行计划会在Presto服务端进行缓存，并提供页面查询，但查询结果随Presto服务重启丢失，且有存活有效期，默认为5分钟</li>
<li>作为查询引擎，必然会对sql进行优化改写，有一些常用的聚合下推，字段过滤，连接优化等。但均基于规则，只有部分数据源支持基于代价优化，可以通过explain查看执行计划</li>
<li>数据是通过客户端不断发起请求，滚动获取数据</li>
<li>查询结果是经过多个Worker的结果组合而成，尽量减少最小粒度的查询能有效降低网络传输，提高查询性能</li>
</ol>
<h2 id="慢查询监控"><a href="#慢查询监控" class="headerlink" title="慢查询监控"></a>慢查询监控</h2><p>根据业务定义，这里我们认为超过5分钟的查询即为慢查询</p>
<p>定位慢查询，首先需要能够收集慢查询的信息，这里Presto提供了 <a class="link"   href="https://trino.io/docs/current/admin/event-listeners-http.html" >EventListener<i class="fas fa-external-link-alt"></i></a> ，Presto会将执行计划通过http发送到指定url，收集到执行计划后，我们可以将执行耗时及查询id输出到grafana上，以便后续分析，监控页面如下：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image7.png"
                        alt="image-202206251715403"
                 ></p>
<ul>
<li>查询计划可视化</li>
</ul>
<p>通过EventListener收集到的执行计划，我们已经可以精准定位到某一条sql，但相同的查询，在不同集群状况下执行效果不同，为了能够精准判断当时的执行结果，我们需要能够重现执行计划。由于执行计划是一个较大的Json体，为了能更直观的查看执行计划，可以通过适当改写源码的执行计划展示逻辑，读取本地执行计划文件，以便输出展示。</p>
<p>后端魔改的类：io.trino.server.ui.UiQueryResource#getQueryInfo</p>
<p>前端魔改的js：webapp&#x2F;dist&#x2F;plan.js</p>
<ul>
<li>集群运行状态分析<ul>
<li>分区是否合理，是否倾斜</li>
<li>内存设置是否合理</li>
<li>队列是否空闲</li>
</ul>
</li>
</ul>
<h2 id="常用优化策略"><a href="#常用优化策略" class="headerlink" title="常用优化策略"></a>常用优化策略</h2><ul>
<li>Sql优化</li>
</ul>
<p>​		优化手段也比较多，官网和网上都讲的比较详细，例如大表放左侧，只查询必要字段，orderBy和Limit共同使用，少用Distinct，命中分区键等。</p>
<p>​		方式有很多种，大体上是基于减少单节点的无效操作为主，这样可以有效降低内存和cpu的消耗。由于我们采用的是Presto+kudu的方式，无法支持基于Cost的优化，优化思路基本集中在合理设计分区，减少扫描量上。更进一步优化需要从业务侧入手，控制高频低价值的查询。</p>
<ul>
<li>数据存储优化<ul>
<li>数据存储分区合理，在尽量不产生数据倾斜的情况下，结合业务使用场景进行分区。</li>
<li>尽可能提前计算数据，减少查询时的聚合量</li>
<li>冷数据做好备份，控制数据总量</li>
</ul>
</li>
</ul>
<h1 id="kudu分区裁剪效果"><a href="#kudu分区裁剪效果" class="headerlink" title="kudu分区裁剪效果"></a>kudu分区裁剪效果</h1><p>presto在生成物理执行计划之前，会创建kudu扫描token（scan-token），用来生成split，并行扫描，此时通过kudu的client，会根据剪纸效果，指定对应的driver，同时指定对应的tabletId，代码路径</p>
<p>物理执行计划生成：</p>
<p>io.prestosql.execution.SqlQueryExecution#planDistribution</p>
<p>io.prestosql.sql.planner.DistributedExecutionPlanner#plan</p>
<p>io.prestosql.sql.planner.DistributedExecutionPlanner#doPlan（生成splitSources）</p>
<p>io.prestosql.sql.planner.plan.ProjectNode#accept</p>
<p>io.prestosql.sql.planner.DistributedExecutionPlanner.Visitor#visitScanAndFilter</p>
<p>io.prestosql.split.SplitManager#getSplits</p>
<p>io.prestosql.plugin.kudu.KuduClientSession#buildKuduSplits（已经获取到指定的tabletId，便于后续生成KuduScanner）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public List&lt;KuduSplit&gt; buildKuduSplits(KuduTableHandle tableHandle)</span><br><span class="line">    &#123;</span><br><span class="line">        KuduTable table = tableHandle.getTable(this);</span><br><span class="line">        final int primaryKeyColumnCount = table.getSchema().getPrimaryKeyColumnCount();</span><br><span class="line">        //生成scanToken</span><br><span class="line">        KuduScanToken.KuduScanTokenBuilder builder = client.newScanTokenBuilder(table);</span><br><span class="line"></span><br><span class="line">        TupleDomain&lt;ColumnHandle&gt; constraint = tableHandle.getConstraint();</span><br><span class="line">        if (!addConstraintPredicates(table, builder, constraint)) &#123;</span><br><span class="line">            return ImmutableList.of();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Optional&lt;List&lt;ColumnHandle&gt;&gt; desiredColumns = tableHandle.getDesiredColumns();</span><br><span class="line"></span><br><span class="line">        List&lt;Integer&gt; columnIndexes;</span><br><span class="line">        //省略获取列过程</span><br><span class="line"></span><br><span class="line">        builder.setProjectedColumnIndexes(columnIndexes);</span><br><span class="line"></span><br><span class="line">        //获取每个tablet的scan</span><br><span class="line">        List&lt;KuduScanToken&gt; tokens = builder.build();</span><br><span class="line">        return tokens.stream()</span><br><span class="line">                .map(token -&gt; toKuduSplit(tableHandle, token, primaryKeyColumnCount))</span><br><span class="line">                .collect(toImmutableList());</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<p>把Split带入到stage，开始调度</p>
<p>io.prestosql.execution.scheduler.SqlQueryScheduler#createSqlQueryScheduler</p>
<p>io.prestosql.execution.scheduler.SqlQueryScheduler#createStages</p>
<p>从stage中取出调度任务，开始执行</p>
<p>io.prestosql.execution.scheduler.SqlQueryScheduler#schedule</p>
<p>io.prestosql.execution.scheduler.StageScheduler#schedule</p>
<p>io.prestosql.execution.SqlStageExecution#scheduleSplits</p>
<p>利用PlanFragment构建Map&lt;PlanNodeId, SplitSource&gt;的关系，在找到Map&lt;PlanNodeId, TableInfo&gt; 的关系，将这个关系保存在StageExecutionPlan中</p>
<p>最后将调度结果存入执行计划缓存，以便页面观看</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="/./3_Presto/image9.png"
                        alt="image-202206251715403"
                 ></p>
<h1 id="奇怪的坑"><a href="#奇怪的坑" class="headerlink" title="奇怪的坑"></a>奇怪的坑</h1><h2 id="本地调试启动死循环"><a href="#本地调试启动死循环" class="headerlink" title="本地调试启动死循环"></a>本地调试启动死循环</h2><ul>
<li>现象：</li>
</ul>
<p>本地用openjdk17，21，22启动时trino-server-dev服务（trino版本为438），启动前会校验jvm的参数，经过堆栈追踪，发现程序一直卡在以下方法</p>
<p>org.openjdk.jol.vm.sa.ServiceabilityAgentSupport#callAgent(org.openjdk.jol.vm.sa.Task, boolean, org.openjdk.jol.vm.sa.ServiceabilityAgentSupport.AgentStyle)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">agentProcess = (new ProcessBuilder(args)).start();</span><br><span class="line">Request request = new Request(this.processId, processor, 5000);</span><br><span class="line">InputStream is = agentProcess.getInputStream();</span><br><span class="line">OutputStream os = agentProcess.getOutputStream();</span><br><span class="line">InputStream es = agentProcess.getErrorStream();</span><br><span class="line">out = new ObjectOutputStream(os);</span><br><span class="line">out.writeObject(request);</span><br><span class="line">out.flush();</span><br><span class="line"></span><br><span class="line">//卡在这里</span><br><span class="line">int exitCode = agentProcess.waitFor();</span><br><span class="line"></span><br><span class="line">agentProcess = null;</span><br><span class="line">err = new BufferedReader(new InputStreamReader(es));</span><br></pre></td></tr></table></figure>

<ul>
<li>处理过程：</li>
</ul>
<p>经过各种排查，在jdk的bug管理中找到蛛丝马迹，记录里表示，某使用者，用jol-0.17（也是trino依赖的版本），jdk21运行时，发现运行到attachMethod.invoke(agent, (int) request.getProcessId()); mac会崩溃，重启多次无效。另一个大神排查表示，怀疑是连接SA有问题，可以使用参数调过连接SA</p>
<p>链接如下：</p>
<p><a class="link"   href="https://bugs.openjdk.org/browse/CODETOOLS-7903447?jql=resolution%20in%20(Unresolved,%20Fixed)%20AND%20component%20=%20tools%20AND%20Subcomponent%20=%20jol%20AND%20text%20~%20%22mac%22" >https://bugs.openjdk.org/browse/CODETOOLS-7903447?jql=resolution%20in%20(Unresolved%2C%20Fixed)%20AND%20component%20%3D%20tools%20AND%20Subcomponent%20%3D%20jol%20AND%20text%20~%20%22mac%22<i class="fas fa-external-link-alt"></i></a></p>
<ul>
<li>小结：</li>
</ul>
<p>最终在启动时，增加VM参数：-Djol.skipHotspotSAAttach&#x3D;true。跳过连接SA。</p>
<h2 id="本地调试无法连接maven父项目"><a href="#本地调试无法连接maven父项目" class="headerlink" title="本地调试无法连接maven父项目"></a>本地调试无法连接maven父项目</h2><ul>
<li>现象：</li>
</ul>
<p>本地启动时，不管是trino父项目，还是子项目，均会报错提示无法连接到 <a class="link"   href="http://repo.maven.apache.org/maven2" >http://repo.maven.apache.org/maven2<i class="fas fa-external-link-alt"></i></a> 但直接访问url<strong>貌似</strong>是可以的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[ERROR] Non-resolvable import POM: Could not transfer artifact com.google.cloud:google-cloud-bigquerystorage-bom:pom:3.9.0 from/to central (http://repo.maven.apache.org/maven2): Failed to transfer http://repo.maven.apache.org/maven2/com/google/cloud/google-cloud-bigquerystorage-bom/3.9.0/google-cloud-bigquerystorage-bom-3.9.0.pom. Error code 501, HTTPS Required @ com.google.cloud:google-cloud-bom:0.226.0, /Users/weiqian/.m2/repository/com/google/cloud/google-cloud-bom/0.226.0/google-cloud-bom-0.226.0.pom, line 179, column 19</span><br></pre></td></tr></table></figure>

<ul>
<li>处理过程：</li>
</ul>
<p>当pom中依赖父项目，且未配置relarelativePath时，父项目会默认从远程拉取。在org.apache.maven.model.building.DefaultModelBuilder#build(org.apache.maven.model.building.ModelBuildingRequest, java.util.Collection&lt;java.lang.String&gt;)构建过程中，会向远程下载父项目jar包。</p>
<p>但又因为airlift.resolver（版本1.6）项目在解析pom时，固定使用了http:&#x2F;&#x2F;，无法修改，参考<a class="link"   href="https://github.com/airlift/resolver/pull/21" >git记录<i class="fas fa-external-link-alt"></i></a>。该committer申请了pr，但该项目太老了，最新一次发布在2019年，也没有将bugfix合并至最新版本。</p>
<p>而maven在很早的时候就不允许http下载，必须修改为https，因此下载失败。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">io.airlift.resolver.ArtifactResolver#getMavenProject</span><br><span class="line"></span><br><span class="line">PlexusContainer container = container();</span><br><span class="line">org.apache.maven.repository.RepositorySystem lrs = container.lookup(org.apache.maven.repository.RepositorySystem.class);</span><br><span class="line">ProjectBuilder projectBuilder = container.lookup(ProjectBuilder.class);</span><br><span class="line">ProjectBuildingRequest request = new DefaultProjectBuildingRequest();</span><br><span class="line">request.setSystemProperties(requiredSystemProperties());</span><br><span class="line">request.setRepositorySession(repositorySystemSession);</span><br><span class="line">request.setProcessPlugins(false);</span><br><span class="line">request.setLocalRepository(lrs.createDefaultLocalRepository());</span><br><span class="line">request.setRemoteRepositories(Arrays.asList(new ArtifactRepository[] &#123;lrs.createDefaultRemoteRepository()&#125;.clone()));</span><br><span class="line">ProjectBuildingResult result = projectBuilder.build(pomFile, request);</span><br></pre></td></tr></table></figure>

<ul>
<li>小结：</li>
</ul>
<p>在pom中手动增加repository</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;name&gt;$&#123;project.artifactId&#125;&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;Trino&lt;/description&gt;</span><br><span class="line">    &lt;url&gt;https://trino.io&lt;/url&gt;</span><br><span class="line"></span><br><span class="line">    &lt;inceptionYear&gt;2012&lt;/inceptionYear&gt;</span><br><span class="line"></span><br><span class="line">		&lt;!-- 新加的 --&gt;</span><br><span class="line">    &lt;repositories&gt;</span><br><span class="line">        &lt;repository&gt;</span><br><span class="line">            &lt;releases&gt;</span><br><span class="line">                &lt;enabled&gt;true&lt;/enabled&gt;</span><br><span class="line">            &lt;/releases&gt;</span><br><span class="line">            &lt;snapshots&gt;</span><br><span class="line">                &lt;enabled&gt;true&lt;/enabled&gt;</span><br><span class="line">            &lt;/snapshots&gt;</span><br><span class="line">            &lt;id&gt;nexus&lt;/id&gt;</span><br><span class="line">            &lt;name&gt;nexus&lt;/name&gt;</span><br><span class="line">            &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt;</span><br><span class="line">        &lt;/repository&gt;</span><br><span class="line">    &lt;/repositories&gt;</span><br></pre></td></tr></table></figure>





<h2 id="待续"><a href="#待续" class="headerlink" title="待续"></a>待续</h2><h1 id="阶段小结"><a href="#阶段小结" class="headerlink" title="阶段小结"></a>阶段小结</h1><p>本文主要以查询计划为分析点，介绍了Presto在查询执行和优化上的一些设计理念，以及分享实际工作中是如何定位和优化慢查询。Presto的源码模块结构较为清晰，且大量使用异步线程，提高查询性能。其中一些常用的查询优化手段，例如广播join，谓词下推，在其他的查询引擎中也都存在，对学习其他框架有参考作用，只有了解Presto的底层原理，才能更好的理解优化策略，更好的指导工作与学习。</p>
<h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a class="link"   href="https://blog.csdn.net/linjunjunjun/article/details/124831612" >presto查询流程<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://blog.csdn.net/zhanyuanlin/article/details/131214028" >Presto(Trino)的逻辑执行计划和Fragment生成过程<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link"   href="https://blog.csdn.net/zhanyuanlin/article/details/131343786" >Presto(Trino)分布式(物理)执行计划的生成和调度<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="本地调试用表结构"><a href="#本地调试用表结构" class="headerlink" title="本地调试用表结构"></a>本地调试用表结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">创建表</span><br><span class="line">CREATE TABLE  memory.default.ncdp_dwb_channel_user_attribute_bos (</span><br><span class="line">   u_key varchar,</span><br><span class="line">   bos_id varchar,</span><br><span class="line">   name varchar</span><br><span class="line">);</span><br><span class="line">INSERT INTO memory.&quot;default&quot;.ncdp_dwb_channel_user_attribute_bos (u_key , bos_id,   name) VALUES(&#x27;1000000027&#x27; , &#x27;4000180336837&#x27;, &#x27;张三&#x27;);</span><br><span class="line">INSERT INTO memory.&quot;default&quot;.ncdp_dwb_channel_user_attribute_bos (u_key , bos_id,   name) VALUES(&#x27;1000000028&#x27; , &#x27;4000180336837&#x27;, &#x27;李四&#x27;);</span><br><span class="line">INSERT INTO memory.&quot;default&quot;.ncdp_dwb_channel_user_attribute_bos (u_key , bos_id,   name) VALUES(&#x27;1000000029&#x27; , &#x27;4000180336837&#x27;, &#x27;王五&#x27;);</span><br><span class="line"></span><br><span class="line">select * from memory.default.ncdp_dwb_channel_user_attribute_bos where u_key =&#x27;1000000029&#x27;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>分布式组件</category>
      </categories>
  </entry>
  <entry>
    <title>分布式事务</title>
    <url>/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<h1 id="什么是事务"><a href="#什么是事务" class="headerlink" title="什么是事务"></a>什么是事务</h1><h2 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h2><p>原子性（Atomicity）：事务要么全部做，要么全部不做。和并发场景的原子性不同。</p>
<p>一致性（Consistency）：事务使系统从一个一致性的状态转换到另一个一致性的状态。</p>
<p>隔离性（Isolation）：两个并发事务看不到彼此正在进行的更新操作。可串行化：多个事务实际上可能同时运行，但结果与串行运行完全相同。</p>
<p>持久性（Durability）：保证一个成功的事务对数据的更新是永久的。</p>
<p>小结：现代数据库通过锁协议实现隔离性；通过日志和恢复技术实现持久性；隔离性和原子性由锁和日志保证；一致性由业务定义约束，运行时检查管理，如果一个事务违反一致性约束，则事务终止。</p>
<ul>
<li>事务一般特指多对象操作。</li>
</ul>
<p>某些数据库提供原子操作，例如”原子自增”，”比较-设置”，可以有效防止并发场景下<strong>更新丢失</strong>问题。但这些操作不是通常意义上的事务。</p>
<ul>
<li>弱隔离级别</li>
</ul>
<p><img src="/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/4.png" alt loading="lazy"></p>
<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>S-Lock：共享锁</p>
<p>X-Lock：排他锁</p>
<h2 id="2PL（Two-Phase-Locking）"><a href="#2PL（Two-Phase-Locking）" class="headerlink" title="2PL（Two-Phase-Locking）"></a>2PL（Two-Phase-Locking）</h2><p>2阶段锁协议，是并发控制下保证程序调度的正确性协议。<strong>与2PC不同</strong>，为了使并发场景下，各事务能够得到正确的结果，不同事务之间操作需要遵循2PL协议。该协议目前在Mysql，SqlServer，DB2中实现，与快照隔离也不同，2PL不仅写写互斥，在读写之间也互斥。是一种悲观并发思想。</p>
<p>2PL协议分为2个阶段</p>
<ul>
<li>阶段1：事务执行阶段，获取锁，不能释放锁。</li>
<li>阶段2：事务提交阶段，只能释放锁，不能获取锁</li>
</ul>
<p>2PL示意图</p>
<p><img src="/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/1.png" alt loading="lazy"></p>
<p>严格2PL，事务修改的数据在事务结束前，其他事务不允许读写。可以避免T1如果回滚，需要级联T2回滚。带来的问题，死锁，对应措施是死锁监测，锁等待图。</p>
<p>SS2PL示意图</p>
<p><img src="/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/2.png" alt loading="lazy"></p>
<p>为了提高性能，减少加锁频次，会扩大锁粒度，比如针对段、表加锁。比如意向锁</p>
<p><img src="/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/3.png" alt loading="lazy"></p>
<h2 id="T-O（Timestamp-Ordering）"><a href="#T-O（Timestamp-Ordering）" class="headerlink" title="T/O（Timestamp Ordering）"></a>T/O（Timestamp Ordering）</h2><p>基于时间戳的并发控制，是一种乐观并发控制的方法，OCC（Optimize Concentecy Control ）是优化后的T/O，只在写时再check，将乐观进行到底。</p>
<ul>
<li>时间戳由全局发号器维护，且单调递增</li>
<li>每一行记录有两个时间戳，W-Ts读时间戳，R-Ts写时间戳。用于后续读写控制</li>
<li>如果i 小于j ，需要保证Ts(i) &lt; Ts (j)，也就是说并发执行之后，看起来，事务i在事务j之前执行</li>
<li>分为读写：<ul>
<li>读：如果Ts(j) &lt; W-Ts(X)，说明读取到”未来”数据，放弃读取，重新读</li>
<li>写：如果Ts(j) &lt; R-Ts(X) or Ts(j) &lt; W-Ts(X)，说明写的时候，读取到/准备写入”未来”的数据，放弃写入，重新读取</li>
</ul>
</li>
</ul>
<h2 id="MVCC（Multi-Version-Concurrency-Control）"><a href="#MVCC（Multi-Version-Concurrency-Control）" class="headerlink" title="MVCC（Multi-Version Concurrency Control）"></a>MVCC（Multi-Version Concurrency Control）</h2><p>为了实现【写入不阻塞其他读取，读取不阻塞写入】，是数据库并发控制的理论基础，不同的数据库实现有所不同。</p>
<ul>
<li>并发协议<ul>
<li>是对2PL，T/O，OCC的补充</li>
</ul>
</li>
<li>版本存储<ul>
<li>通过链表方式存储不同的版本，通过指针关联新老板本</li>
<li>不同数据库实现不同，大致分为3类<ul>
<li>原表直接追加</li>
<li>历史表单独存储</li>
<li>变更数据段单独存储</li>
</ul>
</li>
</ul>
</li>
<li>垃圾回收<ul>
<li>回收宗旨：该数据版本，没有生效中的事务需要查看，或来自中断的事务</li>
<li>回收策略：<ul>
<li>基于行记录，a.单独线程扫全表监测，b.工作线程（例如读取的线程）扫描数据时，顺便监测历史垃圾版本</li>
<li>基于事务，事务自身记录历史版本？</li>
</ul>
</li>
</ul>
</li>
<li>索引管理<ul>
<li>因为有版本的概念，单次查询可能会返回历史版本，因此，Pk或Unique Key存储多条记录，需要一种索引的存储方案</li>
</ul>
</li>
<li>删除<ul>
<li>数据删除后，如何标记数据变更版本是被删除的。<ul>
<li>版本打上删除标记</li>
<li>追加墓碑标记，表示在墓碑之前的版本都是被删除的</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="什么是分布式系统"><a href="#什么是分布式系统" class="headerlink" title="什么是分布式系统"></a>什么是分布式系统</h1><blockquote>
<p>分布式系统是由一组通过网络进行，为了完成共同任务的计算节点而形成的系统</p>
</blockquote>
<h2 id="理论系统模型"><a href="#理论系统模型" class="headerlink" title="理论系统模型"></a>理论系统模型</h2><p>根据计时，可以分为3种模型</p>
<ul>
<li>同步模型。网络延迟，进程暂停和时钟误差都有上界，实际上不太可能。</li>
<li>部分同步模型。网络延迟，进程暂停和时钟误差有一个预期上界，大部分时候不会超过，但需要考虑偶尔违背的情况。</li>
<li>异步模型。算法不对时机做任何假设，可能也没有超时机制。</li>
</ul>
<p>根据节点失效，可以分为3种模型</p>
<ul>
<li>崩溃-中止模型。节点故障后，无法恢复。</li>
<li>崩溃-恢复模型。节点故障后，一段时间会恢复，持久化数据可以保留，内存数据丢失。</li>
<li>失效模型。节点故障后，啥都可能发生。</li>
</ul>
<p>真实场景下，大部分是部分同步模型 + 崩溃恢复模型</p>
<h2 id="FLP"><a href="#FLP" class="headerlink" title="FLP"></a>FLP</h2><blockquote>
<p>出自《<strong>Impossibility of distributed consensus with one faulty process</strong>》，作者：Michael J. Fischer , Nancy A. Lynch , Michael S. Paterson 1983，FLP以三位作者首字母命名</p>
</blockquote>
<p>在异步网络下，如果有一台机器可能出错，则没有任何确定性共识算法保证在有限时间内结束。该理论有限定条件，首先，FLP是基于异步系统模型，且实际上可以使用超时和其他方法监测崩溃节点，从而实现共识。</p>
<h2 id="CAP（Consistency-Availability-Partition-tolerance）"><a href="#CAP（Consistency-Availability-Partition-tolerance）" class="headerlink" title="CAP（Consistency Availability Partition-tolerance）"></a>CAP（Consistency Availability Partition-tolerance）</h2><blockquote>
<p>是FLP的引申，作者是Nancy A. Lynch。</p>
</blockquote>
<p>CAP指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容忍性），三者不可得兼</p>
<h3 id="Consitncy"><a href="#Consitncy" class="headerlink" title="Consitncy"></a>Consitncy</h3><p>一致性，针对每一个请求，每一个服务会返回正确的响应。响应的正确依赖服务的定义。实践中有较多的一致性（例如顺序一致性，因果一致性）</p>
<h3 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h3><p>可用性，针对每一个请求，最终会收到响应。</p>
<h3 id="Partition-tolerance"><a href="#Partition-tolerance" class="headerlink" title="Partition-tolerance"></a>Partition-tolerance</h3><p>分区容忍，基于如下假设，通信是不可靠的，服务器可能被划分为多个组，且彼此之间不能交互。我们假设消息是会延迟，且会丢失的。</p>
<p>取舍的应用：</p>
<ol>
<li>弱化一致性：对一致性不敏感的场景中使用，允许在经过一段时间达成最终一致性，在这期间不保证一致。比如3PC协议、Gossip协议以及CouchDB、Cassandra、DynamoDB等都是基于这种前提设计的。</li>
<li>弱化可用性：对于结果一致性很敏感的系统，比如银行、金融等，当系统故障时可能会选择拒绝服务。Paxos、Raft等算法是在弱化可用性的前提下，解决分布式一致性问题。MongoDB、redis、Hbase等系统也都提供了这种场景下的解决方案。</li>
<li>弱化分区容忍性：网络出现分区的情况概率比较小，但是难以避免。XA、ACID是典型的弱化分区容忍性的设计，而传统的RDBMS在某些部署方案下也弱化了分区容忍性，另外zookeepr和etcd在设计上也考虑了分区容忍性和可用性的折中。</li>
</ol>
<h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><h3 id="Basically-Available-基本可用"><a href="#Basically-Available-基本可用" class="headerlink" title="Basically Available(基本可用)"></a>Basically Available(基本可用)</h3><p>是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用，支持分区失败。</p>
<h3 id="Soft-state-柔性状态"><a href="#Soft-state-柔性状态" class="headerlink" title="Soft state(柔性状态)"></a>Soft state(柔性状态)</h3><p>是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。</p>
<h3 id="Eventually-consistent-最终一致"><a href="#Eventually-consistent-最终一致" class="headerlink" title="Eventually consistent(最终一致)"></a>Eventually consistent(最终一致)</h3><p>系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。</p>
<h2 id="一致性与共识"><a href="#一致性与共识" class="headerlink" title="一致性与共识"></a>一致性与共识</h2><h3 id="线性一致性"><a href="#线性一致性" class="headerlink" title="线性一致性"></a>线性一致性</h3><p>基本思想，让系统看起来只有一个数据副本，且所有操作都是原子的。也称为<strong>强一致性</strong>。</p>
<p><img src="/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/5.png" alt loading="lazy"></p>
<p>根据（来自DDIA9-4）图例，要求，连接竖线，必须总是按照时间向前移动，确保就近性，即一旦新值被写入或读取，所有后续的读都看到的是最新的值，直到被再次覆盖</p>
<ul>
<li>使用场景</li>
</ul>
<ol>
<li>加锁，主节点选举</li>
<li>约束与唯一性保证</li>
<li>多消息通道间的时间保证</li>
</ol>
<ul>
<li>实现线性化系统的例子</li>
</ul>
<ol>
<li>主从复制（仅部分满足），当从主节点，或者更新过后的从节点上读取，可以满足线性化。</li>
<li>共识算法，例如zookeeper，etcd等，<strong>CP系统？</strong></li>
</ol>
<blockquote>
<p>补充一下，<strong>多主复制</strong>，<strong>无主复制</strong>通常无法做到线性化</p>
</blockquote>
<ul>
<li>代价</li>
</ul>
<p>根据CAP理论研究，实现线性一致性则<strong>无法容忍网络故障</strong>，为了满足分布式容错，我们选择牺牲线性化读写</p>
<h3 id="因果一致性"><a href="#因果一致性" class="headerlink" title="因果一致性"></a>因果一致性</h3><p>顾名思义，因果关系就是对事物的发生有因果关系，例如：发送消息先于接收消息，问题出现在答案之前等。如果系统服从因果关系所规定的顺序，则成为因果一致性。</p>
<p>在一个可线性化系统中，存在全序操作关系。如果两个操作都没有发生在对方之前，那么两个操作是并发关系，比如git。</p>
<p><img src="/2024/07/04/4_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/6.png" alt loading="lazy"></p>
<ul>
<li>使用场景</li>
</ul>
<blockquote>
<p>在线性一致性的场景中，大部分场景，其实需要的是因果一致性</p>
</blockquote>
<ol>
<li>主从复制</li>
<li>事务的幻读，幻写</li>
<li>不同通信通道的时间顺序</li>
</ol>
<ul>
<li><p>实现</p>
<p>可以通过监测因果关系的偏序关系，一种比较显而易见的跟踪所有的因果关系，但不切实际。相比之下，可以创建与因果顺序一致的<strong>序列号</strong>，代表偏序关系。</p>
<ul>
<li><p>不太完善的实现</p>
<p>每个节点产生自己的一组序列号；墙上时间作为序列号；预先分配每个节点的序列区间。<strong>但</strong>这些实现都无法保证因果顺序与序列号的一致性。</p>
</li>
<li><p>相对简单的实现</p>
<p>Lamport时间戳 + 全序关系广播。</p>
<blockquote>
<p>Lamport每个节点以及每个客户端都跟踪迄今为止所见到的最大计数器，并在每个请求中附带该最大计数器值，当节点收到某个请求时，如果发现请求内嵌的最大计数器大于节点自身的计数器，则like把自己的计数器修改为该最大值。</p>
<p>全序关系广播，指节点之间交换信息的某种协议，需满足2个基本属性：<strong>可靠发送</strong>，即消息没有丢失，如果消息发送到某一节点，则一定要发送到所有节点；<strong>严格有序</strong>，即消息总是已相同顺序发送给某个节点。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="共识"><a href="#共识" class="headerlink" title="共识"></a>共识</h3><p>一个或多个节点可以提议某些值，由共识算法决定最终值。共识算法有几个性质</p>
<ol>
<li>协商一致性：所有节点都接受相同的 决议</li>
<li>诚实性：所有节点不能反悔</li>
<li>合法性：如果决定了值v，则v一定是有某个节点所提议的</li>
<li>可终止性：节点如果不崩溃，则最终一定可以达成决议</li>
</ol>
<p>典型场景，2PC，XA事务。典型算法，Raft，Zab，Paxos，大部分是决定了一系列值，通过全序关系广播通知其他各节点。共识协议内部使用了某种形式的主节点，协议定义一个世代编号（epoch），主节点如果要做出某个决定，需要将提议发送给其他所有节点，等待quorum节点（多数节点）响应，当没有更高的epoch节点时，才能携带epoch进行投票。</p>
<p><strong>共识的代价</strong>。达成一致性决议前，节点投票是一个同步复制的过程；共识体系需要多个奇数节点才能保证部分容错；共识算法基于固定节点数，如果增减节点，需要一定的处理；共识系统通过超时监测失败，由于网络原因，可能会误判，造成频繁选举主节点。</p>
<p><strong>相关的等价问题</strong>。可线性化比较-设置；原子事务提交；全序广播；锁与租约；成员服务；唯一性约束。</p>
<h1 id="什么是分布式事务"><a href="#什么是分布式事务" class="headerlink" title="什么是分布式事务"></a>什么是分布式事务</h1><p>分布式事务可以理解为：由分布在不同节点的本地事务，通过协调调度，使整体满足ACID的事务。</p>
<p>在分布式场景下，不同节点通过网络连接在一起，共同提供服，预期下，我们希望一个业务流程，可以经过多个分布式节点，同样可以实现类似于单体应用下的ACID特性，即业务操作是原子的，业务结果前后是一致的。由于网络的不确定性，分布式事务只能尽可能满足ACID。业界有多种分布式事务的实现方案，不同的方案各有优劣，都在一致性与隔离性之间寻求平衡。</p>
<p>举个无一致性特性例子</p>
<ul>
<li>直接使用DB本地事务内调用第三方接口（RPC，MQ）</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doSave</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="comment">//开启事务</span></span><br><span class="line">  startTransaction();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//DB保存，执行场景A</span></span><br><span class="line">  saveDB();</span><br><span class="line">  <span class="comment">//调用第三方接口，执行场景B</span></span><br><span class="line">  callRPC();</span><br><span class="line">  <span class="comment">//调用第三方接口，执行场景C</span></span><br><span class="line">  sendMq();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//提交事务</span></span><br><span class="line">  commitTransaction();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>好处</li>
</ul>
<ol>
<li>实现简单粗暴</li>
<li>一定程度保证第三方接口100%调用成功</li>
</ol>
<ul>
<li>问题</li>
</ul>
<ol>
<li>顺序依赖：第三方接口如果依赖本地事务提交后的数据，会由于当前事务未提交而查询不到最新数据，造成流程不可预期</li>
<li>幻读：ABC三个执行场景，如果执行场景B成功后，但执行场景C【调用超时未响应】、【调用异常报错】、【本地事务超时回滚】，如果此时回滚当前事务A，会造成执行场景B已被执行，但不应该执行的情况。</li>
</ol>
<h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><ul>
<li>强一致性<ul>
<li>2PC<ul>
<li>XA协议</li>
</ul>
</li>
<li>3PC</li>
</ul>
</li>
<li>柔性事务，最终一致性<ul>
<li>TCC<ul>
<li>每个业务操作分为三个业务接口</li>
</ul>
</li>
<li>可靠消息<ul>
<li>本地消息表/本地事务表</li>
<li>事务消息</li>
</ul>
</li>
<li>最大努力通知</li>
</ul>
</li>
<li>共识算法</li>
<li>Saga长事务</li>
</ul>
<h2 id="工程实践"><a href="#工程实践" class="headerlink" title="工程实践"></a>工程实践</h2><h3 id="2PC（Two-Phase-Commit）"><a href="#2PC（Two-Phase-Commit）" class="headerlink" title="2PC（Two-Phase Commit）"></a>2PC（Two-Phase Commit）</h3><blockquote>
<p>强一致性，只是概念协议，实际工程落地需要结合数据库（如mysql支持2PC协议）</p>
</blockquote>
<p>前提假设：存在一个节点作为协调者，其他节点作为参与者，节点之间通信正常；节点采用预写日志，保证持久性。一般数据库会实现2PC协议。</p>
<ul>
<li>准备阶段：协调者向每个参与者发送Prepare消息，每个参与者本地执行事务，但事务并不提交。如果执行成功，则返回协调者同意，否则，返回终止。</li>
<li>提交阶段：协调者如果收到终止消息，则向所有参与者发送回滚消息。如果协调者都返回同意，则发送提交命令。</li>
</ul>
<p>这里有几个关键点</p>
<ol>
<li>协调者生成全局事务ID，每个节点均将该全局事务ID附加到事务中，以便追踪</li>
<li>当参与者提交”同意”后，说明满足提交条件，后续不能变更（除非被协调者撤销）</li>
<li>当协调者广播”提交”后，各节点必须完成事务，不可变更。</li>
</ol>
<h4 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h4><ol>
<li>利用数据库本地事务特性，在准备阶段会锁定资源，提交阶段在网络正常的情况下，能达到强一致的效果</li>
<li>数据库自身通过 undo/redo日志，实现了2PC，业务侵入较低</li>
</ol>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ol>
<li>性能差，准备阶段数据被锁定</li>
<li>协调者处于单点状态，严重依赖协调者的稳定性，一旦协调者在提交阶段崩溃，会导致锁定的数据库资源无法释放</li>
<li>网络异常，参与者在提交阶段如果没有收到提交命令，会导致数据不一致</li>
</ol>
<p>3PC（Three-Phase Commit），3PC在2PC的基础上，增加了预准备阶段，增加了参与者未收到提交命令后自动提交的机制。通过预准备阶段，进一步降低准备阶段锁定数据的概率，同时降低提交阶段数据不一致的风险。简而言之是通过降低一致性，提高整体性能。</p>
<h3 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h3><blockquote>
<p>最终一致性（弱一致性）</p>
</blockquote>
<p>2PC和3PC都是数据库层面的事务提交回滚，TCC（Try、Confirm、Cancel ）在业务上，显示定义预提交，确认，取消三个接口，一个业务动作需要改造成3个接口，且接口必须实现幂等。操作流程和2PC类似，协调者（业务发起方）通过Try接口调用参与者（业务配合方）锁定资源，如果下游参与者都返回成功，协调者则发送Confirm通知参与者执行资源。如果有一个参与者返回失败，协调者则发送Cancel通知参与者回滚锁定资源。</p>
<ul>
<li>幂等：由于网络不可信，三个业务接口均实现幂等</li>
<li>空回滚：Try未接收到，但是收到了Cancel，需要Cancel消息能够正常处理</li>
<li>悬挂：一开始Try未接收到，Cancel处理之后，又收到Try消息，需要能正常忽略此Try消息</li>
</ul>
<h4 id="好处-1"><a href="#好处-1" class="headerlink" title="好处"></a>好处</h4><ol>
<li>性能较高，TCC三个接口本质上都是单独的本地事务，阻塞时间少</li>
<li>业界通用，理解成本低。即使调用第三方接口，也可以通过业务上回滚，达到类似TCC的效果</li>
</ol>
<h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><ol>
<li>业务侵入性高，需要额外处理空回滚，悬挂等问题，工程上较为复杂</li>
</ol>
<h3 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h3><blockquote>
<p>最终一致性（弱一致性），属于可靠消息最终一致性</p>
</blockquote>
<ul>
<li>新建本地消息表，每一个场景新建一张表（也可以加类型字段区分）</li>
<li>消息发送方，业务数据和事务表利用本地事务同时提交，然后发送MQ给消息消费方，由定时任务扫描发送失败的消息，重复发送，直到成功为止</li>
<li>消息接收方，消息消费方需要实现幂等逻辑，如果消费异常，则重试，直到成功为止。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`xxx_log`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="string">`message_id`</span> <span class="built_in">varchar</span>(<span class="number">50</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'消息id'</span>,</span><br><span class="line">  <span class="string">`message_data`</span> <span class="built_in">varchar</span>(<span class="number">1000</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'消息内容体'</span>,</span><br><span class="line">  <span class="string">`status`</span> <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'状态（ready,finish）'</span>,</span><br><span class="line">  <span class="string">`business_time`</span> datetime(<span class="number">6</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'业务时间'</span>,</span><br><span class="line">  <span class="string">`create_time`</span> datetime(<span class="number">6</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'创建时间'</span>,</span><br><span class="line">  <span class="string">`modify_time`</span> datetime(<span class="number">6</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'更新时间'</span>,</span><br><span class="line">  <span class="string">`ext`</span> <span class="built_in">varchar</span>(<span class="number">500</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="string">`idx_time`</span> (<span class="string">`status`</span>,<span class="string">`business_time`</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4 <span class="keyword">COMMENT</span>=<span class="string">'本地消息表'</span>;</span><br></pre></td></tr></table></figure>

<h4 id="好处-2"><a href="#好处-2" class="headerlink" title="好处"></a>好处</h4><ol>
<li>实现相对简单</li>
<li>进一步保证第三方接口100%调用成功</li>
<li>确保本地事务的第一优先级</li>
</ol>
<h4 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h4><ol>
<li>不支持回滚，因为本地事务已经保存，第三方接口处理成功与否，不影响本地事务的执行，因此严格来说，这种不算事务</li>
<li>每一个场景都需要建一张表，复用性不高</li>
<li>由于依赖本地数据库存放消息，并发量不高</li>
<li>如果后置处理之间有顺序依赖，补偿发送和正常发送之间会存在乱序的情况。</li>
</ol>
<h3 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h3><blockquote>
<p> 本地消息表的中间件版本，属于可靠消息最终一致性</p>
</blockquote>
<ul>
<li>准备阶段：发送parpered消息（携带业务唯一id），类似与Try</li>
<li>执行阶段：业务方执行本地事务（保存业务唯一id），类似于Confirm</li>
<li>确认/回滚阶段：发送commit消息。如果commit消息发送失败/下游未收到commit消息，业务方提供反查接口，根据业务唯一id确定事务是否执行成功，以判断消息是否应该处理，还是重新拉取。事务消息回滚与本地事务回滚类似于Cancel。</li>
</ul>
<h4 id="好处-3"><a href="#好处-3" class="headerlink" title="好处"></a>好处</h4><ol>
<li>封装良好，由消息中间件实现本地消息表的逻辑</li>
<li>业务侵入性较低</li>
</ol>
<h4 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h4><ol>
<li>不是所有MQ组件都支持，目前已知，RocketMQ支持事务消息。</li>
</ol>
<h3 id="最大努力通知"><a href="#最大努力通知" class="headerlink" title="最大努力通知"></a>最大努力通知</h3><blockquote>
<p>与可靠消息相比，最大的区别在于，业务操作完，不保证一定发送消息。</p>
</blockquote>
<p>最大努力通知的作用场景主要是外部系统。考虑外部网络环境的不可控因素，无法试用事务消息保证数据的最终一致，而且消息发送涉及外部网络（大概率是RPC接口），可能出现超时的情况，无法确定消息发送的情况。</p>
<h1 id="附"><a href="#附" class="headerlink" title="附"></a>附</h1><p>参考：《Designing Data-Intensive Applications》</p>
<p>参考：<a href="https://zhuanlan.zhihu.com/p/480379228" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/480379228</a></p>
<p>CAP论文：<a href="https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf" target="_blank" rel="noopener">https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf</a></p>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
  </entry>
  <entry>
    <title>Oauth2</title>
    <url>/2021/12/03/5_Oauth2%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<blockquote>
<p>认证方式文档：<a href="https://tools.ietf.org/html/rfc6749#section-3.1.2" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc6749#section-3.1.2</a></p>
</blockquote>
<h1 id="Authorization-Code-Grant"><a href="#Authorization-Code-Grant" class="headerlink" title="Authorization Code Grant"></a>Authorization Code Grant</h1><blockquote>
<p>授权码认证。是最完整，安全性最高的认证方式，在客户端不授信，客户端不存储认账账号，且支持重定向的方式传递信息。</p>
</blockquote>
<p>支持刷新token需要支持重定向</p>
<p>交互图如下</p>
<p><img src="/2021/12/03/5_Oauth2%E8%AE%A4%E8%AF%81%E6%96%B9%E5%BC%8F/image1.png" alt loading="lazy"></p>
<blockquote>
<p>A，B，C表示同一个操作在不同终端的调用情况</p>
</blockquote>
<ol>
<li>客户端引导进入到用户代理端（这个可能是个web，或者app），携带clientid和重定向uri等信息。</li>
<li>当到达用户代理端时（可能是到了授权页，或者打开了一个新app），发起请求，先请求用户资源服务，验证用户信息，验证通过后，通知授权服务，签发授权码。请求响应重定向uri。</li>
<li>用户代理端获取到授权码后，使用步骤1传递的重定向uri，重定向到客户端，同时携带授权码</li>
<li>客户端携带重定向uri向授权服务换取token，重定向uri用于比对校验。</li>
<li>授权服务验证通过后，返回token。</li>
</ol>
<ul>
<li>用户代理与客户端之间的交互是通过页面重定向进行传值交互</li>
<li>用户代理与用户资源服务，与授权服务之间交互是通过后端接口调用，这里存在先后顺序，即先校验用户信息，然后将用户标识传递到授权服务，作为后续签发的token里的用户标识。</li>
</ul>
<h1 id="Implicit-Grant"><a href="#Implicit-Grant" class="headerlink" title="Implicit Grant"></a>Implicit Grant</h1><blockquote>
<p>隐式授权。不支持刷新token，和授权码类似，需要支持重定向传递信息，客户端不授信，获取access_token在同一个接口返回，这种方式会将access_token编码在返回参数里，相对授权码来说，安全性会低一点。</p>
</blockquote>
<p>需要支持重定向</p>
<p>交互图如下</p>
<p><img src="https://cdn.nlark.com/yuque/0/2021/png/406465/1610509249943-fe95814e-0ebd-42b2-ac11-06678e539b80.png" alt="image.png" loading="lazy"></p>
<blockquote>
<p>A，B，C表示同一个操作在不同终端的调用情况</p>
</blockquote>
<ol>
<li>客户端引导进入到用户代理端（这个可能是个web，或者app），携带clientid和重定向uri等信息。</li>
<li>当到达用户代理端时（可能是到了授权页，或者打开了一个新app），先请求用户资源服务，验证用户信息，验证通过后，通知授权服务，签发token。</li>
<li>用户代理端请求结束后，通过重定向uri返回token</li>
</ol>
<h1 id="Resource-Owner-Password-Credentials-Grant"><a href="#Resource-Owner-Password-Credentials-Grant" class="headerlink" title="Resource Owner Password Credentials Grant"></a>Resource Owner Password Credentials Grant</h1><blockquote>
<p>账号密码授权认证模式。该方式适用于客户端是授信的，拥有账号密码信息，此时通过传递帐号密码信息，获取到用户标识，且不需要基于重定向传递参数。支持刷新token</p>
</blockquote>
<p>支持刷新token<br>、<br>交互图如下：<br><img src="https://cdn.nlark.com/yuque/0/2021/png/406465/1616317116966-a2a86654-927b-4256-b1d8-6444235f7211.png" alt="image.png" loading="lazy"></p>
<ol>
<li>.客户端向资源所有者申请认证，客户端保存着用户信息</li>
<li>客户端携带者从资源所有者获取的认证信息，请求认证服务器，获取token</li>
<li>客户端获取到token/刷新token</li>
</ol>
<h1 id="Client-Credentials-Grant"><a href="#Client-Credentials-Grant" class="headerlink" title="Client Credentials Grant"></a>Client Credentials Grant</h1><blockquote>
<p>客户端认证。该方式适用于客户端是授信的，且无帐号密码，无需登录标识。不支持刷新token</p>
</blockquote>
<p>交互图如下：<br><img src="https://cdn.nlark.com/yuque/0/2021/png/406465/1616317413222-9485f92b-3345-4d6a-9b21-94931703a179.png" alt="image.png" loading="lazy"></p>
<ol>
<li>直接根据clientid和密钥向认证中心获取token</li>
<li>获取成功</li>
</ol>
]]></content>
      <categories>
        <category>通用知识</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>认证</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础知识</title>
    <url>/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<blockquote>
<p>2015年，jdk8虚拟机规范：<a href="https://docs.oracle.com/javase/specs/jvms/se8/html/index.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/specs/jvms/se8/html/index.html</a></p>
</blockquote>
<h1 id="运行内存区"><a href="#运行内存区" class="headerlink" title="运行内存区"></a>运行内存区</h1><blockquote>
<p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5" target="_blank" rel="noopener">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5</a></p>
</blockquote>
<ul>
<li><p>程序计数器</p>
<ul>
<li>因为java虚拟机需要通过多线程轮流切换，并分配处理器执行时间来实现多线程，在某一个时刻，一个处理器（一般来说也就是一个内核)只会执行一条指令，因此，为了线程切换后能回复到正确的位置，每条线程需要一个独立的程序计数器，各条线程之间互不影响。</li>
<li>【线程私有】</li>
<li>【异常】：这块区域是java中唯一没有规定任何OutOfMemoryError的区域</li>
</ul>
</li>
<li><p>虚拟机栈</p>
<ul>
<li>（也就是通常意义上讲的堆栈中的栈），<strong>生命周期与线程相同</strong>，每个方法在执行的同时创建一个栈帧，方法从调用到执行结束，对应着栈帧入栈到出栈的过程，里面存放着局部变量表，比方说各种基本类型，对象引用（这里这是一个引用，具体的对象信息还是在堆上）。</li>
<li>【线程私有】</li>
<li>【异常】：如果线程请求栈深度大于虚拟机允许的深度，将抛出StoackOverflowError异常，一般无限递归会报这个错。如果虚拟机栈允许动态扩展，但是扩展时无法申请足够的内存，会抛出OutOfMemoryError异常。</li>
</ul>
</li>
<li><p>本地方法栈</p>
<ul>
<li>和虚拟机栈类似，只不过本地方法栈是虚拟机为Native方法准备的。</li>
<li>【线程私有】</li>
<li>【异常】：如果线程请求栈深度大于虚拟机允许的深度，将抛出StoackOverflowError异常，一般无限递归会报这个错。如果虚拟机栈允许动态扩展，但是扩展时无法申请足够的内存，会抛出OutOfMemoryError异常。</li>
</ul>
</li>
<li><p>堆</p>
<ul>
<li>是java虚拟机所管理内存的最大的一块。在虚拟机启动时创建，几乎所有的对象实例都在这里分配内存，在物理上不是不连续的内存中，逻辑上时连续的，</li>
<li>【线程共享】</li>
<li>【异常】：如果堆中没有内存完成实例分配，而且堆无法扩展时，将会抛出OutOfMemoryError异常。</li>
</ul>
</li>
<li><p>方法区</p>
<ul>
<li>各线程共享区域，用于存放虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。这块区域比较模糊，不同的虚拟机实现逻辑不同，有的放在永久代，有的放到Native Memory。</li>
<li><strong>运行时常量池</strong>，是方法区的一部分，存放类的版本，字段，方法等描述信息。</li>
<li>【线程共享】</li>
<li>【异常】，当方法去无法满足内存分配需求，将抛出，OutOfMemoryError异常。</li>
</ul>
</li>
</ul>
<h1 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h1><blockquote>
<p><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-5.html#jvms-5.3" target="_blank" rel="noopener">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-5.html#jvms-5.3</a></p>
</blockquote>
<h1 id="JMM"><a href="#JMM" class="headerlink" title="JMM"></a>JMM</h1><p>Java内存模型，通过特定操作协议，对内存或高速缓存进行读写过程的一种描述。JMM是一种在对线程并发情况下对于共享变量读写的<strong>规范</strong>，屏蔽了不同操作系统的差异，而Jvm内存结构是处于Java虚拟机层面，是运行时对Java进程占用内存的逻辑划分。</p>
<h2 id="结构规范"><a href="#结构规范" class="headerlink" title="结构规范"></a>结构规范</h2><p>所有变量都存储在主内存中，每个线程还有自己的工作内存，线程的工作内存保存了该线程使用的变量的主内存副本，线程对变量的所有操作（读取，赋值等）都必须在工作内存中进行，不能直接读写主内存。不同线程也不能直接访问对方工作内存中的变量，线程之间值的传递都需要通过主内存完成</p>
<h2 id="三个特性"><a href="#三个特性" class="headerlink" title="三个特性"></a>三个特性</h2><ul>
<li>原子性</li>
</ul>
<p>除了64位的long和dubbo，在32位Jvm中，会将64位的数据读写分为2次32位来操作，导致可能不是原子的。（TODO 但大部分操作系统已经支持）</p>
<ul>
<li>可见性</li>
</ul>
<p>一个线程对共享变量做了修改后，其他线程立即能够看到该变量的修改</p>
<ul>
<li>有序性</li>
</ul>
<p>单线程环境下，即使发生指令重拍，所有硬件优化的前提必须遵守as-if-serial语义，但是多线程环境中，因为工作内存与主存同步延迟，或者重排序，会导致可见性问题。</p>
<h2 id="常用概念"><a href="#常用概念" class="headerlink" title="常用概念"></a>常用概念</h2><h3 id="Volatile"><a href="#Volatile" class="headerlink" title="Volatile"></a>Volatile</h3><blockquote>
<p>相关的有happen-before的各种规则，其中比较常用的是volatile，volatile可以保证写入会被另一个线程可见。</p>
</blockquote>
<h3 id="硬件原理"><a href="#硬件原理" class="headerlink" title="硬件原理"></a>硬件原理</h3><p>内存屏障，缓存一致性协议MESI，总线嗅探</p>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ul>
<li>除了使用volatile，还有什么方式可以触发内存屏障（synchronized，unsafe的内存屏障）</li>
<li>volatile修饰的变量，赋值操作是可以保证可见性，但取值赋值操作不能</li>
<li>DCL（dubbo check）时，静态变量需要用volatile修饰，防止初始化时，被指令重排，导致数据不一致<ul>
<li>本质是因为java初始化对象时有3步操作（1. 申请内存空间，2. 初始化变量，3.修改变量指针，指向内存地址）其中，3操作可能会被重排到2操作之前</li>
</ul>
</li>
</ul>
<h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><blockquote>
<p>无特殊说明，默认指1.8版本的HotSpot虚拟机</p>
<p>参考资料：<a href="https://mp.weixin.qq.com/s?__biz=MzIwNDAyOTI2Nw==&amp;mid=2247494932&amp;idx=1&amp;sn=1e0a7a74e947dd03967c36cc3270f8a1&amp;chksm=96c4c128a1b3483e78405fa2b1cf2f2f901b91593c56fc4d6ee086eb1b7c8a27e4d9be1fbf7d&amp;token=2016670857&amp;lang=zh_CN#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzIwNDAyOTI2Nw==&amp;mid=2247494932&amp;idx=1&amp;sn=1e0a7a74e947dd03967c36cc3270f8a1&amp;chksm=96c4c128a1b3483e78405fa2b1cf2f2f901b91593c56fc4d6ee086eb1b7c8a27e4d9be1fbf7d&amp;token=2016670857&amp;lang=zh_CN#rd</a> </p>
<p>查看默认配置</p>
<p>java -XX:+PrintFlagsInitial  -version | grep CMS</p>
<p>查看当前配置</p>
<p>java -XX:+PrintFlagsFinal -version | grep CMS</p>
</blockquote>
<h2 id="相关知识点"><a href="#相关知识点" class="headerlink" title="相关知识点"></a>相关知识点</h2><p>衡量收集器的三项重要指标：内存占用，停顿时间，吞吐量</p>
<blockquote>
<p> 吞吐量 = 运行用户代码时间 / (运行用户代码时间+运行垃圾收集时间)，高吞吐量移位着用户代码执行时间长</p>
</blockquote>
<h3 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h3><ul>
<li>标记清理</li>
</ul>
<p>容易产生内存碎片</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/10.png" alt loading="lazy"></p>
<ul>
<li>复制</li>
</ul>
<p>内存占用较高，不容易产生内存碎片</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/11.png" alt loading="lazy"></p>
<ul>
<li>标记整理</li>
</ul>
<p>标记后，让所有对象向一端移动，再清理边界外区域</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/12.png" alt loading="lazy"></p>
<h3 id="三色标记法"><a href="#三色标记法" class="headerlink" title="三色标记法"></a>三色标记法</h3><p>黑色：表示对象被标记存活，并且该对象所有引用都已经被扫描过。不应该被回收，不会引用任何白色对象</p>
<p>灰色：表示对象被标记存活，但其引用还没有全部被扫描，可能引用白色对象</p>
<p>白色：表示对象尚未被访问，初始所有对象都是白色</p>
<h3 id="卡表"><a href="#卡表" class="headerlink" title="卡表"></a>卡表</h3><blockquote>
<p>针对跨代引用，保存的是一种非收集区（如年轻代）指向收集区（如老年代）</p>
</blockquote>
<p>为了避免年轻代收集时，存在老年代的引用，从而导致高成本扫描老年代。这里使用记忆集存储，用位标记一块特定的内存块，标记内存块内存在跨代引用，成为”脏页”</p>
<h3 id="写屏障"><a href="#写屏障" class="headerlink" title="写屏障"></a>写屏障</h3><p>在对象赋值时，在c++底层，会在更新前后增加类似aop的环绕通知，处理相关逻辑，如卡表，增量更新，原始快照（SATB）等。有的是同步（CMS的增量更新），有的是异步（G1的原始快照）</p>
<h2 id="经典收集器"><a href="#经典收集器" class="headerlink" title="经典收集器"></a>经典收集器</h2><table>
<thead>
<tr>
<th>收集器类型</th>
<th>并行/串行</th>
<th>年轻代/老年代</th>
<th>算法</th>
<th>介绍</th>
</tr>
</thead>
<tbody><tr>
<td>Serial</td>
<td>串行</td>
<td>年轻代</td>
<td>标记复制</td>
<td>简单，无线程交互开销</td>
</tr>
<tr>
<td>Serial Old</td>
<td>串行</td>
<td>老年代</td>
<td>标记整理</td>
<td>同Serial</td>
</tr>
<tr>
<td>ParNew</td>
<td>并行</td>
<td>年轻代</td>
<td>标记复制</td>
<td>搭配CMS</td>
</tr>
<tr>
<td>Parallel Scavenge</td>
<td>并行</td>
<td>年轻代</td>
<td>标记复制</td>
<td>注重吞吐量</td>
</tr>
<tr>
<td>Paralled Old</td>
<td>并行</td>
<td>老年代</td>
<td>标记整理</td>
<td>注重吞吐量或处理器资源稀缺，与Parallel Scavenge搭配</td>
</tr>
</tbody></table>
<h2 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h2><blockquote>
<p>oracle介绍：<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#concurrent_mark_sweep_cms_collector</a></p>
<p>启用Cms收集器</p>
</blockquote>
<p>全称Concurrent Mark Sweep，1.4推出，在1.9标记弃用，14版本正式弃用，与ParNewGC（清理年轻代）配套使用。CMS是一种以获取最短回收停顿时间为目标的收集器。</p>
<p>CMS及之前的收集器对内存的划分</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/14.png" alt loading="lazy"></p>
<ul>
<li>整体过程</li>
</ul>
<ol>
<li>初始标记（STW）。标记GC Root直接关联的对象；</li>
<li>并发标记。与用户线程并行，开始遍历GC Root对象；</li>
<li>重新标记（STW）。修正并发标记期间产生变动的记录（利用增量更新）；</li>
<li>并发清理。与用户线程并发</li>
<li>重置。准备下一轮收集</li>
</ol>
<ul>
<li><p>优势</p>
<ul>
<li>停顿时间短</li>
</ul>
</li>
<li><p>带来的问题</p>
<ul>
<li>对处理器资源敏感，需要消耗处理器算力</li>
<li>由于并行标记，有浮动垃圾，所以老年代需要预留空间，会有浪费空间的情况</li>
<li>为了避免浪费空间，可能导致预留空间过少，触发”并发失败”，因此会执行后备预案，采用”Serial Old”进行老年代清理</li>
<li>标记清理，可能存在内存碎片，因此，CMS不得不在FullGc时，执行内存合并，增大停顿时长</li>
</ul>
</li>
</ul>
<h2 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h2><blockquote>
<p> oracle介绍：<a href="https://www.oracle.com/technetwork/tutorials/tutorials-1876574.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/tutorials/tutorials-1876574.html</a> </p>
</blockquote>
<p>全称Garbage-First，1.7推出，开创了面向局部收集和基于Region的内存布局形式。面向大内存多核，期望建立 “停顿预测模型”的收集器，旨在能够支持指定在长度微M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒的目标。</p>
<p>内存分配模型：</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/13.png" alt loading="lazy"></p>
<blockquote>
<p>内存被划分为相等大小的内存区，每个块有着自己的功能，但年轻代/老年代并没有固定的大小，更灵活。”化整为零”的思想。</p>
</blockquote>
<ul>
<li>整体过程</li>
</ul>
<ol>
<li>初始标记（STW）。标记GC Root可达的对象</li>
<li>并发标记。与用户线程并发扫描</li>
<li>重标记（STW），完成SATB记录</li>
<li>清理复制（STW），标记存活对象，完成空闲区分配，擦出记忆表，根据预期停顿时间指定回收计划，并将存活对象移动到新区域，然后清除旧空间</li>
</ol>
<ul>
<li>优势<ul>
<li>针对多个区而言，是标记复制，内存碎片少</li>
<li>按收益动态确定回收集，利于程序长时间运行</li>
</ul>
</li>
<li>带来的问题<ul>
<li>内存占用较高（比如记忆集）</li>
<li>小内存的情况下，写屏障等内部算法复杂，对用户线程负载较高（经验值，6G-8G使用G1</li>
</ul>
</li>
</ul>
<h2 id="其他收集器"><a href="#其他收集器" class="headerlink" title="其他收集器"></a>其他收集器</h2><ul>
<li>Shenandoah收集器<ul>
<li>号称G1的下一代</li>
<li>非oracle研发</li>
</ul>
</li>
<li>ZGC收集器<ul>
<li>染色指针</li>
<li>无跨代概念</li>
<li>停顿时间在几十毫秒</li>
</ul>
</li>
</ul>
<h1 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a>Synchronized</h1><p>使用姿势：a)方法块，b)代码块</p>
<p>在Object上提供了wait/notify/norifyAll，将Object当做监视器，所以每个对象都可以是一把锁</p>
<p>Object都有一个监视器，对象监视器</p>
<ul>
<li>非公平的，当都在申请锁时，最后一个会优先获取到锁</li>
<li>重量级锁，由于会造成用户态到内核态的切换（CAS是用户态操作）</li>
<li>轻量级锁，偏向锁，失败后会膨胀到重量锁</li>
<li>锁状态和标记存储在对象头里</li>
<li>由于有延迟偏向（4s），不是所有对象立刻会开启偏向锁状态</li>
</ul>
<h2 id="MarkWord"><a href="#MarkWord" class="headerlink" title="MarkWord"></a>MarkWord</h2><ul>
<li>Java对象结构如下</li>
</ul>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/4.png" alt loading="lazy"></p>
<p>可以通过代码查看对象空间，需要引入</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.openjdk.jol<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jol-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.out.println(ClassLayout.parseInstance(lock).toPrintable());</span><br></pre></td></tr></table></figure>

<p>在64位虚拟机默认配置下（开启指针压缩），一个普通的对象内存结构如下（对象头8字节，类指针4字节）</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/3.png" alt loading="lazy"></p>
<ul>
<li>MarkWord</li>
</ul>
<blockquote>
<p>markWord结构，hotspot源码位置markOop.hpp</p>
<p><a href="https://hg.openjdk.org/jdk8u/jdk8u/hotspot/file/69087d08d473/src/share/vm/oops/markOop.hpp" target="_blank" rel="noopener">https://hg.openjdk.org/jdk8u/jdk8u/hotspot/file/69087d08d473/src/share/vm/oops/markOop.hpp</a></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Bit-format of an object header (most significant first, big endian layout below):</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  32 bits:</span></span><br><span class="line"><span class="comment">//  --------</span></span><br><span class="line"><span class="comment">//             hash:25 ------------&gt;| age:4    biased_lock:1 lock:2 (normal object)</span></span><br><span class="line"><span class="comment">//             JavaThread*:23 epoch:2 age:4    biased_lock:1 lock:2 (biased object)</span></span><br><span class="line"><span class="comment">//             size:32 ------------------------------------------&gt;| (CMS free block)</span></span><br><span class="line"><span class="comment">//             PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  64 bits:</span></span><br><span class="line"><span class="comment">//  --------</span></span><br><span class="line"><span class="comment">//  unused:25 hash:31 --&gt;| unused:1   age:4    biased_lock:1 lock:2 (normal object)</span></span><br><span class="line"><span class="comment">//  JavaThread*:54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased object)</span></span><br><span class="line"><span class="comment">//  PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)</span></span><br><span class="line"><span class="comment">//  size:64 -----------------------------------------------------&gt;| (CMS free block)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  unused:25 hash:31 --&gt;| cms_free:1 age:4    biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)</span></span><br><span class="line"><span class="comment">//  JavaThread*:54 epoch:2 cms_free:1 age:4    biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)</span></span><br><span class="line"><span class="comment">//  narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)</span></span><br><span class="line"><span class="comment">//  unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block)</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>以64位举例</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/1.png" alt loading="lazy"></p>
<h2 id="常见问题-1"><a href="#常见问题-1" class="headerlink" title="常见问题"></a>常见问题</h2><ul>
<li>如果调用了hashCode，则不能启用偏向锁，因为没有56bit存放了线程ID，没地方放hashCode，hashCode会存在线程栈帧中</li>
<li>偏向锁轻微竞争时，会升级为轻量级锁。当要升级为重量锁时，偏向锁会撤销为无锁状态，再进入下一阶段</li>
</ul>
<h1 id="JUC"><a href="#JUC" class="headerlink" title="JUC"></a>JUC</h1><blockquote>
<p>java.util.concurrent包</p>
<p>下面主要有3类，atomic，locks，同步工具，线程池等</p>
<p>参考文献A：<a href="https://segmentfault.com/a/1190000015558984" target="_blank" rel="noopener">https://segmentfault.com/a/1190000015558984</a> </p>
</blockquote>
<h2 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h2><p>当前主要使用MESA模型的管程模型，以下是典型的管程模型，主要元素包括</p>
<ol>
<li>共享变量（互斥量）</li>
<li>入口等待队列（去获取锁）</li>
<li>条件队列</li>
<li>阻塞唤醒机制（阻塞后进入条件队列，唤醒后进入同步等待队列）</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//条件队列/等待队列的队列节点</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>  </span>&#123;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//1. 共享变量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state;</span><br><span class="line"><span class="comment">//2. 等待队列的头节点</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> Node head;</span><br><span class="line"><span class="comment">//2. 等待队列的尾节点</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">volatile</span> Node tail;</span><br><span class="line"></span><br><span class="line"><span class="comment">//内部类</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConditionObject</span> <span class="keyword">implements</span> <span class="title">Condition</span></span>&#123;</span><br><span class="line">  <span class="comment">//3. 第一个条件队列</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">transient</span> Node firstWaiter;</span><br><span class="line">  <span class="comment">//3. 最后一个条件队列</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">transient</span> Node lastWaiter;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//4. 阻塞</span></span><br><span class="line">LockSupport.park(threadA)</span><br><span class="line"></span><br><span class="line"><span class="comment">//4. 唤醒</span></span><br><span class="line">LockSupport.unpark(threadA);</span><br></pre></td></tr></table></figure>



<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/2.png" alt loading="lazy"></p>
<blockquote>
<p>上文提到的Synchronized是jvm层面提供的管程实现，只有一个条件变量，ObjectMonitor（重量级锁），但由于需要上下文切换（重量级锁时），性能不好，且粒度较粗，无法自定义解锁，非公平。为此，juc包下，提供了AQS，全称：AbstractQueuedSynchronizer</p>
</blockquote>
<h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ul>
<li>阻塞等待队列</li>
<li>共享/独占</li>
<li>公平/非公平</li>
<li>可重入</li>
<li>允许中断</li>
</ul>
<h2 id="基础锁（Lock）"><a href="#基础锁（Lock）" class="headerlink" title="基础锁（Lock）"></a>基础锁（Lock）</h2><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><blockquote>
<p>典型的AQS锁实现</p>
</blockquote>
<ul>
<li>特点<ul>
<li>公平/非公平</li>
<li>可重入</li>
<li>多条件变量</li>
<li>可设置超时时间</li>
<li>可中断</li>
</ul>
</li>
<li>与Synchronized区别<ul>
<li>synchronized是jvm层面，ReentrantLock是jdk层面</li>
<li>synchronized的锁状态无法在代码中判断，ReentrantLock可以通过java.util.concurrent.locks.ReentrantLock#isLocked判断</li>
</ul>
</li>
</ul>
<h4 id="使用姿势"><a href="#使用姿势" class="headerlink" title="使用姿势"></a>使用姿势</h4><ul>
<li>公平锁</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ReentrantLock lock = <span class="keyword">new</span> ReentrantLock(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                        lock.lock();</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            System.out.println(Thread.currentThread().getName() + <span class="string">"\t锁到了"</span>);</span><br><span class="line">                        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                            lock.unlock();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t1.setName(<span class="string">"Thread"</span> + i);</span><br><span class="line">            t1.start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">        System.out.println(<span class="string">"主线程"</span>);</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line">Thread0	锁到了</span><br><span class="line">Thread3	锁到了</span><br><span class="line">Thread1	锁到了</span><br><span class="line">Thread2	锁到了</span><br><span class="line">Thread4	锁到了</span><br><span class="line">Thread0	锁到了</span><br><span class="line">Thread3	锁到了</span><br><span class="line">Thread1	锁到了</span><br><span class="line">Thread2	锁到了</span><br><span class="line">Thread4	锁到了</span><br><span class="line">Thread0	锁到了</span><br><span class="line">Thread3	锁到了</span><br></pre></td></tr></table></figure>

<ul>
<li>条件队列</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">        Condition c1 = lock.newCondition();</span><br><span class="line"></span><br><span class="line">        Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                lock.lock();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        System.out.println(Thread.currentThread().getName()+<span class="string">"\t开始等待"</span>);</span><br><span class="line">                        c1.await();</span><br><span class="line">                        System.out.println(Thread.currentThread().getName()+<span class="string">"\t执行啦"</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        System.out.println(<span class="string">"中断了"</span>);</span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    lock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        t1.start();</span><br><span class="line">        Thread t2= <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                lock.lock();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        System.out.println(Thread.currentThread().getName()+<span class="string">"\t开始等待"</span>);</span><br><span class="line">                        c1.await();</span><br><span class="line">                        System.out.println(Thread.currentThread().getName()+<span class="string">"\t执行啦"</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        System.out.println(<span class="string">"中断了"</span>);</span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    lock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        t2.start();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"休息3秒钟"</span>);</span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line"></span><br><span class="line">        Thread t3 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                lock.lock();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    System.out.println(<span class="string">"\t释放"</span>);</span><br><span class="line">                    c1.signal();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    lock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                &#125;</span><br><span class="line">                lock.lock();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    System.out.println(<span class="string">"\t再释放一个"</span>);</span><br><span class="line">                    c1.signal();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    lock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        t3.start();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        t1.join();</span><br><span class="line">        t2.join();</span><br><span class="line">        System.out.println(<span class="string">"主线程"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line">Thread-<span class="number">0</span>	开始等待</span><br><span class="line">休息<span class="number">3</span>秒钟</span><br><span class="line">Thread-<span class="number">1</span>	开始等待</span><br><span class="line">	释放</span><br><span class="line">Thread-<span class="number">0</span>	执行啦</span><br><span class="line">	再释放一个</span><br><span class="line">Thread-<span class="number">1</span>	执行啦</span><br><span class="line">主线程</span><br></pre></td></tr></table></figure>

<h4 id="原理小结"><a href="#原理小结" class="headerlink" title="原理小结"></a>原理小结</h4><p>线程利用CAS判断state，尝试加锁，加锁成功后，设置独占属性。其他线程加锁失败，尾插法后加入等待队列，调用park等待。解锁时，更新state=0。公平是针对加锁时，不尝试CAS判断，立刻加入等待队列</p>
<h3 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h3><blockquote>
<p>AQS实现，可重入读写锁，读读共享。读写，写读，写写互斥</p>
</blockquote>
<ul>
<li><p>特点</p>
<ul>
<li>可重入</li>
<li>公平/非公平</li>
<li>读取多余写的情况下，可能造成写饥饿</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-1"><a href="#使用姿势-1" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private final Map&lt;String, Integer&gt; m &#x3D; new TreeMap&lt;String, Integer&gt;();</span><br><span class="line">    private final ReentrantReadWriteLock rwl &#x3D; new ReentrantReadWriteLock();</span><br><span class="line">    private final ReentrantReadWriteLock.ReadLock r &#x3D; rwl.readLock();</span><br><span class="line">    private final ReentrantReadWriteLock.WriteLock w &#x3D; rwl.writeLock();</span><br><span class="line"></span><br><span class="line">    public Integer get(String key) &#123;</span><br><span class="line">        r.lock();</span><br><span class="line">        try &#123;</span><br><span class="line">            return m.get(key);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            r.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public Integer put(String key, Integer value) &#123;</span><br><span class="line">        w.lock();</span><br><span class="line">        try &#123;</span><br><span class="line">            return m.put(key, value);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            w.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h4 id="原理小结-1"><a href="#原理小结-1" class="headerlink" title="原理小结"></a>原理小结</h4><p>利用state的前后16位移位来区分共享读，独占写，高16位读，低16位写。高16位只记录重入次数，每个线程重入次数由ThreadLocal里面保存</p>
<h3 id="StampedLock"><a href="#StampedLock" class="headerlink" title="StampedLock"></a>StampedLock</h3><blockquote>
<p>邮戳锁，1.8版本，基于版本号的读写锁，没有基于AQS，但原理类似，ReentrantReadWriteLock读写存在写饥饿（即多个线程读取，会导致写长时间无法获取锁），StampedLock利用版本号，可根据版本号走乐观读，减少加锁次数。</p>
</blockquote>
<ul>
<li><p>特点</p>
<ul>
<li>不可重入</li>
<li>不基于AQS实现</li>
<li>不支持条件变量</li>
<li>不支持公平/非公平</li>
<li>有3种模式，其中乐观读不会阻塞写</li>
<li>读写加锁后会返回邮戳（版本号），利用邮戳解锁</li>
<li>读写锁相互升级</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-2"><a href="#使用姿势-2" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private double x, y;</span><br><span class="line">    private final StampedLock sl &#x3D; new StampedLock();</span><br><span class="line"></span><br><span class="line">    void move(double deltaX, double deltaY) &#123;</span><br><span class="line">        &#x2F;&#x2F;写加锁</span><br><span class="line">        long stamp &#x3D; sl.writeLock();</span><br><span class="line">        try &#123;</span><br><span class="line">            x +&#x3D; deltaX;</span><br><span class="line">            y +&#x3D; deltaY;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            sl.unlockWrite(stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double distanceFromOrigin() &#123;</span><br><span class="line">        &#x2F;&#x2F;乐观读锁</span><br><span class="line">        long stamp &#x3D; sl.tryOptimisticRead();</span><br><span class="line">        double currentX &#x3D; x, currentY &#x3D; y;</span><br><span class="line">        if (!sl.validate(stamp)) &#123;</span><br><span class="line">            &#x2F;&#x2F;发现读取完被修改，则改为读加锁</span><br><span class="line">            stamp &#x3D; sl.readLock();</span><br><span class="line">            try &#123;</span><br><span class="line">                &#x2F;&#x2F;加锁读取</span><br><span class="line">                currentX &#x3D; x;</span><br><span class="line">                currentY &#x3D; y;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                sl.unlockRead(stamp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return Math.sqrt(currentX * currentX + currentY * currentY);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    double read() &#123;</span><br><span class="line">        long stamp &#x3D; sl.readLock();</span><br><span class="line">        try &#123;</span><br><span class="line">            &#x2F;&#x2F;加锁读取</span><br><span class="line">            double currentX &#x3D; x;</span><br><span class="line">            double currentY &#x3D; y;</span><br><span class="line">            return Math.sqrt(currentX * currentX + currentY * currentY);</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            sl.unlockRead(stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void moveIfAtOrigin(double newX, double newY) &#123; </span><br><span class="line">        &#x2F;&#x2F; 锁升级，从读锁升级到写锁</span><br><span class="line">        long stamp &#x3D; sl.readLock();</span><br><span class="line">        try &#123;</span><br><span class="line">            while (x &#x3D;&#x3D; 0.0 &amp;&amp; y &#x3D;&#x3D; 0.0) &#123;</span><br><span class="line">                long ws &#x3D; sl.tryConvertToWriteLock(stamp);</span><br><span class="line">                if (ws !&#x3D; 0L) &#123;</span><br><span class="line">                    stamp &#x3D; ws;</span><br><span class="line">                    x &#x3D; newX;</span><br><span class="line">                    y &#x3D; newY;</span><br><span class="line">                    break;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    sl.unlockRead(stamp);</span><br><span class="line">                    stamp &#x3D; sl.writeLock();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            sl.unlock(stamp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        StampedLockTest test &#x3D; new StampedLockTest();</span><br><span class="line"></span><br><span class="line">       CountDownLatch countDownLatch &#x3D; new CountDownLatch(25);</span><br><span class="line"></span><br><span class="line">        AtomicLong writeTime &#x3D; new AtomicLong();</span><br><span class="line">        AtomicLong readTime &#x3D; new AtomicLong();</span><br><span class="line">        for (int i &#x3D; 0; i &lt; 20; i++) &#123;</span><br><span class="line">            Thread t2 &#x3D; new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    int k &#x3D; 0;</span><br><span class="line">                    long sumTime &#x3D; 0;</span><br><span class="line">                    while (k &lt; 200) &#123;</span><br><span class="line">                        randomSleep();</span><br><span class="line">                        long start &#x3D; System.currentTimeMillis();</span><br><span class="line">                        &#x2F;&#x2F;使用乐观读</span><br><span class="line">&#x2F;&#x2F;                        test.distanceFromOrigin();</span><br><span class="line">                        &#x2F;&#x2F;使用悲观读</span><br><span class="line">                        test.read();</span><br><span class="line">                        long l &#x3D; System.currentTimeMillis();</span><br><span class="line">                        if ((l - start) &gt; 0) &#123;</span><br><span class="line">                            sumTime +&#x3D; (l - start);</span><br><span class="line">                        &#125;</span><br><span class="line">                        k++;</span><br><span class="line">                    &#125;</span><br><span class="line">                    readTime.addAndGet(sumTime);</span><br><span class="line">                    countDownLatch.countDown();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t2.start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; 5; i++) &#123;</span><br><span class="line">            Thread t1 &#x3D; new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    int k &#x3D; 0;</span><br><span class="line">                    long sumTime &#x3D; 0;</span><br><span class="line">                    while (k &lt; 200) &#123;</span><br><span class="line">                        randomSleep();</span><br><span class="line">                        long start &#x3D; System.currentTimeMillis();</span><br><span class="line">                        &#x2F;&#x2F;写</span><br><span class="line">                        test.move(1, 1);</span><br><span class="line">                        long l &#x3D; System.currentTimeMillis();</span><br><span class="line">                        if ((l - start) &gt; 0) &#123;</span><br><span class="line">                            sumTime +&#x3D; (l - start);</span><br><span class="line">                        &#125;</span><br><span class="line">                        k++;</span><br><span class="line">                    &#125;</span><br><span class="line">                    writeTime.addAndGet(sumTime);</span><br><span class="line">                    countDownLatch.countDown();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t1.start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        countDownLatch.await();</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;运行完成，读\t&quot;+readTime.get()+&quot;\t写\t&quot;+writeTime.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void randomSleep() throws InterruptedException &#123;</span><br><span class="line">        Random random &#x3D; new Random();</span><br><span class="line">        int i &#x3D; random.nextInt(5);</span><br><span class="line">        Thread.sleep(i * 10);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h4 id="原理小结-2"><a href="#原理小结-2" class="headerlink" title="原理小结"></a>原理小结</h4><p>本质上读取并没有加锁，读加锁时，前一个如果也是读节点，会加入读节点的cowait字段，采用头插法。因此被唤醒的是最后插入的节点。唤醒时同理，如果是读节点，会将cowait的栈都唤醒</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><h4 id="常见问题-2"><a href="#常见问题-2" class="headerlink" title="常见问题"></a>常见问题</h4><p>公平：加锁时，如果有等待队列，是否要乖乖排队。唤醒时都是固定逻辑，大部分是从等待队列队首开始唤醒</p>
<p>可重入：当线程再次加锁时，是否能够正常进入，可重入表示当前线程可以再次加锁成功</p>
<p>共享锁：共享变量能够有多个线程来加锁，例如ReentrantReadWriteLock的读锁</p>
<h4 id="简单对比"><a href="#简单对比" class="headerlink" title="简单对比"></a>简单对比</h4><table>
<thead>
<tr>
<th></th>
<th>AQS</th>
<th>ReentrantLock</th>
<th>ReentrantReadWriteLock</th>
<th>StampedLock</th>
</tr>
</thead>
<tbody><tr>
<td>条件变量</td>
<td></td>
<td>✓</td>
<td>✓</td>
<td></td>
</tr>
<tr>
<td>公平</td>
<td></td>
<td>✓</td>
<td>✓</td>
<td></td>
</tr>
<tr>
<td>共享变量（独占）</td>
<td></td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>共享变量（共享）</td>
<td></td>
<td></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>锁超时</td>
<td></td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>可重入</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td></td>
</tr>
<tr>
<td>读读共享</td>
<td></td>
<td></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td>乐观读</td>
<td></td>
<td></td>
<td></td>
<td>✓</td>
</tr>
</tbody></table>
<h2 id="同步工具"><a href="#同步工具" class="headerlink" title="同步工具"></a>同步工具</h2><h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><blockquote>
<p>同步工具类，信号量，主要用于单机限流，基于AQS</p>
</blockquote>
<ul>
<li>特点<ul>
<li>公平/非公平</li>
<li>可重入</li>
<li>可设置超时时间</li>
<li>可中断</li>
<li>共享变量获取资源-1（利用AQS的state）</li>
<li>唤醒</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-3"><a href="#使用姿势-3" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Semaphore semaphore = <span class="keyword">new</span> Semaphore(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">           Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">               <span class="meta">@Override</span></span><br><span class="line">               <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                   semaphore.acquireUninterruptibly();</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                       Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                       <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                   &#125;</span><br><span class="line">                   System.out.println(Thread.currentThread().getName() + <span class="string">"\t执行啦"</span>);</span><br><span class="line">                   semaphore.release();</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;);</span><br><span class="line">           t1.start();</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>

<h4 id="原理小结-3"><a href="#原理小结-3" class="headerlink" title="原理小结"></a>原理小结</h4><p>利用AQS的state实现共享锁，获取和释放资源时，利用CAS修改变量，共享模式时，当之前阻塞被唤醒后，当前线程准备执行前，会把当前节点移除，并传播唤醒后继节点，然后回到业务线程。</p>
<h3 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h3><blockquote>
<p>闭锁，基于AQS</p>
</blockquote>
<ul>
<li>特点<ul>
<li>非公平</li>
<li>可设置超时时间</li>
<li>可中断</li>
<li>共享变量（利用AQS的state）</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-4"><a href="#使用姿势-4" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">int</span> numThreads = <span class="number">5</span>;</span><br><span class="line">        CountDownLatch latch = <span class="keyword">new</span> CountDownLatch(numThreads);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numThreads; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">" 运行"</span>);</span><br><span class="line">                latch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        latch.await();</span><br><span class="line">        System.out.println(<span class="string">"全部运行完成"</span>);	</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment">//</span></span><br><span class="line">Thread-<span class="number">0</span> 运行</span><br><span class="line">Thread-<span class="number">2</span> 运行</span><br><span class="line">Thread-<span class="number">1</span> 运行</span><br><span class="line">Thread-<span class="number">4</span> 运行</span><br><span class="line">Thread-<span class="number">3</span> 运行</span><br><span class="line">全部运行完成</span><br></pre></td></tr></table></figure>

<h4 id="原理小结-4"><a href="#原理小结-4" class="headerlink" title="原理小结"></a>原理小结</h4><p>利用State记录闭锁的资源数，加锁解锁时，都按照固定逻辑操作资源数，释放掉所有资源后，加锁方法（await）才能顺利操作。和join类似，但join是循环判断线程是否存活，相比之下，CountDownLatch比较灵活，避免死锁。</p>
<h3 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h3><blockquote>
<p>循环栅栏，基于ReentrantLock和Condition</p>
</blockquote>
<ul>
<li>特点<ul>
<li>非公平</li>
<li>可设置超时时间</li>
<li>可中断</li>
<li>可重复达到条件</li>
<li>可设置达到条件时触发的异步方法</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-5"><a href="#使用姿势-5" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CyclicBarrier cyclicBarrier = <span class="keyword">new</span> CyclicBarrier(<span class="number">3</span>, <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">"达到一次啦"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">6</span>; i++) &#123;</span><br><span class="line">            Thread t = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        cyclicBarrier.await();</span><br><span class="line">                        System.out.println(Thread.currentThread().getName() + <span class="string">"\t开始运行"</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (BrokenBarrierException e) &#123;</span><br><span class="line">                        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t.start();</span><br><span class="line">            <span class="keyword">if</span>(i%<span class="number">3</span>==<span class="number">0</span>)&#123;</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line">达到一次啦</span><br><span class="line">Thread-<span class="number">2</span>	开始运行</span><br><span class="line">Thread-<span class="number">1</span>	开始运行</span><br><span class="line">Thread-<span class="number">0</span>	开始运行</span><br><span class="line">达到一次啦</span><br><span class="line">Thread-<span class="number">5</span>	开始运行</span><br><span class="line">Thread-<span class="number">3</span>	开始运行</span><br><span class="line">Thread-<span class="number">4</span>	开始运行</span><br></pre></td></tr></table></figure>

<h4 id="原理小结-5"><a href="#原理小结-5" class="headerlink" title="原理小结"></a>原理小结</h4><p>（假设3个变量，Thread0，Thread1）await()方法内部会先通过ReentrantLock加锁，然后进入dowait方法，dowait方法内部调用Condition的await方法，将当前线程加入条件队列尾部，同时释放锁，然后阻塞线程。当有多个线程进入条件队列，且满足数量后。最后那个线程（Thread2）会在dowait方法内部，触发Condition的signalAll，将这个线程从条件队列中，转移到同步队列（从头部开始转），在Thread的unlock方法时，会唤醒下一个线程</p>
<h3 id="Exchanger"><a href="#Exchanger" class="headerlink" title="Exchanger"></a>Exchanger</h3><blockquote>
<p>交换器</p>
</blockquote>
<ul>
<li>特点<ul>
<li>用于两个线程之间交换数据</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-6"><a href="#使用姿势-6" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">        Exchanger&lt;Message&gt; exchanger &#x3D; new Exchanger&lt;&gt;();</span><br><span class="line">        Thread t1 &#x3D; new Thread(new Consumer(exchanger), &quot;消费者-t1&quot;);</span><br><span class="line">        Thread t2 &#x3D; new Thread(new Producer(exchanger), &quot;生产者-t2&quot;);</span><br><span class="line"></span><br><span class="line">        t1.start();</span><br><span class="line">        t2.start();</span><br><span class="line">        System.out.println();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Producer implements Runnable &#123;</span><br><span class="line">        private final Exchanger&lt;Message&gt; exchanger;</span><br><span class="line"></span><br><span class="line">        public Producer(Exchanger&lt;Message&gt; exchanger) &#123;</span><br><span class="line">            this.exchanger &#x3D; exchanger;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            Message message &#x3D; new Message();</span><br><span class="line">            for (int i &#x3D; 0; i &lt; 3; i++) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(1000);</span><br><span class="line"></span><br><span class="line">                    message.setCall(String.valueOf(i));</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + &quot;: 生产了数据[&quot; + i + &quot;]&quot;);</span><br><span class="line">                    message &#x3D; exchanger.exchange(message);</span><br><span class="line"></span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + &quot;: 交换得到数据[&quot; + message.getBack() + &quot;]&quot;);</span><br><span class="line"></span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Consumer implements Runnable &#123;</span><br><span class="line">        private final Exchanger&lt;Message&gt; exchanger;</span><br><span class="line"></span><br><span class="line">        public Consumer(Exchanger&lt;Message&gt; exchanger) &#123;</span><br><span class="line">            this.exchanger &#x3D; exchanger;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            Message msg &#x3D; new Message();</span><br><span class="line">            while (true) &#123;</span><br><span class="line">                try &#123;</span><br><span class="line">                    Thread.sleep(1000);</span><br><span class="line">                    msg &#x3D; exchanger.exchange(msg);</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + &quot;: 消费了数据[&quot; + msg.getCall() + &quot;]&quot;);</span><br><span class="line">                    msg.setBack(&quot;back&quot;);</span><br><span class="line">                &#125; catch (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Message &#123;</span><br><span class="line">        String call;</span><br><span class="line">        String back;</span><br><span class="line"></span><br><span class="line">        public String getCall() &#123;</span><br><span class="line">            return call;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setCall(String call) &#123;</span><br><span class="line">            this.call &#x3D; call;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public String getBack() &#123;</span><br><span class="line">            return back;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setBack(String back) &#123;</span><br><span class="line">            this.back &#x3D; back;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;输出</span><br><span class="line">生产者-t2: 生产了数据[0]</span><br><span class="line">生产者-t2: 交换得到数据[null]</span><br><span class="line">消费者-t1: 消费了数据[0]</span><br><span class="line">生产者-t2: 生产了数据[1]</span><br><span class="line">消费者-t1: 消费了数据[1]</span><br><span class="line">生产者-t2: 交换得到数据[back]</span><br><span class="line">生产者-t2: 生产了数据[2]</span><br><span class="line">生产者-t2: 交换得到数据[back]</span><br><span class="line">消费者-t1: 消费了数据[2]</span><br></pre></td></tr></table></figure>

<h4 id="原理小结-6"><a href="#原理小结-6" class="headerlink" title="原理小结"></a>原理小结</h4><p>单槽交换比较简单，消费者线程先进来时，会通过CAS占用slot字段，并自旋一段时间（尽量少阻塞）后，进入阻塞阶段，当生产者线程进来后，会将slot置空，并把数据放在node对象的match字段里，唤醒消费者线程。</p>
<p>多槽交换类似，不过略微复杂，当CPU核数&gt;1或多槽竞争失败时，会升级为多槽交换</p>
<h3 id="Phaser"><a href="#Phaser" class="headerlink" title="Phaser"></a>Phaser</h3><blockquote>
<p>阶段拦截，1.7版本新增的同步工具类，相比CountDownLatch和CyclicBarrier，Phaser可以中途阶段升级。</p>
</blockquote>
<h4 id="使用姿势-7"><a href="#使用姿势-7" class="headerlink" title="使用姿势"></a>使用姿势</h4><p>模拟countDownLatch示例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">        final Phaser phaser &#x3D; new Phaser();</span><br><span class="line">&#x2F;&#x2F;        final Phaser phaser &#x3D; new Phaser(1); &#x2F;&#x2F; &quot;1&quot; to register self</span><br><span class="line">        List&lt;Runnable&gt; tasks &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">        for (int i &#x3D; 0; i &lt; 5; i++) &#123;</span><br><span class="line">            phaser.register();</span><br><span class="line">            int finalI &#x3D; i;</span><br><span class="line">            Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    System.out.println(&quot;输出&quot;+ finalI);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">            tasks.add(runnable);</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; create and start threads</span><br><span class="line">        for (final Runnable task : tasks) &#123;</span><br><span class="line">            new Thread(() -&gt; &#123;</span><br><span class="line">                phaser.arriveAndAwaitAdvance(); &#x2F;&#x2F; await all creation</span><br><span class="line">                task.run();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;        phaser.arriveAndDeregister();   &#x2F;&#x2F;相当于协调者，到达后直接开始</span><br><span class="line">        System.out.println(&quot;输出完成&quot;);</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">&#x2F;&#x2F;输出</span><br><span class="line">输出完成</span><br><span class="line">输出0</span><br><span class="line">输出2</span><br><span class="line">输出4</span><br><span class="line">输出1</span><br><span class="line">输出3</span><br></pre></td></tr></table></figure>

<p>循环到达阶段示例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">        List&lt;Runnable&gt; tasks &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">        for (int i &#x3D; 0; i &lt; 5; i++) &#123;</span><br><span class="line">            int finalI &#x3D; i;</span><br><span class="line">            Runnable runnable &#x3D; new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    System.out.println(&quot;输出&quot; + finalI);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">            tasks.add(runnable);</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F;阶段向前提前3次。一共执行4次</span><br><span class="line">        final int iterations &#x3D; 3;</span><br><span class="line"></span><br><span class="line">        final Phaser phaser &#x3D; new Phaser() &#123;</span><br><span class="line">            protected boolean onAdvance(int phase, int registeredParties) &#123;</span><br><span class="line">                System.out.println(&quot;onAdvance\t&quot;+phase);</span><br><span class="line">                return phase &gt;&#x3D; iterations || registeredParties &#x3D;&#x3D; 0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        phaser.register();</span><br><span class="line">        for (final Runnable task : tasks) &#123;</span><br><span class="line">            phaser.register();</span><br><span class="line">            new Thread() &#123;</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    do &#123;</span><br><span class="line">                        task.run();</span><br><span class="line">                        phaser.arriveAndAwaitAdvance();</span><br><span class="line">                    &#125; while (!phaser.isTerminated());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;.start();</span><br><span class="line">        &#125;</span><br><span class="line">        phaser.arriveAndDeregister(); &#x2F;&#x2F; deregister self, don&#39;t wait</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;输出</span><br><span class="line">输出0</span><br><span class="line">输出2</span><br><span class="line">输出1</span><br><span class="line">输出3</span><br><span class="line">输出4</span><br><span class="line">onAdvance	0</span><br><span class="line">输出4</span><br><span class="line">输出3</span><br><span class="line">输出0</span><br><span class="line">输出2</span><br><span class="line">输出1</span><br><span class="line">onAdvance	1</span><br><span class="line">输出1</span><br><span class="line">输出4</span><br><span class="line">输出2</span><br><span class="line">输出0</span><br><span class="line">输出3</span><br><span class="line">onAdvance	2</span><br><span class="line">输出3</span><br><span class="line">输出4</span><br><span class="line">输出1</span><br><span class="line">输出2</span><br><span class="line">输出0</span><br><span class="line">onAdvance	3</span><br></pre></td></tr></table></figure>

<p>分层阶段示例，当达到下一层阶段时，触发上一层（parent）阶段跨越，每个phaser对应最多4个线程，超出部分则会创建下一个阶段，并且保持当所有线程（10个）都执行完成，才会跃迁（advance）到下一个阶段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static final int TASKS_PER_PHASER &#x3D; 4;      &#x2F;&#x2F; 每个Phaser对象对应的工作线程（任务）数</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">        int repeats &#x3D; 3;    &#x2F;&#x2F; 指定任务最多执行的次数</span><br><span class="line">        Phaser phaser &#x3D; new Phaser() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            protected boolean onAdvance(int phase, int registeredParties) &#123;</span><br><span class="line">                System.out.println(&quot;---------------PHASE[&quot; + phase + &quot;],Parties[&quot; + registeredParties + &quot;] ---------------&quot;);</span><br><span class="line">                return phase + 1 &gt;&#x3D; repeats || registeredParties &#x3D;&#x3D; 0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        Tasker[] taskers &#x3D; new Tasker[10];</span><br><span class="line">        build(taskers, 0, taskers.length, phaser);       &#x2F;&#x2F; 根据任务数,为每个任务分配Phaser对象</span><br><span class="line"></span><br><span class="line">        for (int i &#x3D; 0; i &lt; taskers.length; i++) &#123;          &#x2F;&#x2F; 执行任务</span><br><span class="line">            Thread thread &#x3D; new Thread(taskers[i]);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static void build(Tasker[] taskers, int lo, int hi, Phaser phaser) &#123;</span><br><span class="line">        if (hi - lo &gt; TASKS_PER_PHASER) &#123;</span><br><span class="line">            for (int i &#x3D; lo; i &lt; hi; i +&#x3D; TASKS_PER_PHASER) &#123;</span><br><span class="line">                int j &#x3D; Math.min(i + TASKS_PER_PHASER, hi);</span><br><span class="line">                build(taskers, i, j, new Phaser(phaser));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            for (int i &#x3D; lo; i &lt; hi; ++i) &#123;</span><br><span class="line">                taskers[i] &#x3D; new Tasker(i, phaser);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Tasker implements Runnable &#123;</span><br><span class="line">        private final Phaser phaser;</span><br><span class="line">        private int count;</span><br><span class="line"></span><br><span class="line">        Tasker(Phaser phaser) &#123;</span><br><span class="line">            this.phaser &#x3D; phaser;</span><br><span class="line">            this.phaser.register();</span><br><span class="line">        &#125;</span><br><span class="line">        Tasker(int i,Phaser phaser) &#123;</span><br><span class="line">            this.count &#x3D; i;</span><br><span class="line">            this.phaser &#x3D; phaser;</span><br><span class="line">            this.phaser.register();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            while (!phaser.isTerminated()) &#123;   &#x2F;&#x2F;只要Phaser没有终止, 各个线程的任务就会一直执行</span><br><span class="line">                int i &#x3D; phaser.arriveAndAwaitAdvance();     &#x2F;&#x2F; 等待其它参与者线程到达</span><br><span class="line">                &#x2F;&#x2F; do something</span><br><span class="line">                System.out.println(Thread.currentThread().getName() + &quot;: 执行完任务,count&#x3D;&quot;+count);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#x2F;&#x2F;输出</span><br><span class="line">---------------PHASE[0],Parties[3] ---------------</span><br><span class="line">Thread-9: 执行完任务,count&#x3D;9</span><br><span class="line">Thread-0: 执行完任务,count&#x3D;0</span><br><span class="line">Thread-2: 执行完任务,count&#x3D;2</span><br><span class="line">Thread-3: 执行完任务,count&#x3D;3</span><br><span class="line">Thread-1: 执行完任务,count&#x3D;1</span><br><span class="line">Thread-5: 执行完任务,count&#x3D;5</span><br><span class="line">Thread-6: 执行完任务,count&#x3D;6</span><br><span class="line">Thread-4: 执行完任务,count&#x3D;4</span><br><span class="line">Thread-8: 执行完任务,count&#x3D;8</span><br><span class="line">Thread-7: 执行完任务,count&#x3D;7</span><br><span class="line">---------------PHASE[1],Parties[3] ---------------</span><br><span class="line">Thread-7: 执行完任务,count&#x3D;7</span><br><span class="line">Thread-8: 执行完任务,count&#x3D;8</span><br><span class="line">Thread-2: 执行完任务,count&#x3D;2</span><br><span class="line">Thread-9: 执行完任务,count&#x3D;9</span><br><span class="line">Thread-0: 执行完任务,count&#x3D;0</span><br><span class="line">Thread-5: 执行完任务,count&#x3D;5</span><br><span class="line">Thread-3: 执行完任务,count&#x3D;3</span><br><span class="line">Thread-6: 执行完任务,count&#x3D;6</span><br><span class="line">Thread-4: 执行完任务,count&#x3D;4</span><br><span class="line">Thread-1: 执行完任务,count&#x3D;1</span><br><span class="line">---------------PHASE[2],Parties[3] ---------------</span><br><span class="line">Thread-6: 执行完任务,count&#x3D;6</span><br><span class="line">Thread-9: 执行完任务,count&#x3D;9</span><br><span class="line">Thread-7: 执行完任务,count&#x3D;7</span><br><span class="line">Thread-5: 执行完任务,count&#x3D;5</span><br><span class="line">Thread-0: 执行完任务,count&#x3D;0</span><br><span class="line">Thread-2: 执行完任务,count&#x3D;2</span><br><span class="line">Thread-1: 执行完任务,count&#x3D;1</span><br><span class="line">Thread-4: 执行完任务,count&#x3D;4</span><br><span class="line">Thread-8: 执行完任务,count&#x3D;8</span><br><span class="line">Thread-3: 执行完任务,count&#x3D;3</span><br></pre></td></tr></table></figure>



<h4 id="原理小结-7"><a href="#原理小结-7" class="headerlink" title="原理小结"></a>原理小结</h4><p>和AQS类似，内部依然保留了同步等待队列，只不过是用链表存储，内部保存奇偶两个链表evenQ，oddQ，根据阶段来区分，奇数阶段oddQ，偶数阶段在evenQ，如果是分层，下层的Phaser共享根节点的链表。当线程数没有到达注册数量时，会采用头插法加入链表，会同步等待（利用的是ForkJoinPool的managedBlock，底层也是park）。当达到注册数量后，最后一个线程会按链表顺序，从顶部以此唤醒（unpark）其他节点，结合头插法，因此是后进先出，栈的形式。</p>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><h4 id="简单对比-1"><a href="#简单对比-1" class="headerlink" title="简单对比"></a>简单对比</h4><table>
<thead>
<tr>
<th>业务诉求</th>
<th>Semaphore</th>
<th>CountDownLatch</th>
<th>CyclicBarrier</th>
<th>Exchanger</th>
<th>Phaser</th>
</tr>
</thead>
<tbody><tr>
<td>多线程阻塞共享额度</td>
<td>✓</td>
<td>✓</td>
<td>✓</td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td>到达一定数量后唤醒另一个线程</td>
<td></td>
<td>✓</td>
<td>✓</td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td>到达一定数量后唤醒另一个线程，可重复使用</td>
<td></td>
<td></td>
<td>✓</td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td>到达一定阶段后唤醒线程，升级阶段，参与线程数可变化</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td>两个线程交换数据</td>
<td></td>
<td></td>
<td></td>
<td>✓</td>
<td></td>
</tr>
</tbody></table>
<h2 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h2><h3 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h3><blockquote>
<p>常用线程池，继承自AbstractExecutorService，有任务需要执行时，会将任务分配给线程，如果当下没有线程，泽辉放入队列，等待线程可用时，取出任务执行。</p>
</blockquote>
<ul>
<li>特点<ul>
<li>线程复用，减少系统因为频繁创建和销毁线程带来的开销</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-8"><a href="#使用姿势-8" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ThreadPoolExecutor thread &#x3D; new ThreadPoolExecutor(2,</span><br><span class="line">        5,</span><br><span class="line">        1,</span><br><span class="line">        TimeUnit.SECONDS,</span><br><span class="line">        new LinkedBlockingDeque&lt;&gt;(1),</span><br><span class="line">        new ThreadFactoryOne(),</span><br><span class="line">        new ThreadPoolExecutor.DiscardOldestPolicy());</span><br><span class="line">for (int i &#x3D; 0; i &lt; 3; i++) &#123;</span><br><span class="line">    thread.execute(() -&gt; &#123;</span><br><span class="line">        System.out.println(Thread.currentThread().getName() + &quot;：我在运行&quot;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(&quot;运行完了&quot;);</span><br></pre></td></tr></table></figure>

<h4 id="原理小结-8"><a href="#原理小结-8" class="headerlink" title="原理小结"></a>原理小结</h4><p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/5.png" alt loading="lazy"></p>
<h5 id="线程池构造器"><a href="#线程池构造器" class="headerlink" title="线程池构造器"></a>线程池构造器</h5><ul>
<li>核心线程 corePoolSize</li>
<li>最大线程数 maximumPoolSize</li>
<li>空闲线程存活时间 keepAliveTime</li>
<li>空闲线程存活时间单位 unit</li>
<li>任务队列 workQueue</li>
<li>线程工厂 threadFactory</li>
<li>拒绝策略 handler</li>
</ul>
<h5 id="线程池状态"><a href="#线程池状态" class="headerlink" title="线程池状态"></a>线程池状态</h5><p>包括线程池状态以及工作线程数的管理变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private final AtomicInteger ctl &#x3D; new AtomicInteger(ctlOf(RUNNING, 0));</span><br><span class="line">private static final int COUNT_BITS &#x3D; Integer.SIZE - 3;    &#x2F;&#x2F;存放线程数位数 32-3&#x3D;29位</span><br><span class="line">private static final int CAPACITY   &#x3D; (1 &lt;&lt; COUNT_BITS) - 1; &#x2F;&#x2F;最大线程数	2^29-1 个线程</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; runState is stored in the high-order bits</span><br><span class="line">&#x2F;&#x2F; 线程运行状态，存储在高3位</span><br><span class="line">private static final int RUNNING    &#x3D; -1 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; 111 00000 00000000 00000000 00000000</span><br><span class="line">private static final int SHUTDOWN   &#x3D;  0 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; 000 00000 00000000 00000000 00000000</span><br><span class="line">private static final int STOP       &#x3D;  1 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; 001 00000 00000000 00000000 00000000</span><br><span class="line">private static final int TIDYING    &#x3D;  2 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; 010 00000 00000000 00000000 00000000</span><br><span class="line">private static final int TERMINATED &#x3D;  3 &lt;&lt; COUNT_BITS; &#x2F;&#x2F; 011 00000 00000000 00000000 00000000</span><br></pre></td></tr></table></figure>

<p>工作线程（Worker）继承自AbstractQueuedSynchronizer，与Thread关联，实际执行委托给runWorker方法</p>
<p>提供默认的线程工厂，便于设置线程名称，优先级，是否守护线程等</p>
<h5 id="线程执行"><a href="#线程执行" class="headerlink" title="线程执行"></a>线程执行</h5><p>核心execute方法</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">public void execute(Runnable command) &#123;</span><br><span class="line">    <span class="keyword">if</span> (command<span class="operator"> == </span>null)</span><br><span class="line">        throw <span class="keyword">new</span> <span class="constructor">NullPointerException()</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="built_in">int</span> c = ctl.get<span class="literal">()</span>;</span><br><span class="line">    <span class="keyword">if</span> (worker<span class="constructor">CountOf(<span class="params">c</span>)</span> &lt; corePoolSize) &#123;              <span class="comment">// CASE1: 工作线程数 &lt; 核心线程池上限</span></span><br><span class="line">        <span class="keyword">if</span> (add<span class="constructor">Worker(<span class="params">command</span>, <span class="params">true</span>)</span>)             <span class="comment">// 添加工作线程并执行</span></span><br><span class="line">            return;</span><br><span class="line">        c = ctl.get<span class="literal">()</span>;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 加入线程失败 工作线程数 &gt;= 核心线程数</span></span><br><span class="line">    <span class="keyword">if</span> (is<span class="constructor">Running(<span class="params">c</span>)</span><span class="operator"> &amp;&amp; </span>workQueue.offer(command)) &#123;     <span class="comment">// CASE2: 插入任务至队列</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 再次检查线程池状态</span></span><br><span class="line">        <span class="built_in">int</span> recheck = ctl.get<span class="literal">()</span>;</span><br><span class="line">        <span class="keyword">if</span> (!is<span class="constructor">Running(<span class="params">recheck</span>)</span><span class="operator"> &amp;&amp; </span>remove(command))    <span class="comment">//线程池非运行状态，移除任务，拒绝请求</span></span><br><span class="line">            reject(command);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (worker<span class="constructor">CountOf(<span class="params">recheck</span>)</span><span class="operator"> == </span><span class="number">0</span>)          <span class="comment">//dubbocheck，在工作的线程数是否=0</span></span><br><span class="line">            add<span class="constructor">Worker(<span class="params">null</span>, <span class="params">false</span>)</span>;                    <span class="comment">//没有工作线程，就创建一个工作线程（非核心），让工作线程去队列获取任务</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!add<span class="constructor">Worker(<span class="params">command</span>, <span class="params">false</span>)</span>)        <span class="comment">// CASE3: 插入队列失败, 判断工作线程数 &lt; 总线程池上限</span></span><br><span class="line">        reject(command);    <span class="comment">// 执行拒绝策略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>小结</p>
<ol>
<li>如果工作线程数小于核心线程池上限（CorePoolSize），则直接新建一个工作线程并执行任务；</li>
<li>如果工作线程数大于等于CorePoolSize，则尝试将任务加入到队列等待以后执行。如果加入队列失败了（比如队列已满的情况），则在总线程池未满的情况下（<code>CorePoolSize ≤ 工作线程数 ＜ maximumPoolSize</code>）新建一个工作线程立即执行任务，否则执行拒绝策略。</li>
</ol>
<p>添加工作线程addWorker方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private boolean addWorker(Runnable firstTask, boolean core) &#123;</span><br><span class="line">				&#x2F;&#x2F;第一部分，CAS增加工作线程数</span><br><span class="line">        retry:</span><br><span class="line">        for (;;) &#123;</span><br><span class="line">            int c &#x3D; ctl.get();</span><br><span class="line">            int rs &#x3D; runStateOf(c);</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 校验线程池状态，工作队列是否为空等</span><br><span class="line">            if (rs &gt;&#x3D; SHUTDOWN &amp;&amp;</span><br><span class="line">                ! (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp;</span><br><span class="line">                   firstTask &#x3D;&#x3D; null &amp;&amp;</span><br><span class="line">                   ! workQueue.isEmpty()))</span><br><span class="line">                return false;</span><br><span class="line"></span><br><span class="line">						&#x2F;&#x2F;CAS递增线程池数量	</span><br><span class="line">            for (;;) &#123;</span><br><span class="line">                int wc &#x3D; workerCountOf(c);</span><br><span class="line">                if (wc &gt;&#x3D; CAPACITY ||</span><br><span class="line">                    wc &gt;&#x3D; (core ? corePoolSize : maximumPoolSize))</span><br><span class="line">                    return false;</span><br><span class="line">                if (compareAndIncrementWorkerCount(c))    &#x2F;&#x2F;更新成功后退出第一部分自旋</span><br><span class="line">                    break retry;</span><br><span class="line">                c &#x3D; ctl.get();  &#x2F;&#x2F; Re-read ctl</span><br><span class="line">                if (runStateOf(c) !&#x3D; rs)</span><br><span class="line">                    continue retry;</span><br><span class="line">                &#x2F;&#x2F; 更新失败就自旋再次重试</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">				&#x2F;&#x2F;第二部分，包装工作线程</span><br><span class="line">        boolean workerStarted &#x3D; false;</span><br><span class="line">        boolean workerAdded &#x3D; false;</span><br><span class="line">        Worker w &#x3D; null;</span><br><span class="line">        try &#123;</span><br><span class="line">        		&#x2F;&#x2F;创建好工作线程</span><br><span class="line">            w &#x3D; new Worker(firstTask);</span><br><span class="line">            final Thread t &#x3D; w.thread;</span><br><span class="line">            if (t !&#x3D; null) &#123;</span><br><span class="line">                final ReentrantLock mainLock &#x3D; this.mainLock;</span><br><span class="line">                &#x2F;&#x2F;加锁，避免加入工作队列时并发</span><br><span class="line">                mainLock.lock();</span><br><span class="line">                try &#123;</span><br><span class="line">                    &#x2F;&#x2F; 锁内再次检查线程池状态</span><br><span class="line">                    int rs &#x3D; runStateOf(ctl.get());</span><br><span class="line"></span><br><span class="line">                    if (rs &lt; SHUTDOWN ||</span><br><span class="line">                        (rs &#x3D;&#x3D; SHUTDOWN &amp;&amp; firstTask &#x3D;&#x3D; null)) &#123;</span><br><span class="line">                        if (t.isAlive()) &#x2F;&#x2F; precheck that t is startable</span><br><span class="line">                            throw new IllegalThreadStateException();</span><br><span class="line">                        workers.add(w);</span><br><span class="line">                        int s &#x3D; workers.size();</span><br><span class="line">                        if (s &gt; largestPoolSize)</span><br><span class="line">                            largestPoolSize &#x3D; s;</span><br><span class="line">                        workerAdded &#x3D; true;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    mainLock.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">                &#x2F;&#x2F;加入工作线程队列后，启动工作线程</span><br><span class="line">                if (workerAdded) &#123;</span><br><span class="line">                    t.start();</span><br><span class="line">                    workerStarted &#x3D; true;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            if (! workerStarted)</span><br><span class="line">                addWorkerFailed(w);</span><br><span class="line">        &#125;</span><br><span class="line">        return workerStarted;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>工作线程执行runWorker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.util.concurrent.ThreadPoolExecutor.Worker#run</span><br><span class="line">public void run() &#123;</span><br><span class="line">	runWorker(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">final void runWorker(Worker w) &#123;</span><br><span class="line">        Thread wt &#x3D; Thread.currentThread();</span><br><span class="line">        Runnable task &#x3D; w.firstTask;</span><br><span class="line">        w.firstTask &#x3D; null;</span><br><span class="line">        w.unlock(); &#x2F;&#x2F; allow interrupts</span><br><span class="line">        boolean completedAbruptly &#x3D; true;</span><br><span class="line">        try &#123;</span><br><span class="line">        		&#x2F;&#x2F;自旋从队列中获取任务，getTask比较简单，核心就是从BlockQueue获取任务</span><br><span class="line">            while (task !&#x3D; null || (task &#x3D; getTask()) !&#x3D; null) &#123;</span><br><span class="line">                w.lock();</span><br><span class="line">                &#x2F;&#x2F; 校验线程池状态，是否中断</span><br><span class="line">                if ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class="line">                     (Thread.interrupted() &amp;&amp;</span><br><span class="line">                      runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class="line">                    !wt.isInterrupted())</span><br><span class="line">                    wt.interrupt();</span><br><span class="line">                try &#123;</span><br><span class="line">                    &#x2F;&#x2F;钩子函数，执行前</span><br><span class="line">                    beforeExecute(wt, task);</span><br><span class="line">                    Throwable thrown &#x3D; null;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        task.run();</span><br><span class="line">                    &#125; catch (RuntimeException x) &#123;</span><br><span class="line">                        thrown &#x3D; x; throw x;</span><br><span class="line">                    &#125; catch (Error x) &#123;</span><br><span class="line">                        thrown &#x3D; x; throw x;</span><br><span class="line">                    &#125; catch (Throwable x) &#123;</span><br><span class="line">                        thrown &#x3D; x; throw new Error(x);</span><br><span class="line">                    &#125; finally &#123;</span><br><span class="line">                        &#x2F;&#x2F;钩子函数，执行后</span><br><span class="line">                        afterExecute(task, thrown);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    task &#x3D; null;</span><br><span class="line">                    w.completedTasks++;</span><br><span class="line">                    w.unlock();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            completedAbruptly &#x3D; false;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            processWorkerExit(w, completedAbruptly);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private Runnable getTask() &#123;</span><br><span class="line">        boolean timedOut &#x3D; false; &#x2F;&#x2F; Did the last poll() time out?</span><br><span class="line"></span><br><span class="line">        for (;;) &#123;</span><br><span class="line">            int c &#x3D; ctl.get();</span><br><span class="line">            int rs &#x3D; runStateOf(c);</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 校验线程池状态，工作队列是否为空</span><br><span class="line">            if (rs &gt;&#x3D; SHUTDOWN &amp;&amp; (rs &gt;&#x3D; STOP || workQueue.isEmpty())) &#123;</span><br><span class="line">                decrementWorkerCount();</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            int wc &#x3D; workerCountOf(c);</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 是否需要超时控制，a)通过设置 b)非核心线程</span><br><span class="line">            boolean timed &#x3D; allowCoreThreadTimeOut || wc &gt; corePoolSize;</span><br><span class="line"></span><br><span class="line">            if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class="line">                &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123;</span><br><span class="line">                &#x2F;&#x2F;超过最大线程池，需要工作线程减回去</span><br><span class="line">                if (compareAndDecrementWorkerCount(c))</span><br><span class="line">                    return null;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            try &#123;</span><br><span class="line">            		&#x2F;&#x2F;核心 从任务队列获取队列方法</span><br><span class="line">                Runnable r &#x3D; timed ?</span><br><span class="line">                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :</span><br><span class="line">                    workQueue.take();</span><br><span class="line">                if (r !&#x3D; null)</span><br><span class="line">                    return r;</span><br><span class="line">                timedOut &#x3D; true;</span><br><span class="line">            &#125; catch (InterruptedException retry) &#123;</span><br><span class="line">                timedOut &#x3D; false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h5 id="拒绝策略"><a href="#拒绝策略" class="headerlink" title="拒绝策略"></a>拒绝策略</h5><ul>
<li>AbortPolicy，拒绝报错</li>
<li>DiscardPolicy，丢弃</li>
<li>DiscardOldestPolicy，丢弃最近一个任务，执行当前任务</li>
<li>CallerRunsPolicy，以自身线程来执行</li>
</ul>
<h5 id="线程关闭"><a href="#线程关闭" class="headerlink" title="线程关闭"></a>线程关闭</h5><p>加锁，将线程池状态置为关闭，尝试中断工作线程。shutdownNow类似</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void shutdown() &#123;</span><br><span class="line">    final ReentrantLock mainLock &#x3D; this.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    try &#123;</span><br><span class="line">        checkShutdownAccess();</span><br><span class="line">        advanceRunState(SHUTDOWN);</span><br><span class="line">        interruptIdleWorkers();</span><br><span class="line">        onShutdown(); &#x2F;&#x2F; hook for ScheduledThreadPoolExecutor</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    tryTerminate();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h3 id="ForkJoinPool"><a href="#ForkJoinPool" class="headerlink" title="ForkJoinPool"></a>ForkJoinPool</h3><blockquote>
<p>拆分合并线程池，是普通线程池的补充，和ThreadPoolExecutor一样，继承自AbstractExecutorService，适合于可拆分子任务的计算密集型任务</p>
</blockquote>
<ul>
<li><p>原理</p>
<ul>
<li><p>基于”分治”算法，相同类型任务拆分，合并成大结果</p>
</li>
<li><p>由于线程处理不同任务速度不同，为了提高效率，采用工作线程”窃取”</p>
</li>
</ul>
</li>
</ul>
<h4 id="使用姿势-9"><a href="#使用姿势-9" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">        ForkJoinPool executor &#x3D; new ForkJoinPool();</span><br><span class="line">        int[] ints &#x3D; new int[10000];</span><br><span class="line">        Arrays.fill(ints,1);</span><br><span class="line">        ArraySumTask task &#x3D; new ArraySumTask(ints, 0, 9999);</span><br><span class="line"></span><br><span class="line">        ForkJoinTask future &#x3D; executor.submit(task);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; some time passed...</span><br><span class="line"></span><br><span class="line">        if (future.isCompletedAbnormally()) &#123;</span><br><span class="line">            System.out.println(future.getException());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            System.out.println(&quot;result: &quot; + future.get());</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class ArraySumTask extends RecursiveTask&lt;Long&gt; &#123;</span><br><span class="line">        private final int[] array;</span><br><span class="line">        private final int begin;</span><br><span class="line">        private final int end;</span><br><span class="line"></span><br><span class="line">        private static final int THRESHOLD &#x3D; 100;</span><br><span class="line"></span><br><span class="line">        public ArraySumTask(int[] array, int begin, int end) &#123;</span><br><span class="line">            this.array &#x3D; array;</span><br><span class="line">            this.begin &#x3D; begin;</span><br><span class="line">            this.end &#x3D; end;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        protected Long compute() &#123;</span><br><span class="line">            long sum &#x3D; 0;</span><br><span class="line"></span><br><span class="line">            if (end - begin + 1 &lt; THRESHOLD) &#123;      &#x2F;&#x2F; 小于阈值, 直接计算</span><br><span class="line">                for (int i &#x3D; begin; i &lt;&#x3D; end; i++) &#123;</span><br><span class="line">                    sum +&#x3D; array[i];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                int middle &#x3D; (end + begin) &#x2F; 2;</span><br><span class="line">                ArraySumTask subtask1 &#x3D; new ArraySumTask(this.array, begin, middle);</span><br><span class="line">                ArraySumTask subtask2 &#x3D; new ArraySumTask(this.array, middle + 1, end);</span><br><span class="line"></span><br><span class="line">                subtask1.fork();</span><br><span class="line">                subtask2.fork();</span><br><span class="line"></span><br><span class="line">                long sum1 &#x3D; subtask1.join();</span><br><span class="line">                long sum2 &#x3D; subtask2.join();</span><br><span class="line"></span><br><span class="line">                sum &#x3D; sum1 + sum2;</span><br><span class="line">            &#125;</span><br><span class="line">            return sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#x2F;&#x2F;输出</span><br><span class="line">result: 10000</span><br></pre></td></tr></table></figure>

<h4 id="原理小结-9"><a href="#原理小结-9" class="headerlink" title="原理小结"></a>原理小结</h4><h5 id="ForkJoinPool-1"><a href="#ForkJoinPool-1" class="headerlink" title="ForkJoinPool"></a>ForkJoinPool</h5><p>线程池：接收外部任务提交，接受内部fork任务提交，管理工作队列，任务队列执行；</p>
<ul>
<li><strong>parallelism</strong>：默认值为CPU核心数，ForkJoinPool里工作线程数量与该参数有关，但它不表示最大线程数；</li>
<li><strong>factory</strong>：工作线程工厂，默认是DefaultForkJoinWorkerThreadFactory</li>
<li><strong>handler</strong>：异常处理器；</li>
<li><strong>config</strong>：保存parallelism和mode信息，供后续读取；</li>
<li><strong>ctl</strong>：线程池的核心控制字段</li>
</ul>
<p>mode字段，表示任务队列的处理模式，同步模式=FIFO_QUEUE=先进先出，异步模式=LIFO=后进先出</p>
<h5 id="ForkJoinTask"><a href="#ForkJoinTask" class="headerlink" title="ForkJoinTask"></a>ForkJoinTask</h5><p>线程池调度的任务，是一个Future</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ForkJoinTask</span>&lt;<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Future</span>&lt;<span class="title">V</span>&gt;, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//表示没有返回结果的ForkJoin任务</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RecursiveAction</span> <span class="keyword">extends</span> <span class="title">ForkJoinTask</span>&lt;<span class="title">Void</span>&gt; </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//表示具有返回结果的ForkJoin任务</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">RecursiveTask</span>&lt;<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">ForkJoinTask</span>&lt;<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="ForkJoinWorkThread"><a href="#ForkJoinWorkThread" class="headerlink" title="ForkJoinWorkThread"></a>ForkJoinWorkThread</h5><p>工作线程，内部包含线程池的引用以及任务队列</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ForkJoinWorkerThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ForkJoinPool pool;                <span class="comment">// 线程池引用</span></span><br><span class="line">    <span class="keyword">final</span> ForkJoinPool.WorkQueue workQueue; <span class="comment">// 任务队列</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">ForkJoinWorkerThread</span><span class="params">(ForkJoinPool pool)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"aForkJoinWorkerThread"</span>);        </span><br><span class="line">        <span class="keyword">this</span>.pool = pool;</span><br><span class="line">        <span class="keyword">this</span>.workQueue = pool.registerWorker(<span class="keyword">this</span>);  <span class="comment">//将自己注册到线程池里</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>任务执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Top-level runloop for workers, called by ForkJoinWorkerThread.run.</span><br><span class="line"> *&#x2F;</span><br><span class="line">final void runWorker(WorkQueue w) &#123;</span><br><span class="line">    w.growArray();                   &#x2F;&#x2F; allocate queue</span><br><span class="line">    int seed &#x3D; w.hint;               &#x2F;&#x2F; initially holds randomization hint</span><br><span class="line">    int r &#x3D; (seed &#x3D;&#x3D; 0) ? 1 : seed;  &#x2F;&#x2F; avoid 0 for xorShift</span><br><span class="line">    for (ForkJoinTask&lt;?&gt; t;;) &#123;</span><br><span class="line">        if ((t &#x3D; scan(w, r)) !&#x3D; null)	   &#x2F;&#x2F;1. 扫描到任务</span><br><span class="line">            w.runTask(t);                &#x2F;&#x2F;2. 执行任务</span><br><span class="line">        else if (!awaitWork(w, r))</span><br><span class="line">            break;</span><br><span class="line">        r ^&#x3D; r &lt;&lt; 13; r ^&#x3D; r &gt;&gt;&gt; 17; r ^&#x3D; r &lt;&lt; 5; &#x2F;&#x2F; xorshift</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h5 id="WorkQueue"><a href="#WorkQueue" class="headerlink" title="WorkQueue"></a>WorkQueue</h5><p>在线程池ForkJoinPool中维护这一个任务队列，该字段在向线程池提交任务（内部/外部）时会初始化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ForkJoinPool extends AbstractExecutorService &#123;</span><br><span class="line">    ...</span><br><span class="line">		volatile WorkQueue[] workQueues; &#x2F;&#x2F; main registry</span><br><span class="line">		...</span><br><span class="line">		</span><br><span class="line">		public &lt;T&gt; ForkJoinTask&lt;T&gt; submit(ForkJoinTask&lt;T&gt; task) &#123;</span><br><span class="line">        if (task &#x3D;&#x3D; null)</span><br><span class="line">            throw new NullPointerException();</span><br><span class="line">        externalPush(task);</span><br><span class="line">        return task;</span><br><span class="line">    &#125;</span><br><span class="line">    final void externalPush(ForkJoinTask&lt;?&gt; task) &#123;</span><br><span class="line">        WorkQueue[] ws; WorkQueue q; int m;</span><br><span class="line">        ...省略代码...</span><br><span class="line">        externalSubmit(task);</span><br><span class="line">    &#125;</span><br><span class="line">		private void externalSubmit(ForkJoinTask&lt;?&gt; task) &#123;</span><br><span class="line">        ...省略代码...</span><br><span class="line">        for (;;) &#123;</span><br><span class="line">            WorkQueue[] ws; WorkQueue q; int rs, m, k;</span><br><span class="line">            boolean move &#x3D; false;</span><br><span class="line">            if ((rs &#x3D; runState) &lt; 0) &#123;</span><br><span class="line">                ...省略代码...</span><br><span class="line">            &#125;</span><br><span class="line">            else if ((rs &amp; STARTED) &#x3D;&#x3D; 0 ||     &#x2F;&#x2F; initialize</span><br><span class="line">                     ((ws &#x3D; workQueues) &#x3D;&#x3D; null || (m &#x3D; ws.length - 1) &lt; 0)) &#123;</span><br><span class="line">                int ns &#x3D; 0;</span><br><span class="line">                rs &#x3D; lockRunState();</span><br><span class="line">                try &#123;</span><br><span class="line">                    if ((rs &amp; STARTED) &#x3D;&#x3D; 0) &#123;</span><br><span class="line">                        U.compareAndSwapObject(this, STEALCOUNTER, null,</span><br><span class="line">                                               new AtomicLong());</span><br><span class="line">                        &#x2F;&#x2F; create workQueues array with size a power of two</span><br><span class="line">                        int p &#x3D; config &amp; SMASK; &#x2F;&#x2F; ensure at least 2 slots</span><br><span class="line">                        int n &#x3D; (p &gt; 1) ? p - 1 : 1;</span><br><span class="line">                        n |&#x3D; n &gt;&gt;&gt; 1; n |&#x3D; n &gt;&gt;&gt; 2;  n |&#x3D; n &gt;&gt;&gt; 4;</span><br><span class="line">                        n |&#x3D; n &gt;&gt;&gt; 8; n |&#x3D; n &gt;&gt;&gt; 16; n &#x3D; (n + 1) &lt;&lt; 1;</span><br><span class="line">                        workQueues &#x3D; new WorkQueue[n];      &#x2F;&#x2F;重点是这里初始化</span><br><span class="line">                        ns &#x3D; STARTED;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; finally &#123;</span><br><span class="line">                    unlockRunState(rs, (rs &amp; ~RSLOCK) | ns);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            else if ((q &#x3D; ws[k &#x3D; r &amp; m &amp; SQMASK]) !&#x3D; null) &#123;</span><br><span class="line">               ...省略代码...</span><br><span class="line">            &#125;</span><br><span class="line">            else if (((rs &#x3D; runState) &amp; RSLOCK) &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; create new queue</span><br><span class="line">               ...省略代码...</span><br><span class="line">            &#125;</span><br><span class="line">            else</span><br><span class="line">                move &#x3D; true;                   &#x2F;&#x2F; move if busy</span><br><span class="line">            if (move)</span><br><span class="line">                r &#x3D; ThreadLocalRandom.advanceProbe(r);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>任务队列分为2类，有工作线程绑定的，任务队列下标是<strong>奇数</strong>。没有工作线程绑定的，任务下标是<strong>偶数</strong>（尚未找到代码）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ForkJoinPool，绑定工作线程时，下标为奇数</span><br><span class="line">final WorkQueue registerWorker(ForkJoinWorkerThread wt) &#123;</span><br><span class="line">        UncaughtExceptionHandler handler;</span><br><span class="line">        wt.setDaemon(true);                           &#x2F;&#x2F; configure thread</span><br><span class="line">        if ((handler &#x3D; ueh) !&#x3D; null)</span><br><span class="line">            wt.setUncaughtExceptionHandler(handler);</span><br><span class="line">        WorkQueue w &#x3D; new WorkQueue(this, wt);</span><br><span class="line">        int i &#x3D; 0;                                    &#x2F;&#x2F; assign a pool index</span><br><span class="line">        int mode &#x3D; config &amp; MODE_MASK;</span><br><span class="line">        int rs &#x3D; lockRunState();</span><br><span class="line">        try &#123;</span><br><span class="line">            WorkQueue[] ws; int n;                    &#x2F;&#x2F; skip if no array</span><br><span class="line">            if ((ws &#x3D; workQueues) !&#x3D; null &amp;&amp; (n &#x3D; ws.length) &gt; 0) &#123;</span><br><span class="line">                int s &#x3D; indexSeed +&#x3D; SEED_INCREMENT;  &#x2F;&#x2F; unlikely to collide</span><br><span class="line">                int m &#x3D; n - 1;</span><br><span class="line">                i &#x3D; ((s &lt;&lt; 1) | 1) &amp; m;               &#x2F;&#x2F; 任务队列下标</span><br><span class="line">                if (ws[i] !&#x3D; null) &#123;                  &#x2F;&#x2F; collision</span><br><span class="line">                    int probes &#x3D; 0;                   &#x2F;&#x2F; step by approx half n</span><br><span class="line">                    int step &#x3D; (n &lt;&#x3D; 4) ? 2 : ((n &gt;&gt;&gt; 1) &amp; EVENMASK) + 2;</span><br><span class="line">                    while (ws[i &#x3D; (i + step) &amp; m] !&#x3D; null) &#123;</span><br><span class="line">                        if (++probes &gt;&#x3D; n) &#123;</span><br><span class="line">                            workQueues &#x3D; ws &#x3D; Arrays.copyOf(ws, n &lt;&lt;&#x3D; 1);</span><br><span class="line">                            m &#x3D; n - 1;</span><br><span class="line">                            probes &#x3D; 0;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                w.hint &#x3D; s;                           &#x2F;&#x2F; use as random seed</span><br><span class="line">                w.config &#x3D; i | mode;</span><br><span class="line">                w.scanState &#x3D; i;                      &#x2F;&#x2F; publication fence</span><br><span class="line">                ws[i] &#x3D; w;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            unlockRunState(rs, rs &amp; ~RSLOCK);</span><br><span class="line">        &#125;</span><br><span class="line">        wt.setName(workerNamePrefix.concat(Integer.toString(i &gt;&gt;&gt; 1)));</span><br><span class="line">        return w;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h3 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h3><h4 id="使用姿势-10"><a href="#使用姿势-10" class="headerlink" title="使用姿势"></a>使用姿势</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> ScheduledThreadPoolExecutor executor = <span class="keyword">new</span> ScheduledThreadPoolExecutor(<span class="number">3</span>);</span><br><span class="line">        executor.schedule(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(LocalDateTime.now()+<span class="string">"\t"</span>+Thread.currentThread().getName() + <span class="string">"：我在运行"</span>);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">10</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(LocalDateTime.now()+<span class="string">"\t"</span>+Thread.currentThread().getName() + <span class="string">"：运行结束"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,<span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">        System.out.println(LocalDateTime.now()+<span class="string">"\t创建线程结束"</span>);</span><br><span class="line">        </span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line"><span class="number">2024</span>-<span class="number">04</span>-<span class="number">13</span>T18:<span class="number">25</span>:<span class="number">32.293</span>	创建线程结束</span><br><span class="line"><span class="number">2024</span>-<span class="number">04</span>-<span class="number">13</span>T18:<span class="number">25</span>:<span class="number">42.172</span>	pool-<span class="number">1</span>-thread-<span class="number">1</span>：我在运行</span><br><span class="line"><span class="number">2024</span>-<span class="number">04</span>-<span class="number">13</span>T18:<span class="number">25</span>:<span class="number">42.182</span>	pool-<span class="number">1</span>-thread-<span class="number">1</span>：运行结束</span><br></pre></td></tr></table></figure>



<h4 id="原理小结-10"><a href="#原理小结-10" class="headerlink" title="原理小结"></a>原理小结</h4><blockquote>
<p>和ThreadPoolExecutor类似，将Runnable封装成ScheduledFutureTask，阻塞队列用DelayedWorkQueue，内部没有直接继承PriorityBlockingQueue，自己实现了优先级队列，因为线程池调度会利用阻塞队列的take。因此天然等待最早到时间的线程。</p>
</blockquote>
<h2 id="并发容器"><a href="#并发容器" class="headerlink" title="并发容器"></a>并发容器</h2><p>类继承关系</p>
<p><img src="/2024/04/13/5_Java%E5%9F%BA%E7%A1%80/6.png" alt loading="lazy"></p>
<h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><blockquote>
<p>解释表头，第一列表示相关类型的操作（入队，出队，检索队头元素），第一行表示当相关操作第一时间不符合条件（如队头队尾无元素）时触发的操作（如抛异常，返回特定值，阻塞，超时阻塞）</p>
</blockquote>
<h4 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h4><ul>
<li>Queue</li>
</ul>
<blockquote>
<p>普通队列</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>Throws exception</th>
<th>Returns special value</th>
</tr>
</thead>
<tbody><tr>
<td>Insert</td>
<td>add(e)</td>
<td>offer(e)</td>
</tr>
<tr>
<td>Remove</td>
<td>remove()</td>
<td>poll()</td>
</tr>
<tr>
<td>Examine</td>
<td>element()</td>
<td>peek()</td>
</tr>
</tbody></table>
<ul>
<li>BlockingQueue</li>
</ul>
<blockquote>
<p>阻塞队列</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>Throws exception</th>
<th>special value</th>
<th>Blocks</th>
<th>Times out</th>
</tr>
</thead>
<tbody><tr>
<td>Insert</td>
<td>add(e)</td>
<td>offer(e)</td>
<td>put(e)</td>
<td>offer(e, time, unit)</td>
</tr>
<tr>
<td>Remove</td>
<td>remove()</td>
<td>poll()</td>
<td>take()</td>
<td>poll(time, unit)</td>
</tr>
<tr>
<td>Examine</td>
<td>element()</td>
<td>peek()</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>Dueue</li>
</ul>
<blockquote>
<p>双端队列</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>First Element (Head)</th>
<th>First Element (Head)</th>
<th>Last Element (Tail)</th>
<th>Last Element (Tail)</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>Throws exception</td>
<td>Special value</td>
<td>Throws exception</td>
<td>Special value</td>
</tr>
<tr>
<td>Insert</td>
<td>addFirst(e)</td>
<td>offerFirst(e)</td>
<td>addLast(e)</td>
<td>offerLast(e)</td>
</tr>
<tr>
<td>Remove</td>
<td>remove()</td>
<td>poll()</td>
<td>removeLast()</td>
<td>pollLast()</td>
</tr>
<tr>
<td>Examine</td>
<td>element()</td>
<td>peek()</td>
<td>getLast()</td>
<td>peekLast()</td>
</tr>
</tbody></table>
<ul>
<li>BlockingDeque</li>
</ul>
<blockquote>
<p>阻塞双端队列</p>
</blockquote>
<p>First Element (Head)</p>
<table>
<thead>
<tr>
<th></th>
<th>Throws exception</th>
<th>Special value</th>
<th>Blocks</th>
<th>Times out</th>
</tr>
</thead>
<tbody><tr>
<td>Insert</td>
<td>addFirst(e)</td>
<td>offerFirst(e)</td>
<td>putFirst(e)</td>
<td>offerFirst(e, time, unit)</td>
</tr>
<tr>
<td>Remove</td>
<td>removeFirst()</td>
<td>pollFirst()</td>
<td>takeFirst()</td>
<td>pollFirst(time, unit)</td>
</tr>
<tr>
<td>Examine</td>
<td>getFirst()</td>
<td>peekFirst()</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>Last Element (Tail)，与上面类似</p>
<table>
<thead>
<tr>
<th></th>
<th>Throws exception</th>
<th>Special value</th>
<th>Blocks</th>
<th>Times out</th>
</tr>
</thead>
<tbody><tr>
<td>Insert</td>
<td>addLast(e)</td>
<td>offerLast(e)</td>
<td>putLast(e)</td>
<td>offerLast(e, time, unit)</td>
</tr>
<tr>
<td>Remove</td>
<td>removeLast()</td>
<td>pollLast()</td>
<td>takeLast()</td>
<td>pollLast(time, unit)</td>
</tr>
<tr>
<td>Examine</td>
<td>getLast()</td>
<td>peekLast()</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>TransferQueue</li>
</ul>
<blockquote>
<p>传输队列，是一种特殊的阻塞队列，发送放会等待消费方检索数据</p>
</blockquote>
<p>主要方法：</p>
<p>tryTransfer(E e) 和tryTransfer(E e, long timeout, TimeUnit unit)尝试传输，当没有对象时，返回false</p>
<p>transfer(E e)是阻塞传输，一直等待消费</p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><ul>
<li>ConcurrentLinkedQueue</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用链表存储，基于自旋和CAS实现入队出队</p>
<ul>
<li>ArrayBlockingQueue</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用数组存储，环形入队出队，使用ReentrantLock实现线程安全，两个条件变量notFull和notEmpty，当队满时，put方法在<strong>notFull</strong>上等待，当队没有元素时，take方法在<strong>notEmpty</strong>上等待。</p>
<ul>
<li>LinkedBlockingQueue</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用链表存储，入队和出队采用两个RentrantLock锁，同时用AtomicInteger存储队列元素个数。不支持公平非公平</p>
<ul>
<li>PriorityBlockingQueue</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用数组存储，无界，最大/最小堆实现优先级。利用RentrantLock加锁，只有出队take有条件变量<strong>notEmpty</strong> 等待</p>
<ul>
<li>SynchronousQueue</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用栈或队列结构的节点对象，存放入队等待的节点，当出队线程加入后，弹出匹配的节点线程，并交换数据</p>
<ul>
<li>DelayQueue</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用PriorityBlockingQueue存放元素，利用ReentrantLock加锁，入队不等待，出队等待。当时间没到时，等待【剩余时间】</p>
<ul>
<li>LinkedBlockingDeque</li>
</ul>
<blockquote>
<p>1.6版本</p>
</blockquote>
<p>利用链表存储，双端入队出队共用一把ReentrantLock锁，双端队列用来实现【工作窃取】</p>
<ul>
<li>ConcurrentLinkedDeque</li>
</ul>
<blockquote>
<p>1.7版本</p>
</blockquote>
<p>利用链表存储，采用自旋和CAS实现【无锁】，逻辑简单，实现比较复杂</p>
<ul>
<li>LinkedTransferQueue</li>
</ul>
<blockquote>
<p>1.7版本</p>
</blockquote>
<p>继承了SynchronousQueue的功能，由于继承了tryTransfer，可以实现异步入队，不用等待。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">LinkedTransferQueue&lt;Integer&gt; arrayBlockingQueue = <span class="keyword">new</span> LinkedTransferQueue();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> finalI = i;</span><br><span class="line">            <span class="keyword">if</span>(finalI ==<span class="number">0</span>)&#123;</span><br><span class="line">                Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        Integer poll = <span class="keyword">null</span>;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            poll = arrayBlockingQueue.take();</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                        &#125;</span><br><span class="line">                        System.out.println(<span class="string">"消费"</span>+poll);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, <span class="string">"consumer"</span> + i);</span><br><span class="line">                t1.start();</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                Thread t1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                        <span class="keyword">boolean</span> b = arrayBlockingQueue.tryTransfer(finalI);</span><br><span class="line">                        System.out.println(finalI + <span class="string">"\t"</span> + b);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;, <span class="string">"producer"</span> + i);</span><br><span class="line">                t1.start();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//输出</span></span><br><span class="line"><span class="number">2</span>	<span class="keyword">false</span></span><br><span class="line"><span class="number">4</span>	<span class="keyword">false</span></span><br><span class="line"><span class="number">1</span>	<span class="keyword">true</span></span><br><span class="line">消费<span class="number">1</span></span><br><span class="line"><span class="number">3</span>	<span class="keyword">false</span></span><br></pre></td></tr></table></figure>



<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><h4 id="接口-1"><a href="#接口-1" class="headerlink" title="接口"></a>接口</h4><ul>
<li>Set</li>
</ul>
<blockquote>
<p>不解释，无重复元素集合</p>
</blockquote>
<ul>
<li>SortedSet</li>
</ul>
<blockquote>
<p>有序的无重复元素集合</p>
</blockquote>
<ul>
<li>NavigableSet</li>
</ul>
<blockquote>
<p>提供定位检索方法的SortedSet，例如比某个元素大，小，移除最小，最大，降序升序等方法</p>
</blockquote>
<h4 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h4><ul>
<li>CopyOnWriteArraySet</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>直接内部代理CopyOnWriteArrayList，实现并发操作</p>
<ul>
<li>ConcurrentSkipListSet</li>
</ul>
<blockquote>
<p>1.6版本</p>
</blockquote>
<p>直接内部代理ConcurrentNavigableMap，实现并发操作</p>
<h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><h4 id="接口-2"><a href="#接口-2" class="headerlink" title="接口"></a>接口</h4><ul>
<li>Map</li>
</ul>
<blockquote>
<p>不解释，字典</p>
</blockquote>
<ul>
<li>SortedMap</li>
</ul>
<blockquote>
<p>有序的无重复Key的字典，根据Key排序</p>
</blockquote>
<ul>
<li>NavigableMap</li>
</ul>
<blockquote>
<p>提供定位检索方法的SortedMap，和NavigableSet类似，只不过根据Key进行定位</p>
</blockquote>
<ul>
<li>ConcurrentMap</li>
</ul>
<blockquote>
<p>提供并发安全操作的能力</p>
</blockquote>
<ul>
<li>ConcurrentNavigableMap</li>
</ul>
<blockquote>
<p>提供支持定位检索方法的并发安全操作的能力</p>
</blockquote>
<h4 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h4><ul>
<li>ConcurrentHashMap</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>高频面试点，底层和TreeMap类似，put时，采用CAS插入Key，当node冲突后，利用node对象锁（synchroized）加入冲突链表</p>
<ul>
<li>ConcurrentSkipListMap</li>
</ul>
<blockquote>
<p>1.6版本</p>
</blockquote>
<p>为了高效检索，利用多层二级索引实现跳表，自旋和CAS并发操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Head nodes          Index nodes                                          </span><br><span class="line">+-+    right        +-+                      +-+                         </span><br><span class="line">|2|----------------&gt;| |---------------------&gt;| |-&gt;null                   </span><br><span class="line">+-+                 +-+                      +-+                         </span><br><span class="line"> | down              |                        |                          </span><br><span class="line"> v                   v                        v                          </span><br><span class="line">+-+            +-+  +-+       +-+            +-+       +-+               </span><br><span class="line">|1|-----------&gt;| |-&gt;| |------&gt;| |-----------&gt;| |------&gt;| |-&gt;null         </span><br><span class="line">+-+            +-+  +-+       +-+            +-+       +-+               </span><br><span class="line"> v              |    |         |              |         |                </span><br><span class="line">Nodes  next     v    v         v              v         v                </span><br><span class="line">+-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+               </span><br><span class="line">| |-&gt;|A|-&gt;|B|-&gt;|C|-&gt;|D|-&gt;|E|-&gt;|F|-&gt;|G|-&gt;|H|-&gt;|I|-&gt;|J|-&gt;|K|-&gt;null         </span><br><span class="line">+-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+  +-+</span><br></pre></td></tr></table></figure>



<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><h4 id="接口-3"><a href="#接口-3" class="headerlink" title="接口"></a>接口</h4><ul>
<li>List</li>
</ul>
<blockquote>
<p>不解释，链表</p>
</blockquote>
<h4 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h4><ul>
<li>CopyOnWriteArrayList</li>
</ul>
<blockquote>
<p>1.5版本</p>
</blockquote>
<p>利用数组存储，写时复制，读取的时候可以不用加锁，适合于”读多写少的场景”，占用内存较多</p>
<h2 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h2><p>基于CAS为了实现无锁算法，AtomicInteger，AtomicReference，AtomicXXXFieldUpdater。1.8提供了LongAdder，利用分段的思想，分散热点</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>TODO</p>
]]></content>
      <categories>
        <category>通用知识</category>
      </categories>
  </entry>
  <entry>
    <title>Java的各种Log框架</title>
    <url>/2022/02/09/5_Java%E7%9A%84log%E6%A1%86%E6%9E%B6/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">

<h1 id="源头"><a href="#源头" class="headerlink" title="源头"></a>源头</h1><p>java里的日志框架很多，像log4j2、slf4j、logback之间的关系剪不断理还乱，日志依赖冲突也是maven中依赖冲突的最常见的一类，这里做一个整理。</p>
<h1 id="常见框架"><a href="#常见框架" class="headerlink" title="常见框架"></a>常见框架</h1><h2 id="Common-logging"><a href="#Common-logging" class="headerlink" title="Common-logging"></a>Common-logging</h2><blockquote>
<p>官网：<a href="https://commons.apache.org/proper/commons-logging/" target="_blank" rel="noopener">https://commons.apache.org/proper/commons-logging/</a></p>
</blockquote>
<h2 id="SLF4J"><a href="#SLF4J" class="headerlink" title="SLF4J"></a>SLF4J</h2><blockquote>
<p>官网：<a href="https://www.slf4j.org/manual.html" target="_blank" rel="noopener">https://www.slf4j.org/manual.html</a></p>
</blockquote>
<p>Slf4j（Simple Logging Facade For Java），是一个log框架的门面类，可以在部署时，由终端用户选择对应的日志实现框架，提供了流式api接口，常见的实现有</p>
<p>slf4j-log4j12（log4j1.2）</p>
<p>slf4j-reload4j（log4j1.2）</p>
<p>slf4j-jdk14</p>
<p>slf4j-nop</p>
<p>slf4j-simple</p>
<p>slf4j-jcl</p>
<p>logback-classic</p>
<p>log4j-slf4j-impl（log4j2）</p>
<p>使用时，只需要在你的class路径下替换对应的jar包，例如，将java.util.logging替换成log4j，只需要替换调slf4j-jdk14-1.7.36.jar with slf4j-log4j12-1.7.36.jar包。<strong>不过</strong>，由于slf4j不依赖特定的类加载器，所以，在编译时，必须保证有且仅有一个日志实现，否则就会异常。</p>
<p>借用官网的图</p>
<p><img src="/2022/02/09/5_Java%E7%9A%84log%E6%A1%86%E6%9E%B6/image1.png" alt loading="lazy"></p>
<h2 id="Log4j2"><a href="#Log4j2" class="headerlink" title="Log4j2"></a>Log4j2</h2><blockquote>
<p>官网：<a href="https://logging.apache.org/log4j/2.x/" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/</a></p>
</blockquote>
<p>Log4j2是一款高性能的日志实现框架，在Log4j1基础上做了性能优化，在2015年log4j1就停止维护，大部分开发者转移到log4j2上，继续开源维护。更新的还比较频繁，截止22年1-20号，最新更新时间是21年12-28号是log4j的升级版，是log4j1那一波人重新出来另起炉灶。提供了自己的接口及实现类，也可以支持Sl4j（log4j-slf4j-impl）</p>
<p>当然，也可以从Log4j2的api接口里路由到Slf4j，然后调用Slf4j的实现包（尽管很蛋疼，且会损失性能，不过也是支持的，相关的包是log4j-to-slf4j）注：log4j-to-slf4j-2.x.jar和log4j-slf4j-impl-2.x.jar不要同时使用。</p>
<p>Log4j2里面包含的包：<a href="https://logging.apache.org/log4j/2.x/runtime-dependencies.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/runtime-dependencies.html</a></p>
<p>log4j-api（核心接口定义）</p>
<p>log4j-core（核心实现）</p>
<p>log4j-jul（jul适配兼容）</p>
<p>log4j-to-slf4j（slf4j转发）</p>
<p>log4j-slf4j-impl（slf4j接口实现）</p>
<p>性能测试，异步写入性能比较好：<a href="https://logging.apache.org/log4j/2.x/performance.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/performance.html</a></p>
<p>log4j2日志文件加载顺序：<a href="https://logging.apache.org/log4j/2.x/manual/configuration.html#XML" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/manual/configuration.html#XML</a></p>
<p>Log4j has the ability to automatically configure itself during initialization. When Log4j starts it will locate all the ConfigurationFactory plugins and arrange them in weighted order from highest to lowest. As delivered, Log4j contains four ConfigurationFactory implementations: one for JSON, one for YAML, one for properties, and one for XML.</p>
<ol>
<li>Log4j will inspect the “log4j2.configurationFile” system property and, if set, will attempt to load the configuration using the ConfigurationFactory that matches the file extension. Note that this is not restricted to a location on the local file system and may contain a URL.</li>
<li>If no system property is set the properties ConfigurationFactory will look for log4j2-test.properties in the classpath.</li>
<li>If no such file is found the YAML ConfigurationFactory will look for log4j2-test.yaml or log4j2-test.yml in the classpath.</li>
<li>If no such file is found the JSON ConfigurationFactory will look for log4j2-test.json or log4j2-test.jsn in the classpath.</li>
<li>If no such file is found the XML ConfigurationFactory will look for log4j2-test.xml in the classpath.</li>
<li>If a test file cannot be located the properties ConfigurationFactory will look for log4j2.properties on the classpath.</li>
<li>If a properties file cannot be located the YAML ConfigurationFactory will look for log4j2.yaml or log4j2.yml on the classpath.</li>
<li>If a YAML file cannot be located the JSON ConfigurationFactory will look for log4j2.json or log4j2.jsn on the classpath.</li>
<li>If a JSON file cannot be located the XML ConfigurationFactory will try to locate log4j2.xml on the classpath.</li>
<li>If no configuration file could be located the DefaultConfiguration will be used. This will cause logging output to go to the console.</li>
</ol>
<h2 id="Log4j1-x"><a href="#Log4j1-x" class="headerlink" title="Log4j1.x"></a>Log4j1.x</h2><blockquote>
<p>官网：<a href="https://logging.apache.org/log4j/1.2/index.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/1.2/index.html</a></p>
</blockquote>
<p>apach较早的日志版本，维护到2015年后就不在维护了，历史资料保存，但不提供更新，](<a href="https://logging.apache.org/log4j/1.2/index.html)，也提供了包与slf4j集成（slf4j-log4j12），后续维护的是Logback。" target="_blank" rel="noopener">https://logging.apache.org/log4j/1.2/index.html)，也提供了包与slf4j集成（slf4j-log4j12），后续维护的是Logback。</a></p>
<h2 id="Logback"><a href="#Logback" class="headerlink" title="Logback"></a>Logback</h2><blockquote>
<p>官网：<a href="https://logback.qos.ch/" target="_blank" rel="noopener">https://logback.qos.ch/</a></p>
</blockquote>
<p>Logback，logback把日志分为3个模块，并实现了slf4j的接口，方便与slf4j集成（logback-classic）</p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ul>
<li>依赖问题，无法打印日志</li>
</ul>
<p>大概率是log4j2的实现和slf4j的实现冲突，删掉其中之一即可</p>
]]></content>
      <categories>
        <category>通用知识</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>小结</tag>
      </tags>
  </entry>
  <entry>
    <title>Regular-正则表达式</title>
    <url>/2022/01/06/5_%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="常规"><a href="#常规" class="headerlink" title="常规"></a>常规</h1><p><a href="https://www.runoob.com/regexp/regexp-syntax.html" target="_blank" rel="noopener">https://www.runoob.com/regexp/regexp-syntax.html</a></p>
<h1 id="先行断言和后行断言"><a href="#先行断言和后行断言" class="headerlink" title="先行断言和后行断言"></a>先行断言和后行断言</h1><p><a href="https://www.runoob.com/w3cnote/reg-lookahead-lookbehind.html" target="_blank" rel="noopener">https://www.runoob.com/w3cnote/reg-lookahead-lookbehind.html</a></p>
<p>对于这 4 个断言的理解，可以从两个方面入手：</p>
<ul>
<li><strong>1、关于先行(lookahead)和后行(lookbehind)：</strong>正则表达式引擎在执行字符串和表达式匹配时，会从头到尾（从前到后）连续扫描字符串中的字符，设想有一个扫描指针指向字符边界处并随匹配过程移动。先行断言，是当扫描指针位于某处时，引擎会尝试匹配指针还未扫过的字符，先于指针到达该字符，故称为先行。后行断言，引擎会尝试匹配指针已扫过的字符，后于指针到达该字符，故称为后行。</li>
<li><strong>2、关于正向(positive)和负向(negative)：</strong>正向就表示匹配括号中的表达式，负向表示不匹配。</li>
</ul>
<p>对这 4 个断言形式的记忆：</p>
<ul>
<li><strong>1、先行和后行：</strong>后行断言 <strong>(?&lt;=pattern)、(?&lt;!pattern)</strong> 中，有个小于号，同时也是箭头，对于自左至右的文本方向，这个箭头是指向后的，这也比较符合我们的习惯。把小于号去掉，就是先行断言。</li>
<li><strong>2、正向和负向：</strong>不等于 <strong>(!=)</strong>、逻辑非 <strong>(!)</strong> 都是用 <strong>!</strong>号来表示，所以有 <strong>!</strong> 号的形式表示不匹配、负向；将 <strong>!</strong> 号换成 <strong>=</strong> 号，就表示匹配、正向。</li>
</ul>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>用来判断以xxx开头，不以xxx结尾的</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;a[^&gt;]*&gt;((?!&lt;&#x2F;a&gt;).)*&lt;&#x2F;a&gt;</span><br></pre></td></tr></table></figure>

<p>分为以下五段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;a    [^&gt;]*   &gt;   ((?!&lt;&#x2F;a&gt;).)*    &lt;&#x2F;a&gt;</span><br></pre></td></tr></table></figure>

<ol>
<li><p>&lt;a</p>
<blockquote>
<p>匹配&lt;a</p>
</blockquote>
</li>
<li><p>[^&gt;]*</p>
<blockquote>
<p>^本意是匹配字符串开始的位置。但在方括号里，表示匹配不接收指定字符串，也就是不接收’’&gt;’’，使正则能够一直忽略”&gt;”一直匹配</p>
</blockquote>
</li>
<li><p>&gt;</p>
<blockquote>
<p>方括号一直匹配，直到遇到”&gt;”终止匹配。也就是说1，2，3匹配了&lt;a xxxxx&gt;这样的左标签</p>
</blockquote>
</li>
<li><p>((?!&lt;/a&gt;).)*</p>
<blockquote>
<p>先行反向断言，匹配（在””后面不能出现&lt;/a&gt;的任意字符）多次。也就是说只要没有遇到&lt;/a&gt;，可以一直匹配</p>
</blockquote>
</li>
<li><p>&lt;/a&gt;</p>
<blockquote>
<p>匹配&lt;/a&gt;</p>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>通用知识</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title>表达式计算框架调研</title>
    <url>/2024/09/01/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<meta name="referrer" content="no-referrer">



<h1 id="AviatorScript"><a href="#AviatorScript" class="headerlink" title="AviatorScript"></a>AviatorScript</h1><blockquote>
<p>用户指南：<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/cpow90" target="_blank" rel="noopener">https://www.yuque.com/boyan-avfmj/aviatorscript/cpow90</a> </p>
</blockquote>
<p>2010年出自淘宝中间件的开源项目，基于jvm的<strong>脚本语言</strong>，支持基础的运算符表达式，运算符扩展，安全的沙箱环境，轻量。社区更新积极，截止24.9.1，最近更新在3个月前，4.4K star。</p>
<p>官网介绍：</p>
<ol>
<li>支持数字、字符串、正则表达式、布尔值、正则表达式等<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/lvabnw" target="_blank" rel="noopener">基本类型</a>，完整支持所有 Java 运算符及优先级等。</li>
<li><a href="https://www.yuque.com/boyan-avfmj/aviatorscript/gl2p0q" target="_blank" rel="noopener">函数</a>是一等公民，支持<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/ksghfc" target="_blank" rel="noopener">闭包和函数式编程</a>。</li>
<li>内置 <a href="https://www.yuque.com/boyan-avfmj/aviatorscript/lvabnw#a0Ifn" target="_blank" rel="noopener">bigint</a>/<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/lvabnw#QbV7z" target="_blank" rel="noopener">decimal</a> 类型用于大整数和高精度运算，支持<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/ydllav#5hq4k" target="_blank" rel="noopener">运算符重载</a>得以让这些类型使用普通的算术运算符 <code>+-*/</code>参与运算。</li>
<li>完整的脚本语法支持，包括多行数据、条件语句、循环语句、词法作用域和异常处理等。</li>
<li><a href="https://www.yuque.com/boyan-avfmj/aviatorscript/ksghfc" target="_blank" rel="noopener">函数式编程</a>结合 <a href="https://www.yuque.com/boyan-avfmj/aviatorscript/yc4l93" target="_blank" rel="noopener">Sequence 抽象</a>，便捷处理任何集合。</li>
<li>轻量化的<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/rqra81" target="_blank" rel="noopener">模块系统</a>。</li>
<li>多种方式，方便地<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/xbdgg2" target="_blank" rel="noopener">调用 Java 方法</a>，完整支持 Java <a href="https://www.yuque.com/boyan-avfmj/aviatorscript/bds23b" target="_blank" rel="noopener">脚本 API</a>（方便从 Java 调用脚本）。</li>
<li>丰富的<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/yr1oau" target="_blank" rel="noopener">定制选项</a>，可作为安全的语言沙箱和全功能语言使用。</li>
<li>动态编译和执行、轻量化、高性能，ASM 模式下通过直接将脚本编译成 JVM 字节码，<a href="https://www.yuque.com/boyan-avfmj/aviatorscript/ok8agx" target="_blank" rel="noopener">解释模式</a>可运行于 Android 等非标 Java 平台。</li>
<li>支持<a href="https://github.com/killme2008/aviatorscript/blob/master/src/test/java/com/googlecode/aviator/example/SerializeExample.java" target="_blank" rel="noopener">编译结果序列化</a>，方便缓存加速等。支持<a href="https://github.com/killme2008/aviatorscript/blob/master/src/test/java/com/googlecode/aviator/example/TimeoutExample.java" target="_blank" rel="noopener">执行超时设置</a>，避免破坏性脚本耗尽资源。</li>
</ol>
<p>比较关心的特性</p>
<ol>
<li>轻量，依赖不多，大小不到2M</li>
<li>运算符重载</li>
<li>动态编译，性能较高</li>
</ol>
<p>maven坐标</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.googlecode.aviator&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;aviator&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;version&gt;5.4.3&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>例子</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">public static class OverloadDivide extends AbstractFunction &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String getName() &#123;</span><br><span class="line">      return &quot;&#x2F;&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public AviatorObject call(final Map&lt;String, Object&gt; env, final AviatorObject arg1,</span><br><span class="line">        final AviatorObject arg2) &#123;</span><br><span class="line">      if (FunctionUtils.getNumberValue(arg2, env).doubleValue() &#x3D;&#x3D; 0) &#123;</span><br><span class="line">        return new AviatorDecimal(0);</span><br><span class="line">      &#125;</span><br><span class="line">      BigDecimal left &#x3D; AviatorNumber.valueOf(arg1.getValue(env)).toDecimal(env);</span><br><span class="line">      BigDecimal right &#x3D; AviatorNumber.valueOf(arg2.getValue(env)).toDecimal(env);</span><br><span class="line">      return AviatorDecimal.valueOf(left.divide(right, RuntimeUtils.getMathContext(env)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  public static void main(final String[] args) &#123;</span><br><span class="line">    AviatorEvaluator.addOpFunction(OperatorType.DIV, new OverloadDivide());</span><br><span class="line"></span><br><span class="line">    System.out.println(AviatorEvaluator.execute(&quot;4 - 1&#x2F;0 + 3&quot;));</span><br><span class="line">    System.out.println(AviatorEvaluator.execute(&quot;4 - 1&#x2F;2.0 + 3&quot;));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>





<h1 id="MVEL"><a href="#MVEL" class="headerlink" title="MVEL"></a>MVEL</h1><blockquote>
<p>用户指南： <a href="http://mvel.documentnode.com/#simple-property-expression" target="_blank" rel="noopener">http://mvel.documentnode.com/#simple-property-expression</a> </p>
</blockquote>
<p>受java语言启发，是一种<strong>表达式语言</strong>，支持集合对象，常见的操作符、逻辑表达式。</p>
<p>maven坐标</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;org.mvel&lt;&#x2F;groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;mvel2&lt;&#x2F;artifactId&gt;</span><br><span class="line">           &lt;version&gt;2.4.14.Final&lt;&#x2F;version&gt;</span><br><span class="line">       &lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>



<p>例子</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void runMvel() &#123;</span><br><span class="line">        Fruit fruit &#x3D; new Fruit();</span><br><span class="line">        fruit.setName(&quot;Apple&quot;);</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; String expression &#x3D; &quot;fruit.getName()&quot;;</span><br><span class="line">        String expression &#x3D; &quot;fruit.name &#x3D;&#x3D; &#39;apple&#39;&quot;;</span><br><span class="line"></span><br><span class="line">        Map&lt;String, Object&gt; paramMap &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        paramMap.put(&quot;fruit&quot;, fruit);</span><br><span class="line"></span><br><span class="line">        Object object &#x3D; MVEL.eval(expression, paramMap);</span><br><span class="line">        System.out.println(object);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Data</span><br><span class="line">    public static class Fruit &#123;</span><br><span class="line">        private String name;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<h1 id="SPEL"><a href="#SPEL" class="headerlink" title="SPEL"></a>SPEL</h1><h1 id="Drools"><a href="#Drools" class="headerlink" title="Drools"></a>Drools</h1><blockquote>
<p>用户指南： <a href="https://docs.drools.org/7.74.1.Final/drools-docs/html_single/index.html" target="_blank" rel="noopener">https://docs.drools.org/7.74.1.Final/drools-docs/html_single/index.html</a></p>
</blockquote>
<p>较为完善的规则引擎，非常重，学习成本高，底层使用过mevl作为规则表达式计算</p>
<h1 id="Camel"><a href="#Camel" class="headerlink" title="Camel"></a>Camel</h1><blockquote>
<p>用户指南： <a href="https://camel.apache.org/manual/architecture.html" target="_blank" rel="noopener">https://camel.apache.org/manual/architecture.html</a> </p>
</blockquote>
<p>开源的系统集成框架，<a href="https://www.enterpriseintegrationpatterns.com/" target="_blank" rel="noopener">Enterprise Integration Patterns</a>的简单实现，处理系统之间消息的过滤，聚合，分发等操作。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><blockquote>
<p><a href="https://www.zhihu.com/question/20017425" target="_blank" rel="noopener">https://www.zhihu.com/question/20017425</a> 京东调研文档</p>
</blockquote>
]]></content>
  </entry>
</search>
